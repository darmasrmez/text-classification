DOI,Authors,Section,Date,Feature
https://doi.org/10.48550/arXiv.2503.18893,"Chi-Chih Chang, Chien-Yu Lin, Yash Akhauri, Wei-Cheng Lin, Kai-Chiang Wu, Luis Ceze, Mohamed S. Abdelfattah",CL,24/03/2025,"xkv : cross layer svd kv cache compression large language model ( llm ) long context window enable powerful application come cost high memory consumption to store key value state ( kv cache ) . recent study attempt to merge kv cache multiple layer share representation , yet approach require expensive pretraining rely assumption high per token cosine similarity layer which generally do not hold practice . find dominant singular vector be remarkably well aligned multiple layer kv cache . exploit insight , propose xkv , simple post training method apply singular value decomposition ( svd ) kv cache grouped layer . xkv consolidate kv cache multiple layer share low rank subspace , significantly reduce kv cache size . extensive evaluation ruler long context benchmark widely used llm ( , ) , xkv achieve to high compression rate state of the art inter layer technique improve accuracy % . moreover , xkv be compatible emerge multi head latent attention ( mla ) ( , ) , yield notable compression rate cod task performance degradation . result highlight xkv strong capability versatility address memory bottleneck long context llm inference . code be publicly available : http url ."
https://doi.org/10.48550/arXiv.2503.18891,"Zhexuan Wang, Yutong Wang, Xuebo Liu, Liang Ding, Miao Zhang, Jie Liu, Min Zhang",CL,24/03/2025,"agentdropout : dynamic agent elimination token efficient high performance llm based multi agent collaboration multi agent system ( ma ) base large language model ( llm ) have demonstrate significant potential collaborative problem solving . however , still face substantial challenge low communication efficiency suboptimal task performance , make careful design agent ' communication topology particularly important . inspire management theory that roles efficient team be often dynamically adjust , propose , which identify redundant agent communication different communication round optimize adjacency matrix communication graph eliminate to enhance token efficiency task performance . compare to state of the art method , agentdropout achieves average reduction % prompt token consumption % completion token consumption , performance improvement task . furthermore , extended experiment demonstrate agentdropout achieves notable domain transferability structure robustness , reveal reliability effectiveness . release code http url ."
https://doi.org/10.48550/arXiv.2503.18878,"Andrey Galichin, Alexey Dontsov, Polina Druzhinina, Anton Razzhigaev, Oleg Y. Rogov, Elena Tutubalina, Ivan Oseledets",CL,24/03/2025,"i have cover all base here : interpret reason feature large language model sparse autoencoders large language model ( llm ) have achieve remarkable success natural language processing . recent advance have lead to developing new class reason llm ; example , open source have achieve state of the art performance integrate deep thinking complex reasoning . impressive capability , internal reasoning mechanism such model remain unexplored . work , employ sparse autoencoders ( saes ) , method to learn sparse decomposition latent representation neural network interpretable feature , to identify feature that drive reason series model . first , propose approach to extract candidate reason feature sae representation . validate feature empirical analysis interpretability method , demonstrate direct correlation model reason ability . crucially , demonstrate steer feature systematically enhance reason performance , offer first mechanistic account reason llm . code available http url"
https://doi.org/10.48550/arXiv.2503.18769,"Alan Dao (Gia Tuan Dao), Dinh Bach Vu, Bui Quang Huy",CL,24/03/2025,"alphaspace : enabling robotic action semantic tokenization symbolic reasoning paper present alphaspace , novel methodology design to enhance spatial reasoning capability large language model ( llm ) cartesian space navigation . alphaspace employ semantics based tokenization strategy , encode height information specialize semantic token , integrate primarily symbolic synthetic reasoning data . approach enable llm to accurately manipulate object position specific [ x , y , z ] coordinate . experimental result demonstrate alphaspace significantly outperform exist model manipulation subtasks , achieve total accuracy % , compare to % % claude sonnet ."
https://doi.org/10.48550/arXiv.2503.18760,"Nick McKenna, Xinnuo Xu, Jack Williams, Nick Wilson, Benjamin Van Durme, Christian Poelitz",CL,24/03/2025,"synthetic function demonstration improve generation low resource programming language key consideration when train llm be target language be more less resourced , be english compare to welsh , python compare to excel . typical training data programming language consist real program demonstration couple human written comment . here present novel approach to creation such data low resource programming language . generate fully synthetic , textbook quality demonstration common library function example domain excel formula , use teacher model . then finetune underperforming student model , show improvement question answering datasets recast excel domain . show advantage finetuning standard , off the shelf rag approach , which can offer only modest improvement due to unfamiliar target domain ."
https://doi.org/10.48550/arXiv.2503.18751,"Wesley Scivetti, Nathan Schneider",CL,24/03/2025,"construction identification disambiguation use bert : case study npn construction grammar hypothesize knowledge language consist chiefly knowledge form meaning pair ( construction ) that include vocabulary , general grammar rule , even idiosyncratic pattern . recent work have show transformer language model represent least constructional pattern , include one where construction be rare overall . work , probe bert representation form meaning minor construction english , npn ( noun preposition noun ) construction exhibit such expression face to face day to day which be know to be polysemous . construct benchmark dataset semantically annotate corpus instance ( include distractors that superficially resemble construction ) . dataset , train evaluate probe classifier . achieve decent discrimination construction distractors , as well sense disambiguation true instance construction , reveal bert embeddings carry indication construction semantics . moreover , artificially permute word order true construction instance cause to be reject , indicate sensitivity to matter form . conclude bert do latently encode least knowledge npn construction go surface syntactic pattern lexical cue ."
https://doi.org/10.48550/arXiv.2503.18730,"Hongkuan Zhou, Stefan Schmid, Yicong Li, Lavdim Halilaj, Xiangtong Yao, Wei cao",CL,24/03/2025,"predict road ahead : knowledge graph base foundation model scene understanding autonomous driving autonomous driving field have see remarkable advancement various topic , such object recognition , trajectory prediction , motion planning . however , current approach face limitation effectively comprehend complex evolution drive scene time . paper propose , novel methodology train symbolic foundation model ( fm ) scene understanding autonomous driving . leverage knowledge graph ( kg ) to capture sensory observation domain knowledge such road topology , traffic rule , complex interaction traffic participant . bird eye view ( bev ) symbolic representation be extract kg drive scene , include spatio temporal information object scene . bev representation be serialize sequence token give to pre trained language model ( plms ) learn inherent understanding co occurrence drive scene element generate prediction next scene . conduct number experiment use nuscenes dataset kg various scenario . result demonstrate fine tuned model achieve significantly high accuracy task . fine tuned model achieve next scene prediction accuracy % . paper conclude offer promising foundation develop more comprehensive model scene understanding autonomous driving ."
https://doi.org/10.48550/arXiv.2503.18702,"David Ph. Shakouri, Crit Cremers, Niels O. Schiller",CL,24/03/2025,"unsupervised acquisition discrete grammatical category article present experiment perform use computational laboratory environment language acquisition experiment . implement multi agent system consist two agent : adult language model daughter language model that aim to learn mother language . crucially , daughter agent do not have access to internal knowledge mother language model only to language exemplars mother agent generates . experiment illustrate how system can be use to acquire abstract grammatical knowledge . demonstrate how statistical analysis pattern input data correspond to grammatical category yield discrete grammatical rule . rule be subsequently add to grammatical knowledge daughter language model . to end , hierarchical agglomerative cluster analysis be apply to utterance consecutively generate mother language model . be argue procedure can be use to acquire structure resemble grammatical category propose linguist natural language . thus , be establish non trivial grammatical knowledge have be acquire . moreover , parameter configuration computational laboratory environment determine use train data generate mother language model be validate second experiment test set similarly result acquisition non trivial category ."
https://doi.org/10.48550/arXiv.2503.18681,"Yazhou Zhang, Chunwang Zou, Bo Wang, Jing Qin",CL,24/03/2025,"commander gpt : fully unleash sarcasm detection capability multi modal large language model sarcasm detection , crucial research direction field natural language processing ( nlp ) , have attract widespread attention . traditional sarcasm detection task have typically focus single modal approach ( , text ) , due to implicit subtle nature sarcasm , such method often fail to yield satisfactory result . recent year , researcher have shift focus sarcasm detection to multi modal approach . however , effectively leverage multi modal information to accurately identify sarcastic content remain challenge that warrant further exploration . leverage powerful integrated processing capability multi modal large language model ( mllms ) various information source , propose innovative multi modal commander gpt framework . inspire military strategy , first decompose sarcasm detection task six distinct sub task . central commander ( decision maker ) then assign best suited large language model to address specific sub task . ultimately , detection result model be aggregate to identify sarcasm . conduct extensive experiment mmsd mmsd , utilize four multi modal large language model six prompt strategy . experiment demonstrate approach achieve state of the art performance , % improvement score , necessitate fine tuning ground truth rationale ."
https://doi.org/10.48550/arXiv.2503.18646,"Zhen-Song Chen, Hong-Wei Ding, Xian-Jia Wang, Witold Pedrycz",CL,24/03/2025,"zerolm : data free transformer architecture search language model neural architecture search ( nas ) provide systematic framework automate design neural network architecture , widespread adoption be hinder prohibitive computational requirement . exist zero cost proxy method , reduce search overhead , demonstrate inadequate performance architecture ranking task , particularly transformer based model where often underperform simple parameter count metric . current automate proxy discovery approach suffer extend search time , susceptibility to data overfitting , structural complexity . paper introduce novel zero cost proxy methodology that quantify model capacity efficient weight statistic computation decompose transformer architecture functionally distinct sub module , thereby optimize balance contribution to overall performance . comprehensive evaluation demonstrate superiority approach , achieve spearman rho kendall tau flexibert benchmark . propose method exhibit exceptional computational efficiency maintain robust performance diverse na benchmark task , offer practical solution large scale architecture search ."
https://doi.org/10.48550/arXiv.2503.18603,"Jong Myoung Kim, Young-Jun Lee, Ho-Jin Choi, Sangkeun Jung",CL,24/03/2025,"langalign : enhance non english language model cross lingual embed alignment large language model have gain attention , many service developer still rely embedding based model due to practical constraint . such case , quality fine tuning data directly impact performance , english datasets be often use seed data train non english model . study , propose langalign , which enhance target language processing align english embed vector target language interface language model task header . experiment korean , japanese , chinese demonstrate that langalign significantly improve performance three language . additionally , show langalign can be apply reverse to convert target language data format english based model can process ."
https://doi.org/10.48550/arXiv.2503.18596,"Yihan Wang, Peiyu Liu, Xin Yang",CL,24/03/2025,"linkalign : scalable schema link real world large scale multi database text to sql schema linking be critical bottleneck achieve human level performance text to sql task , particularly real world large scale multi database scenario . address schema link face two major challenge : ( ) database retrieval : select correct database large schema pool multi database setting , filter out irrelevant one . ( ) schema item grounding : accurately identify relevant table column large redundant schema sql generation . to address , introduce linkalign , novel framework that can effectively adapt exist baseline to real world environment systematically address schema link . framework comprise three key step : multi round semantic enhance retrieval irrelevant information isolation challenge , schema extraction enhancement challenge evaluate method performance schema link spider bird benchmark , ability to adapt exist text to sql model to real world environment spider benchmark . experiment show linkalign outperforms exist baseline multi database setting , demonstrate effectiveness robustness . other hand , method rank high model exclude use long chain of thought reasoning llm . work bridge gap current research real world scenario , provide practical solution robust scalable schema link . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18594,"Guillem García Subies, Álvaro Barbero Jiménez, Paloma Martínez Fernández",CL,24/03/2025,"clintext sp rigoberta clinical : new set open resource spanish clinical nlp present novel contribution to spanish clinical natural language processing introduce large publicly available clinical corpus , clintext sp , state of the art clinical encoder language model , rigoberta clinical . corpus be meticulously curated diverse open source , include clinical case medical journal annotate corpus share task , provide rich diverse dataset that be previously difficult to access . rigoberta clinical , develop domain adaptive pretraining comprehensive dataset , significantly outperform exist model multiple clinical nlp benchmark . publicly release dataset model , aim to empower research community robust resource that can drive further advancement clinical nlp ultimately contribute to improve healthcare application ."
https://doi.org/10.48550/arXiv.2503.18562,"Nariman Naderi, Seyed Amir Ahmad Safavi-Naini, Thomas Savage, Zahra Atf, Peter Lewis, Girish Nadkarni, Ali Soroush",CL,24/03/2025,"self reported confidence large language model gastroenterology : analysis commercial , open source , quantize model study evaluate self reported response certainty several large language model ( gpt , claude , llama , phi , mistral , gemini , gemma , qwen ) use gastroenterology board style question . high performing model ( preview , , ) achieve brier score auroc new model demonstrate improved performance , exhibit consistent tendency towards overconfidence . uncertainty estimation present significant challenge to safe use llm healthcare . keywords : large language model ; confidence elicitation ; artificial intelligence ; gastroenterology ; uncertainty quantification"
https://doi.org/10.48550/arXiv.2503.18539,"Ashenafi Zebene Woldaregay, Jørgen Aarmo Lund, Phuong Dinh Ngo, Mariyam Tayefi, Joel Burman, Stine Hansen, Martin Hylleholt Sillesen, Hercules Dalianis, Robert Jenssen, Lindsetmo Rolf Ole, Karl Øyvind Mikalsen",CL,24/03/2025,"natural language processing electronic health record scandinavian language : norwegian , swedish , danish background : clinical natural language processing ( nlp ) refers to use computational method extract , processing , analyze unstructured clinical text data , hold huge potential to transform healthcare various clinical task . objective : study aim to perform systematic review to comprehensively assess analyze state of the art nlp method mainland scandinavian clinical text . method : literature search be conduct various online database include pubmed , sciencedirect , google scholar , acm digital library , ieee xplore december february far , relevant reference to included article be also use to solidify search . final pool include article that conduct clinical nlp mainland scandinavian language be publish english result : article , % ( ) focus norwegian clinical text , % ( ) swedish , % ( ) danish , % ( ) focus more one language . generally , review identify positive development region observable gap disparity language . there be substantial disparity level adoption transformer based model . essential task such de identification , there be significantly less research activity focus norwegian danish compare to swedish text . far , review identify low level share resource such data , experimentation code , pre trained model , rate adaptation transfer learning region . conclusion : review present comprehensive assessment state of the art clinical nlp electronic health record ( ehr ) text mainland scandinavian language , highlight potential barrier challenge that hinder rapid advancement field region ."
https://doi.org/10.48550/arXiv.2503.18526,"Raúl Ortega, José Manuel Gómez-Pérez",CL,24/03/2025,"sciclaims : end to end generative system biomedical claim analysis validate key claim scientific literature , particularly biomedical research , be essential ensure accuracy advance knowledge . process be critical sector pharmaceutical industry , where rapid scientific progress require automation deep domain expertise . however , current solution have significant limitation . lack end to end pipeline encompass claim extraction , evidence retrieval , verification step ; rely complex nlp information retrieval pipelines prone to multiple failure point ; often fail to provide clear , user friendly justification claim verification outcomes . to address challenge , introduce sciclaims , advanced system power state of the art large language model ( llm ) that seamlessly integrate entire scientific claim analysis process . sciclaims outperform previous approach claim extraction verification require additional fine tuning , set new benchmark automated scientific claim analysis ."
https://doi.org/10.48550/arXiv.2503.18502,"Andrés García-Silva, José Manuel Gómez-Pérez",CL,24/03/2025,"autoregressive language model knowledge base population : case study space mission domain knowledge base population kbp play crucial role populate maintain knowledge base up to date organization leverage domain corpus . motivate increasingly large context window support large language model , propose to fine tune autoregressive language model end toend kpb . case study involve population space mission knowledge graph . to fine tune model generate dataset end to end kbp tap exist domain resource . case study show fine tuned language model limited size can achieve competitive even high accuracy large model kbp task . small model specialize kbp offer affordable deployment low cost inference . moreover , kbp specialist model do not require ontology to be include prompt , allow more space context additional input text output serialization ."
https://doi.org/10.48550/arXiv.2503.18491,"Shuo Yang, Siwen Luo, Soyeon Caren Han, Eduard Hovy",CL,24/03/2025,"magic vqa : multimodal ground inference commonsense knowledge visual question answer visual question answering ( vqa ) require reason visual textual modality , yet large vision language model ( lvlms ) often lack integrated commonsense knowledge , limit robustness real world scenario . to address , introduce magic vqa , novel framework that enhance vqa systematically integrate commonsense knowledge lvlms . magic vqa employ three stage process : ( ) explicit knowledge integration external source , ( ) by type post processing contextual refinement , ( ) implicit knowledge augmentation use graph neural network ( gnn ) structure reasoning . gnns bring great depth to structure inference , enable superior relational inference lvlms . magic vqa bridge key gap unify commonsensse knowledge lvlm driven reasoning , eliminate need extensive pre training complex prompt tuning . framework achieve state of the art performance benchmark datasets , significantly improve commonsense reason vqa ."
https://doi.org/10.48550/arXiv.2503.18485,"Dawit Ketema Gete, Bedru Yimam Ahamed, Tadesse Destaw Belay, Yohannes Ayana Ejigu, Sukairaj Hafiz Imam, Alemu Belay Tessema, Mohammed Oumer Adem, Tadesse Amare Belay, Robert Geislinger, Umma Aliyu Musa, Martin Semmann, Shamsuddeen Hassan Muhammad, Henning Schreiber, Seid Muhie Yimam",CL,24/03/2025,"whisper amharic : fine tuning whisper low resource language work explore fine tuning openai whisper automatic speech recognition ( asr ) model amharic , low resource language , to improve transcription accuracy . foundational whisper model struggle amharic due to limited representation training data , fine tune use datasets mozilla common voice , fleurs , bdu speech dataset . best performing model , whispersmall am , significantly improve when finetuned mix exist fleurs data new , unseen amharic datasets . train solely new data lead to poor performance , combine fleurs data reinforces model , enable good specialization amharic . also demonstrate normalize amharic homophone significantly enhance word error rate ( wer ) bilingual evaluation understudy ( bleu ) score . study underscore importance fine tuning strategy dataset composition improve asr low resource language , provide insight future amharic speech recognition research ."
https://doi.org/10.48550/arXiv.2503.18471,"Calvin Bao, Yow-Ting Shiue, Marine Carpuat, Joel Chan",CL,24/03/2025,"word bridge : explore computational support cross disciplinary translation work scholar often explore literature home community study . exploration process be frequently hamper field specific jargon . past computational work often focus support translation work remove jargon simplification summarization ; here , explore different approach that preserve jargon useful bridge to new conceptual space . specifically , cast different scholarly domains different language using community , explore how to adapt technique unsupervised cross lingual alignment word embeddings to explore conceptual alignment domain specific word embed http url develop prototype cross domain search engine that use align domain specific embeddings to support conceptual exploration , test prototype two case study . discuss qualitative insight promise pitfall approach to translation work , suggest design insight future interface that provide computational support cross domain information seek ."
https://doi.org/10.48550/arXiv.2503.18432,"Junsong Li, Jie Zhou, Yutao Yang, Bihao Zhan, Qianjun Pan, Yuyang Ding, Qin Chen, Jiang Bo, Xin Lin, Liang He",CL,24/03/2025,"teach llm step level automatic math correction reinforcement learning automatic math correction aim to check student ' solution to mathematical problem artificial intelligence technology . most existing study focus judge final answer problem level , ignore detailed feedback step math problem solving process , which require ability semantic understanding reasoning . paper , propose reinforcement learning ( rl )  base method to boost large language model ( llm ) step level automatic math correction , name stepamc . particularly , convert step level automatic math correction text classification task rl problem to enhance reason capability llm . then , design space constrained policy network to improve stability rl . then , introduce fine grained reward network to convert binary human feedback continuous value . conduct extensive experiment two benchmark datasets result show model outperform eleven strong baseline ."
https://doi.org/10.48550/arXiv.2503.18360,"Yiran Hu, Huanghai Liu, Qingjing Chen, Ning Zheng, Chong Wang, Yun Liu, Charles L.A. Clarke, Weixing Shen",CL,24/03/2025,"j & h : evaluate robustness large language model knowledge injection attack legal domain scale capability large language model ( llm ) increase , application knowledge intensive field such legal domain have garner widespread attention . however , remain doubtful llm make judgment base domain knowledge reason . llms base judgment solely specific word pattern , rather underlie logic language , llm as judges paradigm pose substantial risk real world application . to address question , propose method legal knowledge injection attack robustness testing , thereby infer llm have learn legal knowledge reason logic . paper , propose j & h : evaluation framework detect robustness llm knowledge injection attack legal domain . aim framework be to explore llms perform deductive reason when accomplish legal task . to far aim , have attack part reason logic underlie task ( major premise , minor premise , conclusion generation ) . have collect mistake legal expert might make judicial decision real world , such typo , legal synonym , inaccurate external legal statute retrieval . however , real legal practice , legal expert tend to overlook mistake make judgment base logic . however , when face error , llm be likely to be mislead typographical error may not utilize logic judgment . conduct knowledge injection attack exist general domain specific llm . current llm be not robust attack employ experiment . addition propose compare several method to enhance knowledge robustness llm ."
https://doi.org/10.48550/arXiv.2503.18296,"Mengya Xu, Zhongzhen Huang, Jie Zhang, Xiaofan Zhang, Qi Dou",CL,24/03/2025,"surgical action plan large language model robot assisted minimally invasive surgery , introduce surgical action planning ( sap ) task , which generate future action plan visual input to address absence intraoperative predictive planning current intelligent application . sap show great potential enhance intraoperative guidance automating procedure . however , face challenge such understand instrument action relationship track surgical progress . large language model ( llm ) show promise understand surgical video content remain underexplored predictive decision making sap , focus mainly retrospective analysis . challenge data privacy , computational demand , modality specific constraint further highlight significant research gap . to tackle challenge , introduce llm sap , large language models based surgical action planning framework that predict future action generates text response interpret natural language prompt surgical goal . text responses potentially support surgical education , intraoperative decision making , procedure documentation , skill analysis . llm sap integrates two novel module : near history focus memory module ( nhf mm ) model historical state prompt factory action planning . evaluate llm sap construct dataset use model , demonstrate effectiveness next action prediction . pre trained llm be test zero shot , supervise fine tuning ( sft ) lora be implement to address data privacy concern . experiment show surpasses % high accuracy ."
https://doi.org/10.48550/arXiv.2503.18293,"Jiayi Yao, Haibo Sun, Nianwen Xue",CL,24/03/2025,"fact checking ai generated news report : can llms catch own lie ? paper , evaluate ability large language model ( llm ) to assess veracity claim news report generate other llm . goal be to determine llm can effectively fact check own content , use method similar to use to verify claim make human . finding indicate llm be more effective assess claim national international news story local news story , good evaluate static information dynamic information , good verify true claim compare to false one . hypothesize disparity arise former type claim be well represent training data . additionally , find incorporate retrieve result search engine retrieval augmented generation ( rag ) set significantly reduce number claim llm can not assess . however , approach also increase occurrence incorrect assessment , partly due to irrelevant low quality search result . diagnostic study highlight need future research fact checking machine generated report to prioritize improve precision relevance retrieved information to good support fact checking effort . furthermore , claim dynamic event local news may require human in the loop fact checking system to ensure accuracy reliability ."
https://doi.org/10.48550/arXiv.2503.18290,Paul K. Mandal,CL,24/03/2025,"when be dataset cartography ineffective ? use train dynamic do not improve robustness adversarial squad paper , i investigate effectiveness dataset cartography extractive question answer squad dataset . i begin analyze annotation artifact squad evaluate impact two adversarial datasets , addsent addonesent , electra small model . use train dynamic , i partition squad easy to learn , ambiguous , hard to learn subset . i then compare performance model train subset to train randomly select sample equal size . result show train cartography based subset do not improve generalization to squad validation set addsent adversarial set . hard to learn subset yield slightly high score addonesent dataset , overall gain be limit . finding suggest dataset cartography provide little benefit adversarial robustness squad style qa task . i conclude compare result to prior finding snli discus possible reason observed difference ."
https://doi.org/10.48550/arXiv.2503.18288,"Cheng Huang, Fan Gao, Nyima Tashi, Yutong Liu, Xiangxiang Wang, Thupten Tsering, Ban Ma-bao, Renzeg Duojie, Gadeng Luosang, Rinchen Dongrub, Dorje Tashi, Xiao Feng, Yongbin Yu",CL,24/03/2025,"sun shine : large language model tibetan culture tibetan , minority language china , feature highly intricate grammatical structure , characterize four verb tense tense system frequent irregularity , contribute to extensive inflectional diversity . recently , advance large language model ( llm ) have transform paradigm many domain . success other field , current llm often fall short cater to need domain expert tibetan , potential llm tibetan culture be under explored . intrinsic reason be immense intricate nature tibetan culture as well necessity high granularity richness knowledge . simultaneously , complexity uniqueness grammatical structure , couple status minority ethnic language , contribute to data scarcity , which remain fundamental challenge . to alleviate issue , introduce llama sunshine ( sun shine ) , first large language model tibetan culture , which be expert various tibetan language processing task . sun shine incorporate state of the art model architecture optimize tibetan linguistic feature . also propose tib stc , comprehensive dataset comprise diverse tibetan text such literature , religious script , news , conversational data , which be also first large scale dataset tibetan culture . comprehensive experiment , sun shine not only demonstrate high level knowledge expertise tibetan culture also gain preliminary embody intelligence capability tibetan language processing task , language modeling , text classification , machine translation , syntactic analysis . moreover , excel low resource scenario , showcasing strong generalization capability ."
https://doi.org/10.48550/arXiv.2503.18260,"Mahak Shah, Akaash Vishal Hazarika, Meetu Malhotra, Sachin C. Patil, Joshit Mohanty",CL,24/03/2025,"bridge emotion architecture : sentiment analysis modern distribute system sentiment analysis be field nlp that have gain importance be apply various area such ; social medium surveillance , customer feedback evaluation market research . same time , distribute system allow effective processing large amount data . therefore , paper examine how sentiment analysis converges distributed system concentrate different approach , challenge future investigation . furthermore , do extensive experiment where train sentiment analysis model use single node configuration distributed architecture to bring out benefit shortcoming method term performance accuracy ."
https://doi.org/10.48550/arXiv.2503.18253,"Tadesse Destaw Belay, Dawit Ketema Gete, Abinew Ali Ayele, Olga Kolesnikova, Grigori Sidorov, Seid Muhie Yimam",CL,24/03/2025,"enhance multi label emotion analysis corresponding intensity ethiopian language digital world , people freely express emotion use different social medium platform . result , modeling integrate emotion understanding model be vital various human computer interaction task such decision making , product customer feedback analysis , political promotion , marketing research , social medium monitoring . user express different emotion simultaneously single instance , annotate emotion multilabel set such ethioemo ( belay et , ) dataset effectively capture dynamic . additionally , incorporate intensity , degree emotion , be crucial , emotion can significantly differ expressive strength impact . intensity be significant assess further action be necessary decision making process , especially concern negative emotion application such healthcare mental health study . to enhance ethioemo dataset , include annotation intensity label emotion . furthermore , evaluate various state of the art encoder only pretrained language model ( plms ) decoder only large language model ( llm ) to provide comprehensive benchmarking ."
https://doi.org/10.48550/arXiv.2503.18250,"Jong Myoung Kim, Young-Jun_Lee, Ho-Jin Choi, Sangkeun Jung",CL,24/03/2025,"pad : towards efficient data generation transfer learn use phrase alignment transfer learning leverage abundance english data to address scarcity resource model non english language , such korean . study , explore potential phrase align data ( pad ) standardized statistical machine translation ( smt ) to enhance efficiency transfer learning . extensive experiment , demonstrate pad synergizes effectively syntactic characteristic korean language , mitigate weakness smt significantly improve model performance . moreover , reveal pad complement traditional data construction method enhances effectiveness when combine . innovative approach not only boost model performance also suggest cost efficient solution resource scarce language ."
https://doi.org/10.48550/arXiv.2503.18247,"Tadesse Destaw Belay, Israel Abebe Azime, Ibrahim Said Ahmad, Idris Abdulmumin, Abinew Ali Ayele, Shamsuddeen Hassan Muhammad, Seid Muhie Yimam",CL,24/03/2025,"afroxlmr social : adapt pre trained language model african language social medium text pretrained language model ( plms ) build various source be foundation today nlp progress . language representation learn such model achieve strong performance many task datasets vary size draw various source . explore thorough analysis domain task adaptive continual pretraining approach low resource african language promising result be show evaluated task . create afrisocial , corpus design domain adaptive finetuning that pass quality pre processing step . continual pretraining plms use afrisocial domain adaptive pretraining ( dapt ) data , consistently improve performance fine grained emotion classification task targeted language % to % macro score . likewise , use task adaptive pertaining ( tapt ) approach , further finetuning small unlabeled similar task data show promise result . example , unlabeled sentiment data ( source ) fine grained emotion classification task ( target ) improve base model result score range % to % . combine two method , dapt + tapt , achieve also good result base model . all resource will be available to improve low resource nlp task , generally , as well other similar domain task such hate speech sentiment task ."
https://doi.org/10.48550/arXiv.2503.18242,"Aneesh Vathul, Daniel Lee, Sheryl Chen, Arthi Tasmia",CL,23/03/2025,"shed hd : shannon entropy distribution framework lightweight hallucination detection edge device large language model ( llm ) have demonstrate impressive capability broad array nlp task , tendency to produce hallucination $ { } $ plausible sounding factually incorrect content $ { } $ pose severe challenge high stakes domain . exist hallucination detection method bear computational cost multiple inference pass sacrifice accuracy efficiency single pass approach , which be ideal resource constrained environment such edge device . propose shannon entropy distribution hallucination detector ( shed hd ) , novel hallucination detection framework that bridge gap classify sequence level entropy pattern use lightweight bilstm architecture single headed attention . contrast to prior approach , shed hd efficiently detect distinctive uncertainty pattern entire output sequence , preserve contextual awareness . in depth evaluation three datasets ( bioasq , triviaqa , jeopardy question ) , show shed hd significantly outperform other computationally efficient approach out of distribution setting , achieve comparable performance in distribution setting . shed hd facilitates hallucination detection that be low cost , accurate , generalizable , improve credibility content generate llm resource constrained environment where trustworthy ai functionality be crucial ."
https://doi.org/10.48550/arXiv.2503.18226,"Venkatesh Bollineni, Igor Crk, Eren Gultepe",CL,23/03/2025,"map hymn organize concept rigveda : quantitatively connect vedic suktas access gain insight rigveda pose non trivial challenge due to extremely ancient sanskrit language , poetic structure , large volume text . use nlp technique , study identify topic semantic connection hymn rigveda that be corroborate seven well known grouping hymn . suktas ( hymn ) modern english translation rigveda jamison brereton be preprocessed sukta level embeddings be obtain use , i ) novel adaptation lsa , present herein , ii ) sbert , iii ) embeddings . follow umap dimension reduction vector , network suktas be form use k near neighbour . then , community detection topic sukta network be perform louvain , leiden , label propagation method , whose statistical significance form topic be determine use appropriate null distribution . only novel adaptation lsa use leiden method , have detect sukta topic network that be significant ( z = , p < ) modularity score seven famous sukta grouping analyze ( , creation , funeral , water , etc . ) lsa derive network be successful seven case , be not significant fail to detect relevant suktas . sbert detect four famous suktas separate group , mistakenly combine three single mixed group . also , sbert network be not statistically significant ."
https://doi.org/10.48550/arXiv.2503.18212,"Kanishka Parankusham, Rodrigue Rizk, KC Santosh",CL,23/03/2025,"lakotabert : transformer based model low resource lakota language lakota , critically endanger language sioux people north america , face significant challenge due to decline fluency young generation . paper introduce lakotabert , first large language model ( llm ) tailor lakota , aim to support language revitalization effort . research have two primary objective : ( ) to create comprehensive lakota language corpus ( ) to develop customized llm lakota . compile diverse corpus sentence lakota , english , parallel text various source , such book website , emphasize cultural significance historical context lakota language . utilize roberta architecture , pre train model conduct comparative evaluation establish model such roberta , bert , multilingual bert . initial result demonstrate masked language model accuracy % single ground truth assumption , showcasing performance comparable to english based model . also evaluate model use additional metric , such precision score , to provide comprehensive assessment capability . integrate ai linguistic methodology , aspire to enhance linguistic diversity cultural resilience , set valuable precedent leverage technology revitalization other endanger indigenous language ."
https://doi.org/10.48550/arXiv.2503.18182,"Divya Patel, Vansh Parikh, Om Patel, Agam Shah, Bhaskar Chaudhury",CL,23/03/2025,"explore topic trend research literature use non negative matrix factorization work , apply topic model use non negative matrix factorization ( nmf ) open research dataset ( ) to uncover underlying thematic structure evolution extensive body research literature . factorize document term matrix two non negative matrix , effectively represent topic distribution document . help see how strongly document relate to topic how topic relate to word . describe complete methodology which involve series rigorous pre processing step to standardize available text data preserve context phrase , subsequently feature extraction use term frequency inverse document frequency ( tf idf ) , which assign weight to word base frequency rarity dataset . to ensure robustness topic model , conduct stability analysis . process assess stability score nmf topic model different number topic , enable to select optimal number topic analysis . analysis , track evolution topic time dataset . finding contribute to understanding knowledge structure research landscape , provide valuable resource future research field ."
https://doi.org/10.48550/arXiv.2503.18174,"Weronika Łajewska, Krisztian Balog",CL,23/03/2025,"ginger : ground information nugget based generation response retrieval augmented generation ( rag ) face challenge relate to factual correctness , source attribution , response completeness . to address , propose modular pipeline ground response generation that operate information nuggets minimal , atomic unit relevant information extract retrieved document . multistage pipeline encompass detection , cluster , rank , top cluster summarization , fluency enhancement . guarantee ground specific fact , facilitate source attribution , ensure maximum information inclusion length constraint . extensive experiment trec dataset evaluate autonuggetizer framework demonstrate that ginger achieve state of the art performance benchmark ."
https://doi.org/10.48550/arXiv.2503.18172,"Zixin Chen, Sicheng Song, Kashun Shum, Yanna Lin, Rui Sheng, Huamin Qu",CL,23/03/2025,"unmask deceptive visuals : benchmarking multimodal large language model mislead chart question answer mislead chart visualization , which intentionally manipulate data representation to support specific claim , can distort perception lead to incorrect conclusion . decade research , mislead visualization remain widespread pressing issue . recent advance multimodal large language model ( mllms ) have demonstrate strong chart comprehension capability , yet exist work have systematically evaluate ability to detect interpret misleading chart . paper introduce misleading chart question answer ( mislead chartqa ) benchmark , large scale multimodal dataset design to assess mllms identifying reason mislead chart . contain curated example , cover type misleader chart type . example include standardized chart code , csv data , multiple choice question labeled explanation , validate multi round mllm check exhaust expert human review . benchmark state of the art mllms dataset , reveal limitation identify visually deceptive practice . also propose novel pipeline that detect localize misleader , enhance mllms ' accuracy mislead chart interpretation . work establish foundation advance mllm driven misleading chart comprehension . publicly release sample dataset to support further research critical area ."
https://doi.org/10.48550/arXiv.2503.18167,"Suman Adhya, Avishek Lahiri, Debarshi Kumar Sanyal, Partha Pratim Das",CL,23/03/2025,"evaluate negative sampling approach neural topic model negative sampling have emerge effective technique that enable deep learning model to learn good representation introduce paradigm learn to compare . goal approach be to add robustness to deep learning model to learn good representation compare positive sample negative one . numerous demonstration various area computer vision natural language processing , comprehensive study effect negative sampling unsupervised domain topic modeling have not be well explore . paper , present comprehensive analysis impact different negative sampling strategy neural topic model . compare performance several popular neural topic model incorporate negative sampling technique decoder variational autoencoder based neural topic model . experiment four publicly available datasets demonstrate integrate negative sampling topic model result significant enhancement multiple aspect , include improve topic coherence , rich topic diversity , more accurate document classification . manual evaluation also indicate inclusion negative sample neural topic model enhance quality generated topic . finding highlight potential negative sampling valuable tool advance effectiveness neural topic model ."
https://doi.org/10.48550/arXiv.2503.18132,"Yibo Yan, Shen Wang, Jiahao Huo, Philip S. Yu, Xuming Hu, Qingsong Wen",CL,23/03/2025,"mathagent : leverage mixture of math agent framework real world multimodal mathematical error detection mathematical error detection educational setting present significant challenge multimodal large language model ( mllms ) , require sophisticated understanding visual textual mathematical content complex reason capability . effective mathematical problem solving , mllms often struggle nuanced task identify categorize student error multimodal mathematical context . therefore , introduce mathagent , novel mixture of math agent framework design specifically to address challenge . approach decompose error detection three phase , handle specialized agent : image text consistency validator , visual semantic interpreter , integrative error analyzer . architecture enable more accurate processing mathematical content explicitly model relationship multimodal problem student solution step . evaluate mathagent real world educational data , demonstrate approximately % high accuracy error step identification % improvement error categorization compare to baseline model . besides , mathagent have be successfully deploy educational platform that have serve one million student , achieve nearly % student satisfaction generate significant cost saving reduce manual error detection ."
https://doi.org/10.48550/arXiv.2503.18129,"Varvara Krechetova, Denis Kochedykov",CL,23/03/2025,"geobenchx : benchmarking llm multistep geospatial task paper , establish benchmark evaluate large language model ( llm ) multi step geospatial task relevant to commercial gi practitioner . assess seven lead commercial llm ( sonnet , haiku , gemini , , mini , ) use simple tool calling agent equip geospatial function . benchmark comprise task four category increase complexity , solvable intentionally unsolvable task to test hallucination rejection . develop llm as judge evaluation framework to compare agent solution reference implementation . result show sonnet achieve best overall performance , claude model excel solvable task openai model well identify unsolvable scenario . observe significant difference token usage , anthropic model consume substantially more token competitor . common error include misunderstand geometrical relationship , rely outdated knowledge , inefficient data manipulation . result benchmark set , evaluation framework , data generation pipeline be release open source resource , provide one more standardized method ongoing evaluation llm geoai ."
https://doi.org/10.48550/arXiv.2503.18117,"Muhidin A. Mohamed, Shuab D. Ahmed, Yahye A. Isse, Hanad M. Mohamed, Fuad M. Hassan, Houssein A. Assowe",CL,23/03/2025,"detection somali written fake news toxic message social medium use transformer based language model fact everyone social medium account can create share content , increase public reliance social medium platform news information source bring significant challenge such misinformation , fake news , harmful content , etc . human content moderation may be useful to extent use platform to flag posted material , use ai model provide more sustainable , scalable , effective way to mitigate harmful content . however , low resourced language such somali language face limitation ai automation , include scarce annotate train datasets lack language model tailor to unique linguistic characteristic . paper present part ongoing research work to bridge gap somali language . particular , create two human annotated social media sourced somali datasets two downstream application , fake news \ & toxicity classification , develop transformer based monolingual somali language model ( name somberta ) first kind to best knowledge . somberta be then fine tuned evaluate toxic content , fake news news topic classification datasets . comparative evaluation analysis propose model related multilingual model ( , afriberta , afroxlmr , etc ) demonstrate somberta consistently outperform comparators fake news toxic content classification task achieve best average accuracy ( % ) task . research contribute to somali nlp offer foundational language model replicable framework other low resource language , promote digital ai inclusivity linguistic diversity ."
https://doi.org/10.48550/arXiv.2503.18095,"Lorena G Barberia, Belinda Lombard, Norton Trevisan Roman, Tatiane C. M. Sousa",CL,23/03/2025,"clarify misconception vaccine sentiment stance analysis implication vaccine hesitancy mitigation : systematic review background advance machine learning ( ml ) model have increase capability researcher to detect vaccine hesitancy social medium use natural language processing ( nlp ) . considerable volume research have identify persistence vaccine hesitancy discourse share various social medium platform . method objective study be to conduct systematic review research employ sentiment analysis stance detection to study discourse towards vaccine vaccination spread twitter ( officially know x ) . follow registration prospero international registry systematic review , search paper publish january to december that use supervise machine learn to assess vaccine hesitancy stance detection sentiment analysis twitter . categorize study accord to taxonomy five dimension : tweet sample selection approach , self reported study type , classification typology , annotation codebook definition , interpretation result . analyze study use stance detection report different hesitancy trend use sentiment analysis examine how vaccine hesitancy be measure , effort be make to avoid measurement bias . result review find measurement bias be widely prevalent study employ supervised machine learn to analyze sentiment stance vaccine vaccination . reporting error be sufficiently serious hinder generalisability interpretation study to understand individual opinion communicate reluctance to vaccinate . conclusion improve reporting nlp method be crucial to address knowledge gap vaccine hesitancy discourse ."
https://doi.org/10.48550/arXiv.2503.18089,"Javad SeraJ, Mohammad Mahdi Mohajeri, Mohammad Javad Dousti",CL,23/03/2025,"$ $ : data driven lora initialization low resource task tune large language model be essential optimize performance diverse application , particularly scenario limited data availability . tune large language model scarce data scenario be crucial , particularly give convergence speed lora method be low full fine tuning . paper , present analysis post training method include supervise fine tuning ( sft ) , direct preference optimization ( dpo ) , odds ratio preference optimization ( orpo ) context task specific learn use lora method . introduce $ $ , data driven approach initialize lora metric that enhance training efficiency , especially limited data setting . experiment compare $ $ vanilla lora term performance catastrophic forget extremely data constrained condition . result demonstrate $ $ achieve % improvement benchmark improvement rouge score title generation task . $ $ facilitate adaptation llm to multiple task even when task specific data be scarce , thereby reduce training expense offer data cost ."
https://doi.org/10.48550/arXiv.2503.18085,"Rochana Chaturvedi, Peyman Baghershahi, Sourav Medya, Barbara Di Eugenio",CL,23/03/2025,"temporal relation extraction clinical text : span based graph transformer approach temporal information extraction unstructured text be essential contextualizing event derive actionable insight , particularly medical domain . address task extract clinical event temporal relation use well studied temporal relation challenge corpus . task be inherently challenge due to complex clinical language , long document , sparse annotation . introduce graphtrex , novel method integrate span based entity relation extraction , clinical large pre trained language model ( lplms ) , heterogeneous graph transformer ( hgt ) to capture local global dependency . hgt component facilitate information propagation document innovative global landmark bridge distant entity . method improve state of the art % improvement tempeval $ $ score previous best up to % improvement long range relation , which present formidable challenge . work not only advance temporal information extraction also lay groundwork improve diagnostic prognostic model enhanced temporal reasoning ."
https://doi.org/10.48550/arXiv.2503.18076,"Somnath Roy, Padharthi Sreekar, Srivatsa Narasimha, Anubhav Anand",CL,23/03/2025,"multi model adaptation speculative decoding classification current study introduce novel adaptation speculative decoding , repurposed generation to classification task . propose multi model framework employ up to three lightweight worker model single , more robust judge model analogous to draft model target model , respectively , speculative decoding . worker model , task bulk computation , independently predict discrete class label give input . when majority worker model agree label , be accept final label , optimize efficiency bypass computationally expensive judge model . case disagreement , judge model intervenes to resolve label . approach minimize redundant computation , leverage redundancy multiple worker confidence , confine judge model role to challenge case , offer practical balance efficiency accuracy . analysis suggest small box finetuned worker model billion parameter ( hereafter , ) demonstrate level alignment judge model comparable to large finetuned worker model billion parameter ( hereafter , ) simple high order reason task . top performing worker model pair achieve agreement rate approximately % sentiment % similar ticket when compare to judge model . additionally , worker model provide speedup range to relative to judge model , worker model combination achieve speedup range to"
https://doi.org/10.48550/arXiv.2503.18072,"Germán Capdehourat, Isabel Amigo, Brian Lorenzo, Joaquín Trigo",CL,23/03/2025,"effectiveness llm automatic grading open ended question spanish grading be time consuming laborious task educator must face . be important task provide feedback signal to learner , have be demonstrate timely feedback improve learning process . recent year , irruption llm have shed light effectiveness automatic grading . paper , explore performance different llm prompt technique automatically grade short text answer to open ended question . most literature , study focus use case where question , answer , prompt be spanish . experimental result compare automatic score to human expert evaluator show good outcome term accuracy , precision consistency advanced llm , open proprietary . result be notably sensitive to prompt style , suggest bias certain word content prompt . however , best combination model prompt strategy , consistently surpass accuracy % three level grading task , which even rise up to more % when be simplify to binary right wrong rating problem , which demonstrate potential llm have to implement type automation education application ."
https://doi.org/10.48550/arXiv.2503.18071,"Zhiyu Lin, Yifei Gao, Xian Zhao, Yunfan Yang, Jitao Sang",CL,23/03/2025,"mind eye : language reason to multimodal reason language model have recently advance realm reasoning , be multimodal reasoning can fully unlock potential to achieve more comprehensive , human like cognitive capability . survey provide systematic overview recent multimodal reason approach , categorize two level : language centric multimodal reasoning collaborative multimodal reasoning . former encompasses one pass visual perception active visual perception , where vision primarily serve support role language reasoning . latter involve action generation state update reason process , enable more dynamic interaction modality . furthermore , analyze technical evolution method , discuss inherent challenge , introduce key benchmark task evaluation metric assess multimodal reason performance . finally , provide insight future research direction follow two perspective : ( i ) visual language reason to omnimodal reasoning ( ii ) multimodal reason to multimodal agent . survey aim to provide structured overview that will inspire further advancement multimodal reason research ."
https://doi.org/10.48550/arXiv.2503.18069,"Si Shen, Fei Huang, Zhixiao Zhao, Chang Liu, Tiansheng Zheng, Danhao Zhu",CL,23/03/2025,"long be more important difficult train reasoning model difficult problem , which often result long reasoning trace , be widely recognize key factor enhance performance reason model . however , such high challenge problem be scarce , limit size available datasets . paper , propose simple method to decouple reliance problem difficulty . first , empirically demonstrate reason length , rather problem difficulty , primarily influence performance trained model . second , identify scaling law reason length , show model performance increase log linear fashion reason data length grows . finally , introduce straightforward technique to generate reason data arbitrary length , show synthesize data be effective train reason model . fine tune language model dataset , present model , , which achieve remarkable performance only training sample , achieve % accuracy math , % gpqa outperform . model , code , dataset be open sourced , available http url ."
https://doi.org/10.48550/arXiv.2503.18063,"Pieyi Zhang, Richong Zhang, Zhijie Nie",CL,23/03/2025,"dynamic task vector group efficient multi task prompt tuning multi task prompt tune utilizes multiple high resource source task to improve performance low source target task . exist approach transfer soft prompt train combine source task single high similar source task one time only . however , find optimal transfer performance often come combination source task , which be one . far , find similarity source target task also change dynamically fine tuning transfer , make similarity calculation initiation stage inadequate . to address issue , propose method call dynamic task vector grouping ( dtvg ) , whose core idea contain ( ) measure task similarity task vector instead soft prompt , ( ) group optimal source task combination base two metric : { target similarity } { knowledge consistency } ; ( ) dynamically update combination iteration step . extensive experiment nlp datasets different setting demonstrate dtvg effectively group similar source task reduce negative transfer , achieve start of art performance ."
https://doi.org/10.48550/arXiv.2503.18062,"Anh Duc Nguyen, Hieu Minh Phi, Anh Viet Ngo, Long Hai Trieu, Thai Phuong Nguyen",CL,23/03/2025,"investigate recent large language model vietnamese machine reading comprehension large language model ( llm ) have show remarkable proficiency machine reading comprehension ( mrc ) task ; however , effectiveness low resource language vietnamese remains largely unexplored . paper , fine tune evaluate two state of the art llm : llama ( parameter ) gemma ( parameter ) , vimmrc , vietnamese mrc dataset . utilize quantized low rank adaptation ( qlora ) , efficiently fine tune model compare performance powerful llm based baseline . fine tuned model be small , outperform traditional bert based approach large model . demonstrate effectiveness fine tuning process , showcasing how modern llm can surpass capability old model bert still be suitable deployment resource constrained environment . intensive analysis , explore various aspect model performance , provide valuable insight adapt llm low resource language vietnamese . study contribute to advancement natural language processing low resource language , make fine tuned model publicly available : http url ."
https://doi.org/10.48550/arXiv.2503.18008,"Kyuyoung Kim, Jinwoo Shin, Jaehyung Kim",CL,23/03/2025,"personalize language model privacy preserving evolutionary model merge personalization large language model ( llm ) seek to tailor model to individual user user group preference . prompt based method augment query user preference information , training based method directly encode preference model parameter more effective personalization . achieve success personalize llm , prior method often fail to directly optimize task specific metric lack explicit privacy preservation mechanism . to address limitation , propose privacy preserving model merge evolutionary algorithm ( prime ) , novel approach to personalization employ gradient free method to directly optimize task specific metric preserve user privacy . incorporate privacy preservation optimization , prime produce personalized module that effectively capture target user preference minimize privacy risk user share private information . experiment lamp benchmark show prime outperforms prompt based training based method , achieve up to % performance improvement prior art . further analysis show prime achieve significantly well privacy utility trade off , highlight potential evolutionary approach privacy preserving llm personalization ."
https://doi.org/10.48550/arXiv.2503.17994,"Xin Xue, Haoyi Zhou, Tianyu Chen, Shuai Zhang, Yizhou Long, Jianxin Li",CL,23/03/2025,"instruct architecture search spatial temporal sequence forecasting llm spatial temporal sequence forecasting ( stsf ) be long standing research problem widespread real world application . neural architecture search ( nas ) , which automate neural network design , have be show effective tackle stsf problem . however , exist na method stsf focus generate architecture time consuming data driven fashion , which heavily limit ability to use background knowledge explore complicate search trajectory . large language model ( llm ) have show remarkable ability decision making comprehensive internal world knowledge , how could benefit na stsf remain unexplored . paper , propose novel nas method stsf base llm . instead directly generate architecture llm , inspire llm capability multi level enhancement mechanism . specifically , step level , decompose generation task decision step powerful prompt engineering inspire llm to serve instructor architecture search base internal knowledge . instance level , utilize one step tuning framework to quickly evaluate architecture instance memory bank to cumulate knowledge to improve llm search ability . task level , propose two stage architecture search , balance exploration stage optimization stage , to reduce possibility be trap local optimum . extensive experimental result demonstrate method can achieve competitive effectiveness superior efficiency exist nas method stsf ."
https://doi.org/10.48550/arXiv.2503.17965,"Beining Xu, Arkaitz Zubiaga",CL,23/03/2025,"understand effect rlhf quality detectability llm generated text large language model ( llm ) have demonstrate exceptional performance range downstream nlp task generate text that closely resemble human write . however , ease achieve similarity raise concern potential malicious us scale bad actor , llm generated text become increasingly difficult to discern human text . detection method have be develop to address issue , bad actor can far manipulate llm generated text to make less detectable . work , study how further edit text reinforcement learn human feedback ( rlhf ) , which align model output human preference , affect ( ) quality generated text two task , ( b ) performance llm generated text detector , look training based zero shot detection method . rlhf improve quality llm generated text , find also tend to produce more detectable , lengthy , repetitive output . additionally , observe training based detector be vulnerable to short text to texts incorporate code , zero shot detector exhibit great robustness ."
https://doi.org/10.48550/arXiv.2503.17963,"Guijin Son, Hyunwoo Ko, Haneral Jung, Chami Hwang",CL,23/03/2025,"won : establishing best practice korean financial nlp work , present first open leaderboard evaluate korean large language model focus finance . operate about eight week , leaderboard evaluate submission closed benchmark cover five mcqa category : finance accounting , stock price prediction , domestic company analysis , financial market , financial agent task one open ended qa task . building insight evaluation , release open instruction dataset instance summarize widely used training strategy observe top performing model . finally , introduce win , fully open transparent llm build use best practice . hope contribution help advance development good safer financial llm korean other language ."
https://doi.org/10.48550/arXiv.2503.17952,"Divyansh Singh, Manuel Nunez Martinez, Bonnie J. Dorr, Sonja Schmer Galunder",CL,23/03/2025,"slide : slide localize information document extraction construct accurate knowledge graph long text low resource language be challenge , large language model ( llm ) experience degrade performance long input chunk . problem be amplify low resource setting where data scarcity hinders accurate entity relationship extraction . contextual retrieval method , improve retrieval accuracy , struggle long document . truncate critical information text exceed maximum context length llm , significantly limit knowledge graph construction . introduce slide ( slide localize information document extraction ) , chunk method that process long document generate local context overlap window . slide ensure essential contextual information be retain , enhance knowledge graph extraction document exceed llm context limit . significantly improve graphrag performance , achieve % increase entity extraction % improvement relationship extraction english . afrikaans , low resource language , slide achieve % increase entity extraction % improvement relationship extraction . furthermore , improve state of the art question answering metric such comprehensiveness , diversity empowerment , demonstrate effectiveness multilingual resource constrained setting ."
https://doi.org/10.48550/arXiv.2503.17936,"Riya Naik, Ashwin Srinivasan, Estrid He, Swati Agarwal",CL,23/03/2025,"empirical study role incompleteness ambiguity interaction large language model natural language medium human computer interaction have long be anticipate , have be undergo sea change advent large language model ( llm ) startle capacity processing generating language . many now treat llm modern day oracle , ask almost kind question . delphic predecessor , consult llm do not have to be single turn activity ( ask question , receive answer , leave ) ; also pythia be widely acknowledge answer llm can be improve additional context . paper , aim to study when need multi turn interaction llm to successfully get question answer ; conclude question be unanswerable . present neural symbolic framework that model interaction human llm agent . propose framework , define incompleteness ambiguity question property deducible message exchange interaction , provide result benchmark problem , which answer correctness be show to depend not question demonstrate presence incompleteness ambiguity ( accord to property identify ) . result show multi turn interaction be usually require datasets which have high proportion incompleteness ambiguous question ; increase interaction length have effect reduce incompleteness ambiguity . result also suggest measure incompleteness ambiguity can be useful tool characterise interaction llm question answeringproblems"
https://doi.org/10.48550/arXiv.2503.17933,"Justice Ou, Tinglin Huang, Yilun Zhao, Ziyang Yu, Peiqing Lu, Rex Ying",CL,23/03/2025,"experience retrieval augmentation electronic health record enable accurate discharge qa to improve reliability large language model ( llm ) clinical application , retrieval augmented generation ( rag ) be extensively apply to provide factual medical knowledge . however , general medical knowledge open ended datasets , clinical case based knowledge be also critical effective medical reasoning , provide context ground real world patient experience . motivate , propose experience retrieval augmentation - exprag framework base electronic health record ( ehr ) , aim to offer relevant context other patient ' discharge report . exprag performs retrieval coarse to fine process , utilize ehr based report ranker to efficiently identify similar patient , follow experience retriever to extract task relevant content enhanced medical reasoning . to evaluate exprag , introduce dischargeqa , clinical qa dataset discharge related question diagnosis , medication , instruction task . problem be generate use ehr data to ensure realistic challenging scenario . experimental result demonstrate exprag consistently outperform text based ranker , achieve average relative improvement % , highlight importance case based knowledge medical reasoning ."
https://doi.org/10.48550/arXiv.2503.17932,"Xunguang Wang, Wenxuan Wang, Zhenlan Ji, Zongjie Li, Pingchuan Ma, Daoyuan Wu, Shuai Wang",CL,23/03/2025,"stshield : single token sentinel real time jailbreak detection large language model large language model ( llm ) have become increasingly vulnerable to jailbreak attack that circumvent safety mechanism . exist defense method suffer adaptive attack require computationally expensive auxiliary model , present stshield , lightweight framework real time jailbroken judgement . stshield introduce novel single token sentinel mechanism that append binary safety indicator to model response sequence , leverage llm own alignment capability detection . framework combine supervise fine tuning normal prompt adversarial train use embedding space perturbation , achieve robust detection preserve model utility . extensive experiment demonstrate stshield successfully defend various jailbreak attack , maintain model performance legitimate query . compare to exist approach , stshield achieves superior defense performance minimal computational overhead , make practical solution real world llm deployment ."
https://doi.org/10.48550/arXiv.2503.17922,"Youhui Zuo, Sibo Wei, Chen Zhang, Zhuorui Liu, Wenpeng Lu, Dawei Song",CL,23/03/2025,"windowkv : task adaptive group wise kv cache window selection efficient llm inference advancement long context inference capability large language model ( llm ) , kv cache have become one foundational component . however , substantial gpu memory consumption make kv cache compression key technique enable efficient llm inference industrial scenario . recent study have focus optimize memory occupy kv cache , overlook two critical factor : preserve semantic coherence consider task specific characteristic compression . to address limitation , propose novel task adaptive kv cache window selection method , windowkv . windowkv dynamically select local semantic window consist consecutive token , accord to task specific characteristic , ensure retain kv cache capture continuous , essential context . additionally , introduce intra group layer kv cache index share strategy to reduce computational overhead , achieve balance performance efficiency . rigorously evaluate windowkv longbench benchmark , result demonstrate maintain performance comparable to full kv cache retention use only % original kv cache , significantly reduce memory requirement . furthermore , method also achieve state of the art result needle in a haystack evaluation , highlight effectiveness robustness ."
https://doi.org/10.48550/arXiv.2503.17900,"Hsin-Ling Hsu, Cong-Tinh Dao, Luning Wang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Chun-Chieh Liao, Pengfei Hu, Xiaoxue Han, Chih-Ho Hsu, Dongsheng Luo, Wen-Chih Peng, Feng Liu, Fang-Ming Hung, Chenwei Wu",CL,23/03/2025,"medplan : two stage rag based system personalized medical plan generation recent success apply large language model ( llm ) to electronic health record ( ehr ) , most system focus primarily assessment rather treatment planning . identify three critical limitation current approach : generate treatment plan single pas rather follow sequential reasoning process use clinician ; rarely incorporate patient specific historical context ; fail to effectively distinguish subjective objective clinical information . motivate soap methodology ( subjective , objective , assessment , plan ) , introduce medplan , novel framework that structure llm reason to align real life clinician workflow . approach employ two stage architecture first generate clinical assessment base patient symptom objective data , then formulate structured treatment plan inform assessment enrich patient specific information retrieval augmented generation . comprehensive evaluation demonstrate method significantly outperform baseline approach assessment accuracy treatment plan quality ."
https://doi.org/10.48550/arXiv.2503.17882,"Shengyun Si, Xinpeng Wang, Guangyao Zhai, Nassir Navab, Barbara Plank",CL,22/03/2025,"think refusal : trigger safety reflection llm to mitigate false refusal behavior recent advancement large language model ( llm ) have demonstrate fine tuning human alignment can render llms harmless . practice , such harmlessness behavior be mainly achieve train model to reject harmful request , such explain how to burn down neighbor house , where model appropriately decline to respond . however , approach can inadvertently result false refusal , where model reject benign query well , such tell how to kill python process . work , demonstrate prompt safety reflection generate response can mitigate false refusal behavior . building finding , introduce think before refusal ( tbr ) schema conduct safety aware instruction fine tuning incorporating safety reflection . ablation study pre trained model , show model fine tune safety reflection significantly reduce false refusal behavior maintain safety overall performance compare to fine tuned safety reflection ."
https://doi.org/10.48550/arXiv.2503.17876,"Kaiwen Zuo, Jing Tang, Hanbing Qin, Binli Luo, Ligang He, Shiyan Tang",CL,22/03/2025,"satisfactory medical consultation base terminology enhanced information retrieval emotional in context learning recent advancement large language model ( llm ) have mark significant progress understanding respond to medical inquiry . however , performance still fall short standard set professional consultation . paper introduce novel framework medical consultation , comprise two main module : terminology enhanced information retrieval ( teir ) emotional in context learning ( eicl ) . teir ensures implicit reason utilization inductive knowledge key terminology retrieval , overcome limitation restricted domain knowledge public database . additionally , module feature capability process long context . eicl module aid generate sentence high attribute relevance memorize semantic attribute information unlabelled corpus apply control retrieval required information . furthermore , dataset comprise consultation record be compile china , significantly enhance model capability complex dialogue proactive inquiry initiation . comprehensive experiment demonstrate propose method effectiveness extend context window length exist llm . experimental outcome extensive data validate framework superiority five baseline model term bleu rouge performance metric , substantial lead certain capability . notably , ablation study confirm significance teir eicl component . addition , new framework have potential to significantly improve patient satisfaction real clinical consulting situation ."
https://doi.org/10.48550/arXiv.2503.17860,"Felix Faltings, Wei Wei, Yujia Bao",CL,22/03/2025,"enhance retrieval system inference time logical reasoning traditional retrieval method rely transform user query vector representation retrieve document base cosine similarity embedding space . efficient scalable , approach often fail to handle complex query involve logical construct such negation , conjunction , disjunction . paper , propose novel inference time logical reasoning framework that explicitly incorporate logical reason retrieval process . method extract logical reason structure natural language query then compose individual cosine similarity score to formulate final document score . approach enable retrieval process to handle complex logical reasoning compromise computational efficiency . result synthetic real world benchmark demonstrate propose method consistently outperform traditional retrieval method different model datasets , significantly improve retrieval performance complex query ."
https://doi.org/10.48550/arXiv.2503.17811,"Wenqi Pei, Hailing Xu, Hengyuan Zhao, Shizheng Hou, Han Chen, Zining Zhang, Pingyi Luo, Bingsheng He",CL,22/03/2025,"feather sql : lightweight framework dual model collaboration paradigm small language model natural language to sql ( ) have see significant advancement large language model ( llm ) . however , model often depend closed source system high computational resource , pose challenge data privacy deployment . contrast , small language model ( slms ) struggle task , exhibit poor performance incompatibility exist framework . to address issue , introduce feather sql , new lightweight framework tailor slms . feather sql improves sql executability accuracy ) schema pruning linking , ) multi path multi candidate generation . additionally , introduce model collaboration paradigm , which pair strong general purpose chat model fine tuned sql specialist , combine strong analytical reasoning high precision sql generation . experimental result bird demonstrate feather sql improves performance slms , % boost model fine tuning . propose paradigm raise accuracy ceiling slms to % , highlight effectiveness ."
https://doi.org/10.48550/arXiv.2503.17810,"Farhan Farsi, Parnian Fazel, Sepand Haghighi, Sadra Sabouri, Farzaneh Goshtasb, Nadia Hajipour, Ehsaneddin Asgari, Hossein Sameti",CL,22/03/2025,"parsipy : nlp toolkit historical persian text python study historical language present unique challenge due to complex orthographic system , fragmentary textual evidence , absence standardized digital representation text language . tackle challenge need special nlp digital tool to handle phonetic transcription analyze ancient text . work introduce parsipy , nlp toolkit design to facilitate analysis historical persian language offer module tokenization , lemmatization , part of speech tagging , phoneme to transliteration conversion , word embedding . demonstrate utility toolkit processing parsig ( middle persian ) text , highlight potential expand computational method study historical language . work , contribute to computational philology , offering tool that can be adapt broad study ancient text digital preservation ."
https://doi.org/10.48550/arXiv.2503.17799,"Yuhang Jiang, Ramakanth Kavuluru",CL,22/03/2025,"relation extraction instance adapted predicate description relation extraction ( re ) be standard information extraction task play major role downstream application such knowledge discovery question answer . decoder only large language model be excel generative task , small encoder model be still go to architecture re . paper , revisit fine tuning such small model use novel dual encoder architecture joint contrastive cross entropy loss . previous method that employ fixed linear layer predicate representation , approach use second encoder to compute instance specific predicate representation infuse real entity span correspond input instance . conduct experiment two biomedical re datasets two general domain datasets . approach achieve score improvement range % to % state of the art method simple elegant formulation . ablation study justify importance various component build propose architecture ."
https://doi.org/10.48550/arXiv.2503.17755,"Sharan Maiya, Yinhong Liu, Ramit Debnath, Anna Korhonen",CL,22/03/2025,"improve preference extraction llm identify latent knowledge classify probe large language model ( llm ) be often use automated judge to evaluate text , effectiveness can be hinder various unintentional bias . propose use linear classify probe , train leverage difference contrast pair prompt , to directly access llm ' latent knowledge extract more accurate preference . extensive experiment use model vary size four different family six diverse datasets assess text quality evaluation common sense reasoning , demonstrate supervise unsupervised probing approach consistently outperform traditional generation based judgement maintain similar computational cost . probe generalise domain shift can even outperform finetuned evaluator same training data size . result suggest linear probe offer accurate , robust computationally efficient approach llm as judge task provide interpretable insight how model encode judgement relevant knowledge . data code will be openly release future ."
https://doi.org/10.48550/arXiv.2503.17753,"Hojun Cho, Donghu Kim, Soyoung Yang, Chan Lee, Hunjoo Lee, Jaegul Choo",CL,22/03/2025,"build resource constrained language agent : korean case study chemical toxicity information language agent power large language model ( llm ) face significant deployment challenge resource constrained environment , particularly specialized domain less common language . paper present tox chat , korean chemical toxicity information agent devise limitation . propose two key innovation : context efficient architecture that reduce token consumption hierarchical section search , scenario based dialogue generation methodology that effectively distill tool using capability large model . experimental evaluation demonstrate fine tuned parameter model substantially outperform untuned model baseline approach , term db faithfulness preference . work offer valuable insight researcher develop domain specific language agent practical constraint ."
https://doi.org/10.48550/arXiv.2503.17739,"Chatrine Qwaider, Bashar Alhafni, Kirill Chirkunov, Nizar Habash, Ted Briscoe",CL,22/03/2025,"enhance arabic automate essay score synthetic data error injection automate essay scoring ( aes ) play crucial role assess language learner ' write quality , reduce grade workload , provide real time feedback . arabic aes system be particularly challenge lack annotated essay datasets . paper present novel framework leverage large language model ( llm ) transformer to generate synthetic arabic essay datasets aes . prompt llm to generate essay cefr proficiency level introduce control error injection use fine tuned standard arabic bert model error type prediction . approach produce realistic human like essay , contribute dataset annotated essay . additionally , develop bert based auto marking system accurate scalable arabic essay evaluation . experimental result demonstrate effectiveness framework improve arabic aes performance ."
https://doi.org/10.48550/arXiv.2503.17684,"Dhruv Sahnan, David Corney, Irene Larraz, Giovanni Zagni, Ruben Miguez, Zhuohan Xie, Iryna Gurevych, Elizabeth Churchill, Tanmoy Chakraborty, Preslav Nakov",CL,22/03/2025,"can llms automate fact checking article writing ? automatic fact checking aim to support professional fact checker offer tool that can help speed up manual fact checking . yet , exist framework fail to address key step produce output suitable broad dissemination to general public : human fact checker communicate finding fact checking article , automate system typically produce little justification assessment . here , aim to bridge gap . argue need to extend typical automatic fact checking pipeline automatic generation full fact checking article . first identify key desideratum such article series interview expert lead fact checking organization . then develop qraft , llm based agentic framework that mimic write workflow human fact checker . finally , assess practical usefulness qraft human evaluation professional fact checker . evaluation show qraft outperforms several previously propose text generation approach , lag considerably expert written article . hope work will enable further research new important direction ."
https://doi.org/10.48550/arXiv.2503.17662,"Ke Ji, Yixin Lian, Linxu Li, Jingsheng Gao, Weiyuan Li, Bin Dai",CL,22/03/2025,"enhance persona consistency llm ' role playing use persona aware contrastive learning recent year , large language model ( llm ) have achieve progress many dialogue generation task . however , lack emotion fine grained role awareness limit model ability to provide personalized diverse interaction far . current method face high cost collect high quality annotate data scenario such role playing , traditional human alignment method be difficult to deploy due to inherent diversity model behavior role playing scenario . inspire alignment model safety behavior rlhf ( reinforcement learn human feedback ) , paper , revisit model role playing behavior perspective persona alignment propose novel annotation free framework name { { p } } ersona aware { { c } } ontrastive { { l } } earn ( pcl ) to align llm ' behavior role playing , enhance model role consistency . specifically , first design role chain method to encourage model to self question base role characteristic dialogue context to adjust personality consistency . then , further enhance model role playing strategy iterative contrastive learning use role characteristic not . experiment black box white box llm show llm equip pcl significantly outperform vanilla llm automatic evaluation method ( chareval \ & ) human expert evaluation ."
https://doi.org/10.48550/arXiv.2503.17599,"Zheqing Li, Yiying Yang, Jiping Lang, Wenhao Jiang, Yuhang Zhao, Shuang Li, Dingqian Wang, Zhu Lin, Xuanna Li, Yuze Tang, Jiexian Qiu, Xiaolin Lu, Hongji Yu, Shuang Chen, Yuhua Bi, Xiaofei Zeng, Yixian Chen, Junrong Chen, Lin Yao",CL,22/03/2025,"gpbench : comprehensive fine grained benchmark evaluate large language model general practitioner general practitioner ( gps ) serve cornerstone primary healthcare system provide continuous comprehensive medical service . however , due to community oriented nature practice , uneven training resource gap , clinical proficiency gps can vary significantly region healthcare setting . currently , large language model ( llm ) have demonstrate great potential clinical medical application , make promising tool support general practice . however , most exist benchmark evaluation framework focus exam style assessments typically multiple choice question lack comprehensive assessment set that accurately mirror real world scenario encounter gps . to evaluate how effectively llms can make decision daily work gps , design gpbench , which consist test question clinical practice novel evaluation framework . test set include multiple choice question that assess fundamental knowledge general practice , as well realistic , scenario based problem . question be meticulously annotate expert , incorporate rich fine grained information relate to clinical management . propose llm evaluation framework be base competency model general practice , provide comprehensive methodology assess llm performance real world setting . first large model evaluation set target gp decision making scenario , gpbench allow to evaluate current mainstream llm . expert assessment evaluation reveal area such disease staging , complication recognition , treatment detail , medication usage , model exhibit least ten major shortcoming . overall , exist llm be not yet suitable independent use real world gp work scenario human oversight ."
https://doi.org/10.48550/arXiv.2503.17579,"Suet-Ying Lam, Qingcheng Zeng, Jingyi Wu, Rob Voigt",CL,21/03/2025,"leverage human production interpretation asymmetry to test llm cognitive plausibility large language model ( llm ) process language similarly to human have be subject much theoretical practical debate . examine question lens production interpretation distinction find human sentence processing evaluate extent to which instruction tuned llm replicate distinction . use empirically document asymmetry production interpretation human implicit causality verb testbed , find llm do quantitatively qualitatively reflect human like asymmetry production interpretation . demonstrate behavior hold depend model size - large model more likely to reflect human like pattern choice meta linguistic prompt use to elicit behavior ."
https://doi.org/10.48550/arXiv.2503.17523,"Linlu Qiu, Fei Sha, Kelsey Allen, Yoon Kim, Tal Linzen, Sjoerd van Steenkiste",CL,21/03/2025,"bayesian teaching enables probabilistic reasoning large language model artificial intelligence system base large language model ( llm ) be increasingly use agent interact user world . to do so successfully , llm need to construct internal representation world form probabilistic belief representation . to provide user personalized recommendation , example , llm need to gradually infer user preference , course multiple interaction . to evaluate contemporary llm be able to do so , use bayesian inference framework probability theory , which lay out optimal way to update agent belief receive new information . first show llm do not update belief expect bayesian framework , consequently prediction do not improve as expect more information become available , even less so find be case human . to address issue , teach llm to reason bayesian manner train to mimic prediction optimal bayesian model . find approach not only significantly improve llm performance particular recommendation task be train , also enable generalization to other task . suggest method endow llm broad bayesian reasoning skill . more generally , result indicate llm can learn reason strategy effectively generalize skill to new domain , which part explain llm ' empirical success ."
https://doi.org/10.48550/arXiv.2503.17514,"Ken Ziyu Liu, Christopher A. Choquette-Choo, Matthew Jagielski, Peter Kairouz, Sanmi Koyejo, Percy Liang, Nicolas Papernot",CL,21/03/2025,"language model may verbatim complete textthey be not explicitly train important question today be give text be use to train large language model ( llm ) . { completion } test be often employ : check llm complete sufficiently complex text . , however , require ground truth definition membership ; most commonly , be define member base $ n $  gram overlap target text text dataset . work , demonstrate $ n $  gram base membership definition can be effectively game . study scenario where sequence be { non member } give $ n $ find completion test still succeed . find many natural case phenomenon retrain llm scratch remove training sample that be complete ; case include exact duplicate , near duplicate , even short overlap . showcase be difficult to find single viable choice $ n $ membership definition . use insight , design adversarial datasets that can cause give target sequence to be complete contain , reasonable choice $ n $ . finding highlight inadequacy $ n $  gram membership , suggest membership definition fail to account auxiliary information available to training algorithm ."
https://doi.org/10.48550/arXiv.2503.17509,"Joseph Gatto, Parker Seegmiller, Timothy Burdick, Inas S. Khayal, Sarah DeLozier, Sarah M. Preum",CL,21/03/2025,"follow up question generation enhanced patient provider conversation follow up question generation be essential feature dialogue system can reduce conversational ambiguity enhance modeling complex interaction . conversational context often pose core nlp challenge such ( i ) extract relevant information bury fragmented data source , ( ii ) model parallel thought process . two challenge occur frequently medical dialogue doctor ask question base not only patient utterance also prior ehr data current diagnostic hypothesis . ask medical question asynchronous conversation compound issue doctor can only rely static ehr information to motivate follow up challenge , introduce followupq , novel framework enhance asynchronous medical conversation . followupq be multi agent framework that process patient message ehr data to generate personalized follow up question , clarify patient reported medical condition . followupq reduce requisite provider follow up communication % . also improve performance % % real synthetic data , respectively . also release first public dataset asynchronous medical message link ehr data alongside follow up question write clinical expert wider nlp research community ."
https://doi.org/10.48550/arXiv.2503.17489,"Shu Pu, Yaochen Wang, Dongping Chen, Yuhang Chen, Guohao Wang, Qi Qin, Zhongyi Zhang, Zhiyuan Zhang, Zetong Zhou, Shuang Gong, Yi Gui, Yao Wan, Philip S. Yu",CL,21/03/2025,"judge anything : mllm judge modality evaluate generative foundation model open ended multimodal understanding ( mmu ) generation ( mmg ) task diverse modality ( , image , audio , video ) pose significant challenge due to complexity cross modal interaction . to end , idea utilize multimodal llm ( mllms ) automate judge have emerge , encouraging result assess vision language understanding task . move far , paper extend mllm as a judge modality to unified manner introduce two benchmark , taskanything judgeanything , to respectively evaluate overall performance judge capability mllms any to any modality task . specifically , taskanything evaluate mmu mmg capability any to any modality category , employ query curated well established benchmark . furthermore , judgeanything evaluate judging capability advanced ( , ) perspective pair comparison score evaluation , provide standardized testbed that incorporate human judgment detailed rubric . extensive experiment reveal mllms show promise assess mmu ( , achieve average % pair comparison set % score evaluation set ) , encounter significant challenge mmg task ( , average only % pair comparison set % score evaluation set ) , expose cross modality bias hallucination issue . to address , present omniarena , automated platform evaluate omni model multimodal reward model . work highlight need fair evaluation protocol strong alignment human preference . source code dataset be publicly available : http url ."
https://doi.org/10.48550/arXiv.2503.17485,"Lama Ayash, Hassan Alhuzali, Ashwag Alasmari, Sultan Aloufi",CL,21/03/2025,"saudiculture : benchmark evaluate large language model cultural competence saudi arabia large language model ( llm ) have demonstrate remarkable capability natural language processing ; however , often struggle to accurately capture reflect cultural nuance . research address challenge focus saudi arabia , country characterize diverse dialect rich cultural tradition . introduce saudiculture , novel benchmark design to evaluate cultural competence llm distinct geographical cultural context saudi arabia . saudiculture be comprehensive dataset question cover five major geographical region , such west , east , south , north , center , general question applicable region . dataset encompass broad spectrum cultural domain , include food , clothing , entertainment , celebration , craft . to ensure rigorous evaluation , saudiculture include question vary complexity , such open ended , single choice , multiple choice format , require multiple correct answer . additionally , dataset distinguishes common cultural knowledge specialized regional aspect . conduct extensive evaluation five llm , such , llama , fanar , jais , acegpt , analyze performance different question type cultural context . finding reveal model experience significant performance decline when face highly specialize region specific question , particularly require multiple correct response . additionally , certain cultural category be more easily identifiable others , far highlight inconsistency llms cultural understanding . result emphasize importance incorporate region specific knowledge llms training to enhance cultural competence ."
https://doi.org/10.48550/arXiv.2503.17460,"Reem Gody, Mahmoud Goudy, Ahmed Y. Tawfik",CL,21/03/2025,"convogen : enhance conversational ai synthetic data : multi agent approach paper , present convogen : innovative framework generate synthetic conversational data use multi agent system . method leverage few shot learning introduces iterative sample dynamically updated few shot hub to create diverse realistic conversational scenario . generate data have numerous application , include training evaluate conversational ai model , augment exist datasets task conversational intent classification conversation summarization . experiment demonstrate effectiveness method produce high quality diverse synthetic conversational data , highlight potential to enhance development evaluation conversational ai system ."
https://doi.org/10.48550/arXiv.2503.17456,"Soumen Kumar Mondal, Sayambhu Sen, Abhishek Singhania, Preethi Jyothi",CL,21/03/2025,"language specific neuron do not facilitate cross lingual transfer multilingual large language model ( llm ) aim towards robust natural language understanding diverse language , performance significantly degrade low resource language . work explore exist technique to identify language specific neuron can be leverage to enhance cross lingual task performance lowresource language . conduct detailed experiment cover exist language specific neuron identification technique ( such language activation probability entropy activation probability based thresholding ) neuron specific lora fine tune model llama mistral nemo . find such neuron specific intervention be insufficient to yield cross lingual improvement downstream task ( xnli , xquad ) lowresource language . study highlight challenge achieve cross lingual generalization provide critical insight multilingual llm ."
https://doi.org/10.48550/arXiv.2503.17425,"Veysel Kocaman, Yigit Gul, M. Aytug Kaya, Hasham Ul Haq, Mehmet Butgul, Cabir Celik, David Talby",CL,21/03/2025,"negation detection : comprehensive assertion detection model clinical nlp assertion status detection be critical yet often overlooked component clinical nlp , essential accurately attribute extract medical fact . past study have narrowly focus negation detection , lead to underperforming commercial solution such aws medical comprehend , azure ai text analytics , due to limited domain adaptation . to address gap , develop state of the art assertion detection model , include fine tuned llm , transformer based classifier , few shot classifier , deep learning ( dl ) approach . evaluate model cloud based commercial api solution , legacy rule based negex approach , . fine tuned llm achieve high overall accuracy ( ) , outperform ( ) commercial apis notable margin , particularly excel present ( % ) , absent ( % ) , hypothetical ( % ) assertion . dl based model surpass commercial solution conditional ( % ) associated with someone else ( % ) category , few shot classifier offer lightweight yet highly competitive alternative ( ) , make ideal resource constrained environment . integrate spark nlp , model consistently outperform black box commercial solution enable scalable inference seamless integration medical ner , relation extraction , terminology resolution . result reinforce importance domain adapted , transparent , customizable clinical nlp solution general purpose llm proprietary apis ."
https://doi.org/10.48550/arXiv.2503.17407,"Jiaheng Liu, Dawei Zhu, Zhiqi Bai, Yancheng He, Huanxuan Liao, Haoran Que, Zekun Wang, Chenchen Zhang, Ge Zhang, Jiebin Zhang, Yuanxing Zhang, Zhuo Chen, Hangyu Guo, Shilong Li, Ziqiang Liu, Yong Shan, Yifan Song, Jiayi Tian, Wenhao Wu, Zhejian Zhou, Ruijie Zhu, Junlan Feng, Yang Gao, Shizhu He, Zhoujun Li, Tianyu Liu, Fanyu Meng, Wenbo Su, Yingshui Tan, Zili Wang, Jian Yang, Wei Ye, Bo Zheng, Wangchunshu Zhou, Wenhao Huang, Sujian Li, Zhaoxiang Zhang",CL,20/03/2025,"comprehensive survey long context language modeling efficient processing long context have be persistent pursuit natural language processing . grow number long document , dialogue , other textual data , be important to develop long context language model ( lclms ) that can process analyze extensive input effective efficient way . paper , present comprehensive survey recent advance long context modeling large language model . survey be structure three key aspect : how to obtain effective efficient lclms , how to train deploy lclms efficiently , how to evaluate analyze lclms comprehensively . first aspect , discuss data strategy , architectural design , workflow approach orient long context processing . second aspect , provide detailed examination infrastructure require lclm training inference . third aspect , present evaluation paradigm long context comprehension long form generation , as well behavioral analysis mechanism interpretability lclms . three key aspect , thoroughly explore diverse application scenario where exist lclms have be deploy outline promising future development direction . survey provide up to date review literature long context llm , which wish to serve valuable resource researcher engineer . associated github repository collect late paper repos be available : { http url } { [ rgb ] { } { lclm horizon } } ."
https://doi.org/10.48550/arXiv.2503.17403,"Azim Akhtarshenas, Afshin Dini, Navid Ayoobi",CL,19/03/2025,"chatgpt silent everywhere helper : survey large language model large language model ( llm ) have revo lutionized natural language process natural language processing ( nlp ) , generative pre trained transformer ( chatgpt ) stand out notable exampledue to advanced capability widespread application . survey provide comprehensive analysis chatgpt , explore architecture , training process , functionality . examine integration various domain industry such customer service , education , healthcare , entertainment . comparative analysis other llm highlight chatgpt unique feature performance metric . regard benchmark , paper examine chatgpt comparative performance other llm discuss potential risk such misinformation , bias , data privacy concern . additionally , offer number figure table that outline backdrop discussion , main idea article , numerous llm model , thorough list datasets use pre training , fine tuning , evaluation , as well particular llm application pertinent reference . finally , identify future research direction technological advancement , underscore evolve landscape llm profound impact artificial intelligence artificial intelligence ( ai ) society ."
https://doi.org/10.48550/arXiv.2503.18941,"Hongru Cai, Yongqi Li, Ruifeng Yuan, Wenjie Wang, Zhen Zhang, Wenjie Li, Tat-Seng Chua",CL,24/03/2025,"explore training inference scale law generative retrieval generative retrieval have emerge novel paradigm leverage large language model ( llm ) to autoregressively generate document identifier . promising , mechanism that underpin performance scalability remain largely unclear . conduct systematic investigation training inference scale law generative retrieval , explore how model size , train data scale , inference time compute jointly influence retrieval performance . to address lack suitable metric , propose novel evaluation measure inspire contrastive entropy generation loss , provide continuous performance signal that enable robust comparison diverse generative retrieval method . experiment show n gram based method demonstrate strong alignment training inference scaling law , especially when pair large llm . furthermore , increase inference computation yield substantial performance gain , reveal generative retrieval can significantly benefit high compute budget inference . setting , llama model consistently outperform model , suggest particular advantage large decoder only model generative retrieval . take together , finding underscore model size , data availability , inference computation interact to unlock full potential generative retrieval , offer new insight design optimizing future system ."
https://doi.org/10.48550/arXiv.2503.18892,"Weihao Zeng, Yuzhen Huang, Qian Liu, Wei Liu, Keqing He, Zejun Ma, Junxian He",CL,24/03/2025,"simplerl zoo : investigating tame zero reinforcement learn open base model wild have show long chain of thought ( cot ) reasoning can naturally emerge simple reinforcement learning ( rl ) framework rule based reward , where training may directly start base models a paradigm refer to zero rl training . most recent effort to reproduce zero rl training have primarily focus model series , which may not be representative find base model already exhibit strong instruction following self reflection ability . work , investigate zero rl train diverse base model , span different family size include , , , , model to . leverage several key design strategies such adjust format reward control query difficulty we achieve substantial improvement reason accuracy response length most setting . however , carefully monitor training dynamic , observe different base model exhibit distinct pattern training . instance , increase response length do not always correlate emergence certain cognitive behavior such verification ( , aha moment ) . notably , observe aha moment first time small model not qwen family . share key design enable successful zero rl training , finding practice . to facilitate further research , open source code , model , analysis tool ."
https://doi.org/10.48550/arXiv.2503.18888,"Zhengcong Yin, Daniel W. Goldberg, Binbin Lin, Bing Zhou, Diya Li, Andong Ma, Ziqian Ming, Heng Cai, Zhe Zhang, Shaohua Wang, Shanzhen Gao, Joey Ying Lee, Xiao Li, Da Huo",CL,24/03/2025,"build next generation geocoding system : systematic review geocoding system be widely use scientific research spatial analysis everyday life location based service . quality geocoded data significantly impact subsequent process application , underscore need next generation system . response to demand , review first examine evolving requirement geocoding input output various scenario system must address . then provide detailed analysis how to construct such system break down key functional component review broad spectrum exist approach , traditional rule based method to advance technique information retrieval , natural language processing , large language model . finally , identify opportunity to improve next generation geocoding system light recent technological advance ."
https://doi.org/10.48550/arXiv.2503.18866,"Yangjun Ruan, Neil Band, Chris J. Maddison, Tatsunori Hashimoto",CL,24/03/2025,"reason to learn latent thought compute scale language model ( lm ) pretraining have outpace growth human written text , lead to concern data will become bottleneck to lm scale . to continue scale pretraining data constrained regime , propose explicitly model infer latent thought that underlie text generation process can significantly improve pretraining data efficiency . intuitively , approach view web text compressed final outcome verbose human thought process latent thought contain important contextual knowledge reason step that be critical to data efficient learning . empirically demonstrate effectiveness approach data constrained continued pretraining math . first show synthetic data approach to infer latent thought significantly improve data efficiency , outperform training same amount raw data ( % $ $ % math ) . furthermore , demonstrate latent think inference strong teacher , where lm bootstrap own performance use em algorithm to iteratively improve capability trained lm quality thought augmented pretraining data . show lm can bootstrap performance least three iteration significantly outperform baseline train raw data , increase gain additional inference compute when perform e step . gain inference scaling em iteration suggest new opportunity scale data constrained pretraining ."
https://doi.org/10.48550/arXiv.2503.18825,"Sara Fish, Julia Shephard, Minkai Li, Ran I. Shorrer, Yannai A. Gonczarowski",CL,24/03/2025,"econevals : benchmark litmus test llm agent unknown environment develop benchmark llm agent that act , learn , strategize unknown environment , specification which llm agent must learn time deliberate exploration . benchmark consist decision making task derive key problem economics . to forestall saturation , benchmark task be synthetically generate scalable difficulty level . additionally , propose litmus test , new kind quantitative measure llm llm agent . benchmark , litmus test quantify difference character , value , tendency llm llm agent , consider behavior when face tradeoff ( , efficiency versus equality ) where there be objectively right wrong behavior . overall , benchmark litmus test assess ability tendency llm agent tackle complex economic problem diverse setting span procurement , scheduling , task allocation , pricing application that should grow importance such agent be far integrate economy ."
https://doi.org/10.48550/arXiv.2503.18792,"Jingwen Cheng, Kshitish Ghate, Wenyue Hua, William Yang Wang, Hong Shen, Fei Fang",CL,24/03/2025,"realm : dataset real world llm use case large language model , such gpt series , have drive significant industrial application , lead to economic societal transformation . however , comprehensive understanding real world application remain limited . to address , introduce realm , dataset llm use case collect reddit news article . realm capture two key dimension : diverse application llm demographic user . categorize llm application explore how user ' occupation relate to type application use . integrate real world data , realm offer insight llm adoption different domain , provide foundation future research evolving societal role . dedicated dashboard http url present data ."
https://doi.org/10.48550/arXiv.2503.18773,"Dayou Du, Shijie Cao, Jianyi Cheng, Ting Cao, Mao Yang",CL,24/03/2025,"bitdecoding : unlocking tensor core long context llm decode low bit kv cache grow adoption long context large language model ( llm ) have introduce significant memory computational challenge autoregressive decoding due to expand key value ( kv ) cache . kv cache quantization have emerge promising solution , prior work show even quantization can maintain model accuracy reduce memory cost . however , benefit , preliminary implementation low bit kv cache struggle to deliver expect speedup due to quantization dequantization overhead lack tensor core utilization . work , propose bitdecoding , gpu optimized framework that unlock tensor core efficient decode low bit kv cache . efficiently leverage tensor core low bit kv cache be challenge due to dynamic nature kv cache generation decode step . bitdecoding address challenge tensor cores centric bitfusion scheme that ensure data layout compatibility to enable high utilization tensor core . additionally , bitdecoding incorporate warp efficient parallel decode kernel fine grained asynchronous pipeline , minimize dequantization overhead improve computational efficiency . experiment show bitdecoding achieve to speedup rtx , , , compare to . also outperform state of the art low bit kv cache implementation ( qserve ) to . sequence length , bitdecoding reduces single batch decode latency , demonstrate effectiveness long context generation scenario . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18680,"Danrui Li, Yichao Shi, Yaluo Wang, Ziying Shi, Mubbasir Kapadia",CL,24/03/2025,"archseek : retrieve architectural case study use vision language model efficiently search relevant case study be critical architectural design , designer rely precedent example to guide inspire ongoing project . however , traditional text based search tool struggle to capture inherently visual complex nature architectural knowledge , often lead to time consuming imprecise exploration . paper introduce archseek , innovative case study search system recommendation capability , tailor architecture design professional . power visual understanding capability vision language model cross modal embeddings , enable text image query fine grained control , interaction based design case recommendation . offer architects more efficient , personalized way to discover design inspiration , potential application other visually drive design field . source code be available http url ."
https://doi.org/10.48550/arXiv.2503.18666,"Haoyu Wang, Christopher M. Poskitt, Jun Sun",CL,24/03/2025,"agentspec : customizable runtime enforcement safe reliable llm agent agent build llm be increasingly deploy diverse domain , automate complex decision making task execution . however , autonomy introduces safety risk , include security vulnerability , legal violation , unintended harmful action . exist mitigation method , such model based safeguard early enforcement strategy , fall short robustness , interpretability , adaptability . to address challenge , propose agentspec , lightweight domain specific language specify enforce runtime constraint llm agent . agentspec , user define structure rule that incorporate trigger , predicate , enforcement mechanism , ensure agent operate predefined safety boundary . implement agentspec multiple domain , include code execution , embodied agent , autonomous driving , demonstrate adaptability effectiveness . evaluation show agentspec successfully prevent unsafe execution % code agent case , eliminate hazardous action embodied agent task , enforce % compliance autonomous vehicle ( av ) . strong safety guarantee , agentspec remain computationally lightweight , overhead millisecond . combine interpretability , modularity , efficiency , agentspec provide practical scalable solution enforce llm agent safety diverse application . also automate generation rule use llm assess effectiveness . evaluation show rule generate openai achieve precision % recall % embodied agent , successfully identify % risky code , prevent av break law scenario ."
https://doi.org/10.48550/arXiv.2503.18570,"Tilahun Yeshambel, Moncef Garouani, Serge Molina, Josiane Mothe",CL,24/03/2025,"dense retrieval low resource language case amharic language paper report difficulty result when use dense retriever amharic , one low resource language speak million population . effort put difficulty face university addis ababa amharic information retrieval will be develop presentation ."
https://doi.org/10.48550/arXiv.2503.18565,"Abdoul Majid O. Thiombiano, Brahim Hnich, Ali Ben Mrad, Mohamed Wiem Mkaouer",CL,24/03/2025,"distil xlstm : learning attention mechanism recurrent structure current era natural language processing ( nlp ) be dominate transformer model . however , novel architecture rely recurrent mechanism , such xlstm mamba , have be propose alternative to attention based model . computation be do differently attention mechanism mechanism , recurrent model yield good result sometimes even outperform state of the art attention based model . work , propose distil xlstm , xlstm based small language model ( slm ) train distil knowledge large language model ( llm ) that show promise result be compute scale efficient . distil xlstm focus approximate transformer based model attention parametrization use recurrent sequence mix component show good result minimal training ."
https://doi.org/10.48550/arXiv.2503.18556,"Bin Li, Dehong Gao, Yeyuan Wang, Linbo Jin, Shanqing Yu, Xiaoyan Cai, Libin Yang",CL,24/03/2025,"instruction aligned visual attention mitigate hallucination large vision language model significant success large vision language model ( lvlms ) , model still suffer hallucination when describe image , generate answer that include non existent object . be report model tend to over focus certain irrelevant image token that do not contain critical information answer question distort output . to address , propose instruction aligned visual attention ( iava ) approach , which identify irrelevant token compare change attention weight two different instruction . apply contrastive decoding , dynamically adjust logits generate original image token irrelevant image token , reduce model over attention to irrelevant information . experimental result demonstrate iava consistently outperform exist decode technique benchmark such mme , pope , textvqa mitigate object hallucination . iava approach be available online http url ."
https://doi.org/10.48550/arXiv.2503.18494,"Hao-Yuan Chen, Cheng-Pong Huang, Jui-Ming Yao",CL,24/03/2025,"verbal process supervision elicit well cod agent emergence large language model application ai agent have significantly advance state of the art code generation benchmark , transform modern software engineering task . however , even test time computed reasoning model , system still struggle complex software engineering challenge . work introduce cura , code understanding reason agent system enhance verbal process supervision ( vps ) , achieve % improvement baseline model challenge benchmark bigcodebench . furthermore , cura , when pair model vps technique , attain state of the art performance . work represent step forward integrate reasoning driven architecture llm based code generation , enable agentic reasoning language model to solve complex software engineering task ."
https://doi.org/10.48550/arXiv.2503.18492,"Jungjae Lee, Dongjae Lee, Chihun Choi, Youngmin Im, Jaeyoung Wi, Kihong Heo, Sangeun Oh, Sunjae Lee, Insik Shin",CL,24/03/2025,"safeguard mobile gui agent logic based action verification large foundation model ( lfms ) have unlock new possibility human computer interaction , particularly rise mobile graphical user interface ( gui ) agents capable interpret gui . agent promise to revolutionize mobile compute allow user to automate complex mobile task simple natural language instruction . however , inherent probabilistic nature lfms , couple ambiguity context dependence mobile task , make lfm based automation unreliable prone to error . to address critical challenge , introduce verisafe agent ( vsa ) : formal verification system that serve logically ground safeguard mobile gui agent . vsa be design to deterministically ensure agent action strictly align user intent conduct action . core , vsa introduces novel autoformalization technique that translate natural language user instruction formally verifiable specification , express domain specific language ( dsl ) . enable runtime , rule based verification , allow vsa to detect prevent erroneous action execute action , either provide corrective feedback halt unsafe behavior . to best knowledge , vsa be first attempt to bring rigor formal verification to gui agent . effectively bridge gap lfm driven automation formal software verification . implement vsa use off the shelf llm service ( ) evaluate performance user instruction widely use mobile apps . result demonstrate vsa achieve % % accuracy verify agent action , represent significant % % improvement exist llm based verification method , consequently increase gui agent task completion rate % % ."
https://doi.org/10.48550/arXiv.2503.18484,"Junyuan Gao, Jiahe Song, Jiang Wu, Runchuan Zhu, Guanlin Shen, Shasha Wang, Xingjian Wei, Haote Yang, Songyang Zhang, Weijia Li, Bin Wang, Dahua Lin, Lijun Wu, Conghui He",CL,24/03/2025,": parallel multilingual multi modal multi task benchmark large vision language model exist multilingual benchmark large vision language model ( lvlms ) suffer limitation include language specific content bias , disjoint multimodal input format , lack safety evaluation . to address gap , propose , first parallel multilingual multi modal multi task benchmark lvlms . feature parallel corpus design language , enable fair accurate cross lingual comparison . include vision set where text query be embed image , require lvlms to simultaneously see , read , think , align real world application . additionally , { } bench incorporates safety evaluation , address critical oversight exist multilingual benchmark . use , evaluate mainstream lvlms , reveal significant cross linguistic performance disparity , particularly vision setting , identify ocr capability key determinant imbalance . will release http url ."
https://doi.org/10.48550/arXiv.2503.18476,"Wei Deng, Mengshi Qi, Huadong Ma",CL,24/03/2025,"global local tree search language guide scene generation large vision language model ( vlms ) , such , have achieve remarkable success various field . however , there be few study indoor scene generation vlms . paper consider task planning problem subject to spatial layout common sense constraint . to solve problem vlm , propose new global local tree search algorithm . globally , method place object sequentially explore multiple placement placement process , where problem space be represent tree . to reduce depth tree , decompose scene structure hierarchically , . room level , region level , floor object level , support object level . algorithm independently generate floor object different region support object place different floor object . locally , also decompose sub task , placement object , multiple step . algorithm search tree problem space . to leverage vlm model to produce position object , discretize top down view space dense grid fill cell diverse emojis to make to cell distinct . prompt vlm emoji grid vlm produce reasonable location object describe position name emojis . quantitative qualitative experimental result illustrate approach generate more plausible scene state of the art approach . source code be available http url ."
https://doi.org/10.48550/arXiv.2503.18458,"Luchao Wang, Qian Ren, Kaiming He, Hua Wang, Zhi Chen, Yaohua Tang",CL,24/03/2025,"stablegs : floater free framework gaussian splatting recent year have witness remarkable success gaussian splatting ( ) novel view synthesis , surpass prior differentiable render method quality efficiency . however , training process suffers couple opacity color optimization that frequently converge to local minimum , produce floater artifact that degrade visual fidelity . present stablegs , framework that eliminate floater cross view depth consistency constraint introduce dual opacity g model to decouple geometry material property translucent object . to further enhance reconstruction quality weakly textured region , integrate depth estimation , significantly improve geometric stability . method fundamentally address training instability , outperform exist state of the art method open source datasets ."
https://doi.org/10.48550/arXiv.2503.18435,"Junteng Liu, Weihao Zeng, Xiwen Zhang, Yijun Wang, Zifei Shan, Junxian He",CL,24/03/2025,"perception bottleneck vlms chart understanding chart understand require model to effectively analyze reason numerical data , textual element , complex visual component . observation reveal perception capability exist large vision language model ( lvlms ) constitute critical bottleneck process . study , delve perception bottleneck decompose two component : vision encoder bottleneck , where visual representation may fail to encapsulate correct information , extraction bottleneck , where language model struggle to extract necessary information provide visual representation . comprehensive experiment , find ( ) information embed visual representation be substantially rich what be typically capture linear extractor , such widely use retrieval accuracy metric ; ( ) instruction tune effectively enhance extraction capability lvlms , vision encoder remain critical bottleneck , demand focused attention improvement . therefore , further enhance visual encoder to mitigate vision encoder bottleneck contrastive learning framework . empirical result demonstrate approach significantly mitigate perception bottleneck improve ability lvlms to comprehend chart . code be publicly available http url ."
https://doi.org/10.48550/arXiv.2503.18394,"Kun Li, Xinwei Chen, Tianyou Song, Chengrui Zhou, Zhuoran Liu, Zhenyan Zhang, Jiangjian Guo, Qing Shan",CL,24/03/2025,"solve situation puzzle large language model external reformulation recent year , large language model ( llm ) have show impressive ability to perform arithmetic symbolic reasoning task . however , find llm ( , chatgpt ) can not perform well reason require multiple round dialogue , especially when solve situation puzzle . specifically , llm intend to ask very detailed question focus specific aspect question several round q & . to help llms get above dilemma , propose novel external reformulation methodology , where situation puzzle will be reformulate several round q & when llm raise incorrect guess . experiment show superior performance ( , win rate , number attempt ) method directly use llm solve situation puzzle , highlight potential strategic problem reformulation to enhance reason capability llm complex interactive scenario ."
https://doi.org/10.48550/arXiv.2503.18320,"Dong Jing, Nanyi Fei, Zhiwu Lu",CL,24/03/2025,"bridge write manner gap visual instruction tuning create llm aligned instruction realm large multi modal model ( lmms ) , instruction quality visual instruction tune stage significantly influence performance modality alignment . paper , assess instruction quality unique perspective term { write manner } , which encompass selection vocabulary , grammar sentence structure to convey specific semantics . argue there exist substantial writing manner gap visual instruction base large language model ( llm ) lmms . gap force pre trained base llm to deviate original writing style , lead to capability degradation base llm lmms . to bridge writing manner gap preserve original semantics , propose directly leverage base llm to align write manner soft format visual instruction base llm , result novel llm aligned instruction . manual writing manner evaluation result demonstrate approach successfully minimize writing manner gap . utilize llm aligned instruction , baseline model qwenvl demonstrate enhance resistance to hallucination non trivial comprehensive improvement $ $ visual language benchmark ."
https://doi.org/10.48550/arXiv.2503.18225,"Massimo Bini, Leander Girrbach, Zeynep Akata",CL,23/03/2025,"decouple angle strength low rank adaptation parameter efficient finetuning ( peft ) method have recently gain significant popularity thanks to widespread availability large scale pretrained model . method allow quick adaptation to downstream task minimal computational cost . however , popular finetuning method such lora exhibit limited robustness when come to hyperparameter choice extended training regime , prevent optimal out of the box performance . contrast , bound approach , such ether , provide great robustness be limit to extremely low rank adaptation fixed strength transformation , reduce adaptation expressive power . work , propose decoupled low rank adaptation ( delora ) , novel finetuning method that normalize scale learnable low rank matrix . bound distance transformation , delora effectively decouple angular learning adaptation strength , enhance robustness compromise performance . evaluation subject driven image generation , natural language understanding , instruction tuning , show delora match surpasses performance compete peft method , exhibit strong robustness . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18102,"Samuel Schmidgall, Michael Moor",CL,23/03/2025,"agentrxiv : towards collaborative autonomous research progress scientific discovery be rarely result single eureka moment , be rather product hundred scientist incrementally work together common goal . exist agent workflow be capable produce research autonomously , do so isolation , ability to continuously improve prior research result . to address challenge , introduce agentrxiv a framework that let llm agent laboratory upload retrieve report share preprint server order to collaborate , share insight , iteratively build other research . task agent laboratory to develop new reasoning prompt technique find agent access to prior research achieve high performance improvement compare to agent operate isolation ( % relative improvement baseline ) . find best performing strategy generalize to benchmarks other domain ( improve average % ) . multiple agent laboratory share research agentrxiv be able to work together common goal , progress more rapidly isolated laboratory , achieve high overall accuracy ( % relative improvement baseline ) . finding suggest autonomous agent may play role design future ai system alongside human . hope agentrxiv allow agent to collaborate research goal enable researcher to accelerate discovery ."
https://doi.org/10.48550/arXiv.2503.18065,"Ziming Wei, Bingqian Lin, Yunshuang Nie, Jiaqi Chen, Shikui Ma, Hang Xu, Xiaodan Liang",CL,23/03/2025,"unseen see : rewrite observation instruction use foundation model augment vision language navigation data scarcity be long standing challenge vision language navigation ( vln ) field , which extremely hinder generalization agent to unseen environment . previous work primarily rely additional simulator data web collected to improve generalization . however , simulator environment still face limited diversity , web collected data often require extensive labor to remove noise . paper , propose rewriting driven augmentation ( ram ) paradigm vln , which directly create unseen observation instruction pair rewrite human annotated training data . benefiting rewrite mechanism , new observation instruction can be obtain simulator free labor saving manner to promote generalization . specifically , first introduce object enriched observation rewriting , where combine vision language model ( vlms ) large language model ( llm ) to derive rewritten object enriched scene description , enable observation synthesis diverse object spatial layout text to image generation model ( ) . then , propose observation contrast instruction rewriting , which generate observation aligned rewritten instruction require llm to reason difference original new observation . further develop mixing then focusing training strategy random observation crop scheme , effectively enhance data distribution diversity suppress augmentation data noise training . experiment discrete environment ( , reverie , datasets ) continuous environment ( dataset ) show superior performance impressive generalization ability method . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18050,Hanwool Lee,CL,23/03/2025,"( g ) i dle : generative inference distribution preserving logit exclusion kl divergence minimization constrain decoding propose ( g ) i dle , new approach to constrain decode leverage kl divergence minimization to preserve intrinsic conditional probability distribution autoregressive language model exclude undesirable token . conventional method that naively set ban token ' logits to $ $ , which can distort conversion raw logits to posterior probability increase output variance , ( g ) i dle re normalizes allow token probability to minimize such distortion . validate method dataset , specifically design to assess korean language fluency , logical reasoning , cultural appropriateness . experimental result model ( range to ) demonstrate g idle not only boost mean evaluation score also substantially reduce variance output quality ."
https://doi.org/10.48550/arXiv.2503.18034,"Qiao Liang, Yanjiang Liu, Ben He, Yaojie Lu, Hongyu Lin, Jia Zheng, Xianpei Han, Le Sun, Yingfei Sun",CL,23/03/2025,"expand boundary vision prior knowledge multi modal large language model do prior knowledge vision encoder constrain capability boundary multi modal large language model ( mllms ) ? most exist research treat mllms unified system optimize end to end training , impact vision encoder prior knowledge be seldom investigate . work , introduce novel metric , $ $ , to quantify effect vision encoder prior knowledge mllm performance . analysis reveal positive correlation prior knowledge mllm performance . moreover , find domain specific fine tuning use solely end to end visual question answering ( vqa ) data be insufficient particularly entity low inherent visual prior knowledge . to address issue , propose vispre ( vision prior remediation ) , two stage training framework that explicitly incorporate prior knowledge vision encoder level . experimental result demonstrate augment vision encoder prior knowledge substantially boost visual understanding capability mllms , offer novel effective strategy improve performance , especially scenario involve uncommon visual entity ."
https://doi.org/10.48550/arXiv.2503.17979,"Weixiang Zhao, Xingyu Sui, Jiahe Guo, Yulin Hu, Yang Deng, Yanyan Zhao, Bing Qin, Wanxiang Che, Tat-Seng Chua, Ting Liu",CL,23/03/2025,"trade offs large reason model : empirical analysis deliberative adaptive reasoning foundational capability recent advancement large reasoning model ( lrms ) , such openai , have demonstrate remarkable performance specialized reasoning task human like deliberative thinking long chain of thought reasoning . however , systematic evaluation various model family ( deepseek , qwen , llama ) scale ( to ) reveals acquire deliberative reasoning capability significantly reduce foundational capability lrms , include notable decline helpfulness harmlessness , alongside substantially increased inference cost . importantly , demonstrate adaptive reasoning employ mode zero thinking , less thinking , summary thinking can effectively alleviate drawback . empirical insight underline critical need develop more versatile lrms capable dynamically allocate inference time compute accord to specific task characteristic ."
https://doi.org/10.48550/arXiv.2503.17955,"Stefan Pasch, Sun-Young Ha",CL,23/03/2025,"human ai interaction user satisfaction : empirical evidence online review ai product human ai interaction ( hai ) guideline design principle have become increasingly important industry academia to guide development ai system that align user need expectation . however , large scale empirical evidence how hai principle shape user satisfaction practice remains limited . study address gap analyze user review ai related product http url , lead review platform business software service . base widely adopt industry guideline , identify seven core hai dimension examine coverage sentiment review . find sentiment four hai dimension adaptability , customization , error recovery , security is positively associate overall user satisfaction . moreover , show engagement hai dimension varies professional background : user technical job role be more likely to discuss system focused aspect , such reliability , non technical user emphasize interaction focused feature customization feedback . interestingly , relationship hai sentiment overall satisfaction be not moderate job role , suggest once hai dimension have be identify user , effect satisfaction be consistent job role ."
https://doi.org/10.48550/arXiv.2503.17928,"Zefeng Zhang, Hengzhu Tang, Jiawei Sheng, Zhenyu Zhang, Yiming Ren, Zhenyang Li, Dawei Yin, Duohe Ma, Tingwen Liu",CL,23/03/2025,"debiasing large language model noise aware preference optimization multimodal large language model excel various task , yet often struggle modality bias , where model tend to rely heavily single modality overlook critical information other modality , which lead to incorrect focus generate irrelevant response . paper , propose use paradigm preference optimization to solve modality bias problem , include rlaifvbias , debiased preference optimization dataset , noise aware preference optimization algorithm . specifically , first construct dataset introduce perturbation to reduce informational content certain modality , compel model to rely specific modality when generate negative response . to address inevitable noise automatically construct data , combine noise robust mean absolute error binary cross entropy direct preference optimization negative box cox transformation , dynamically adjust algorithm noise robustness base evaluated noise level data . extensive experiment validate approach , demonstrate not only effectiveness mitigate modality bias also significant role minimize hallucination ."
https://doi.org/10.48550/arXiv.2503.17793,"Codefuse, Ling Team: Wenting Cai, Yuchen Cao, Chaoyu Chen, Chen Chen, Siba Chen, Qing Cui, Peng Di, Junpeng Fang, Zi Gong, Ting Guo, Zhengyu He, Yang Huang, Cong Li, Jianguo Li, Zheng Li, Shijie Lian, BingChang Liu, Songshan Luo, Shuo Mao, Min Shen, Jian Wu, Jiaolong Yang, Wenjie Yang, Tong Ye, Hang Yu, Wei Zhang, Zhenduo Zhang, Hailin Zhao, Xunjin Zheng, Jun Zhou",CL,22/03/2025,"sample matter : leverage mixture of expert high quality data efficient accurate code llm recent advancement code large language model ( llm ) have demonstrate remarkable capability code generation understanding . be still challenge to build code llm comprehensive performance yet ultimate efficiency . many attempt have be release open source community to break trade off performance efficiency , such qwen coder series deepseek coder series . paper introduce yet attempt area , namely ling coder lite . leverage efficient mixture of expert ( moe ) architecture set high quality data curation method ( especially base program analytics ) to build efficient yet powerful code llm . ling coder lite exhibit on par performance representative cod benchmark compare to state of the art model similar size , such , offer competitive latency throughput . practice , achieve % reduction deployment resource compare to similar sized dense model performance loss . to facilitate further research development area , open source model as well substantial portion high quality data annealing post training stage . model data can be access { http url } ."
https://doi.org/10.48550/arXiv.2503.17783,"Nguyen Phuc Tran, Brigitte Jaumard, Oscar Delgado",CL,22/03/2025,"energy aware llm : step sustainable ai downstream application advanced large language model ( llm ) have revolutionize various field , include communication network , spark innovation wave that have lead to new application service , significantly enhanced solution scheme . all impressive development , most llms typically require huge computational resource , result terribly high energy consumption . thus , research study propose end to end pipeline that investigate trade off energy efficiency model performance llm fault ticket analysis communication network . far evaluate pipeline performance use two real world datasets task root cause analysis response feedback communication network . result show appropriate combination quantization prune technique be able to reduce energy consumption significantly improve model performance ."
https://doi.org/10.48550/arXiv.2503.17736,"Yiming Zhao, Yu Zeng, Yukun Qi, YaoYang Liu, Lin Chen, Zehui Chen, Xikun Bao, Jie Zhao, Feng Zhao",CL,22/03/2025,": evaluate video language understanding visual prompt good human model interaction large vision language model ( lvlms ) have make significant progress field video understand recently . however , current benchmark uniformly lean text prompt evaluation , which often necessitate complex referential language fail to provide precise spatial temporal reference . limitation diminish experience efficiency human model interaction . to address limitation , propose video visual prompt benchmark ( ) , comprehensive benchmark specifically design to evaluate lvlms ' video understand capability multimodal human model interaction scenario . include unique video qa pair , cover main task dimension , facilitate instance level fine grained understanding align human cognition . benchmarking result reveal even most powerful model perform poorly ( % % ) , significantly low human expert ' % , highlight current shortcoming lvlms understand video visual prompt . hope will serve foundation advance multimodal human model interaction video understanding evaluation . project page : http url ."
https://doi.org/10.48550/arXiv.2503.17632,"Jiali Cheng, Hadi Amiri",CL,22/03/2025,"fairflow : mitigating dataset bias undecided learning language model be prone to dataset bias , know shortcut spurious correlation data , which often result performance drop new data . present new debiasing framework call fairflow that mitigate dataset bias learn to be undecided prediction data sample representation associate know unknown bias . framework introduces two key component : suite data model perturbation operation that generate different biased view input sample , contrastive objective learn debiased robust representation result biased view sample . experiment show fairflow outperforms exist debiasing method , particularly out of domain hard test sample compromise in domain performance"
https://doi.org/10.48550/arXiv.2503.17553,"Humza Nusrat (1 and 2), Bing Luo (1), Ryan Hall (1), Joshua Kim (1), Hassan Bagher-Ebadian (1 and 2), Anthony Doemer (1), Benjamin Movsas (1 and 2), Kundan Thind (1 and 2) ((1) Department of Radiation Oncology, Henry Ford Health, Detroit, USA (2) College of Human Medicine, Michigan State University, East Lansing, USA)",CL,21/03/2025,"autonomous radiotherapy treatment plan use dola : privacy preserving , llm based optimization agent radiotherapy treatment planning be complex time intensive process , often impact inter planner variability subjective decision making . to address challenge , introduce dose optimization language agent ( dola ) , autonomous large language model ( llm )  base agent design optimize radiotherapy treatment plan rigorously protect patient privacy . dola integrate llm directly commercial treatment plan system , utilize chain of thought prompting , retrieval augmented generation ( rag ) , reinforcement learning ( rl ) . operate entirely secure local infrastructure , agent eliminate external data share . evaluate dola use retrospective cohort prostate cancer patient prescribe gy fraction , compare model size ( billion billion parameter ) optimization strategy ( no rag , rag , ) planning iteration . model demonstrate significantly improve performance , achieve approximately % high final score model . rag approach outperform no rag baseline % , incorporate rl accelerate convergence , highlight synergy retrieval based memory reinforcement learning . optimal temperature hyperparameter analysis identify provide best balance exploration exploitation . proof concept study represent first successful deployment locally host llm agent autonomous optimization treatment plan commercial radiotherapy planning system . extend human machine interaction interpretable natural language reasoning , dola offer scalable privacy conscious framework , significant potential clinical implementation workflow improvement ."
https://doi.org/10.48550/arXiv.2503.17502,"Hamed Jelodar, Mohammad Meymani, Roozbeh Razavi-Far",CL,21/03/2025,"large language model ( llm ) source code analysis : application , model datasets large language model ( llm ) transformer based architecture be increasingly utilized source code analysis . software system grow complexity , integrate llm code analysis workflows become essential enhance efficiency , accuracy , automation . paper explore role llm different code analysis task , focus three key aspect : ) what can analyze application , ) what model be use ) what datasets be use , challenge face . regard goal research , investigate scholarly article that explore use llm source code analysis to uncover research development , current trend , intellectual structure emerge field . additionally , summarize limitation highlight essential tool , datasets , key challenge , which could be valuable future work ."
https://doi.org/10.48550/arXiv.2503.17500,"Louis Owen, Abhay Kumar, Nilabhra Roy Chowdhury, Fabian Güra",CL,21/03/2025,"variance control weight rescale llm pre training outcome large language model ( llm ) pre training strongly depend weight initialization variance control strategy . importance initial variance control have be well document neural network general , literature initialization management growth llm pre training , specifically , be somewhat sparse . paper , introduce layer index rescaling ( lir ) weight initialization scheme , target variance rescaling ( tvr ) variance control strategy . experiment parameter llama model demonstrate good variance management use technique yield substantial improvement downstream task performance ( to % common pre training benchmark ) reduce extreme activation value , thus mitigate challenge associate quantization low precision training . code be available : http url ."
https://doi.org/10.48550/arXiv.2503.17438,"Paolo Frazzetto, Muhammad Uzair Ul Haq, Flavia Fabris, Alessandro Sperduti",CL,21/03/2025,"text to talent : pipeline extract insight candidate profile recruitment process be undergo significant transformation increase use machine learning natural language processing technique . previous study have focus automate candidate selection , role multiple vacancy process remain understudied . paper address gap propose novel pipeline leverage large language model graph similarity measure to suggest ideal candidate specific job opening . approach represent candidate profile multimodal embeddings , enable capture nuanced relationship job requirement candidate attribute . propose approach have significant implication recruitment industry , enable company to streamline hiring process identify top talent more efficiently . work contribute to grow body research application machine learning human resource , highlight potential llm graph based method revolutionize recruitment landscape ."
https://doi.org/10.48550/arXiv.2503.17421,"Junwei Kuang, Liang Yang, Shaoze Cui, Weiguo Fan",CL,21/03/2025,"understand social support need question : hybrid approach integrate semi supervised learning llm based data augmentation patient be increasingly turn to online health q & community social support to improve well being . however , when support receive do not align specific need , may prove ineffective even detrimental . necessitate model capable identify social support need question . however , train such model be challenge due to scarcity class imbalance issue label data . to overcome challenge , follow computational design science paradigm to develop novel framework , hybrid approach social support need classification ( ha so ) . ha sos integrates answer enhanced semi supervised learning approach , text data augmentation technique leverage large language model ( llm ) reliability  diversity aware sample selection mechanism , unified training process to automatically label social support need question . extensive empirical evaluation demonstrate ha so significantly outperform exist question classification model alternative semi supervised learning approach . research contribute to literature social support , question classification , semi supervised learning , text data augmentation . practice , ha sos framework facilitates online q & platform manager answerer to good understand user ' social support need , enable to provide timely , personalized answer intervention ."
https://doi.org/10.48550/arXiv.2503.17382,"Andrew Kiruluta, Andreas Lemos",CL,16/03/2025,"state fourier diffusion language model ( sfdlm ) : scalable , novel iterative approach to language modeling recent year , diffusion base method have emerge powerful paradigm generative modeling . discrete diffusion natural language processing have be explore to less extent , show promise task require iterative denoising token base data . standard approach to text generation , transformer dominate , reliance self attention often incur high computational cost . paper introduce fully diffusion driven discrete text generation model build transformer large convolution module . instead , model integrate structured state space dynamic time domain novel complex fourier multi layer perceptron module that operate frequency domain . forward noise process randomly sample vocabulary to replace token controlled probability , learned reverse model systematically revert corrupted sequence original state . compose local state space update global fourier base mixing , approach effectively capture short long range dependency ."
https://doi.org/10.48550/arXiv.2503.16586,"Yash Vekaria (1), Aurelio Loris Canino (2), Jonathan Levitsky (1), Alex Ciechonski (3), Patricia Callejo (4), Anna Maria Mandalari (3), Zubair Shafiq (1) ((1) UC Davis, (2) Mediterranea University of Reggio Calabria, (3) University College London, (4) Universidad Carlos III de Madrid)",CL,20/03/2025,"big help big brother ? audit tracking , profile , personalization generative ai assistant generative ai ( genai ) browser assistant integrate powerful capability genai web browser to provide rich experience such question answering , content summarization , agentic navigation . assistant , available today browser extension , can not only track detailed browse activity such search click data , can also autonomously perform task such fill form , raise significant privacy concern . be crucial to understand design operation genai browser extension , include how collect , store , process , share user data . to end , study ability to profile user personalize response base explicit inferred demographic attribute interest user . perform network traffic analysis use novel prompting framework to audit tracking , profile , personalization ten most popular genai browser assistant extension . find instead rely local in browser model , assistant largely depend server side apis , which can be auto invoked explicit user interaction . when invoke , collect share webpage content , often full html dom sometimes even user form input , first party server . assistant also share identifier user prompt third party tracker such google analytics . collection sharing continue even webpage contain sensitive information such health personal information such name ssn enter web form . find several genai browser assistant infer demographic attribute such age , gender , income , interest use profile which carry browse context to personalize response . summary , work show genai browser assistant can do collect personal sensitive information profiling personalization little to safeguard ."
https://doi.org/10.48550/arXiv.2503.17363,"Yansi Li, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Qiuzhi Liu, Rui Wang, Zhuosheng Zhang, Zhaopeng Tu, Haitao Mi, Dong Yu",CL,21/03/2025,"dance critique : enhance llm reason stepwise natural language self critique enhance reason capability large language model ( llm ) , particularly complex task require multi step logical deduction , remain significant challenge . traditional inference time scale method utilize scalar reward signal process reward model to evaluate candidate reason step , scalar reward lack nuanced qualitative information essential understand justify step . paper , propose novel inference time scaling approach stepwise natural language self critique ( panel ) , which employ self generated natural language critique feedback to guide step level search process . generate rich , human readable critique candidate reason step , panel retain essential qualitative information , facilitate good informed decision making inference . approach bypass need task specific verifier associated training overhead , make broadly applicable diverse task . experimental result challenge reason benchmark , include aime gpqa , demonstrate panel significantly enhance reason performance , outperform traditional scalar reward based method . code be available http url to support encourage future research promising field ."
https://doi.org/10.48550/arXiv.2503.17336,"Reem Gody, Mohamed Abdelghaffar, Mohammed Jabreel, Ahmed Tawfik",CL,21/03/2025,"efficient intent based filtering multi party conversation use knowledge distillation llm large language model ( llm ) have showcased remarkable capability conversational ai , enable open domain response chat bot , as well advanced processing conversation summarization , intent classification , insight generation . however , model be resource intensive , demand substantial memory computational power . to address , propose cost effective solution filter conversational snippet interest llm processing , tailor to target downstream application , rather process snippet . work , introduce innovative approach that leverage knowledge distillation llm to develop intent based filter multi party conversation , optimize compute power constrain environment . method combine different strategy to create diverse multi party conversational dataset , that be annotate target intent be then use to fine tune mobilebert model multi label intent classification . model achieve balance efficiency performance , effectively filter conversation snippet base intent . pass only relevant snippet to llm further processing , approach significantly reduce overall operational cost depend intent data distribution demonstrate experiment ."
https://doi.org/10.48550/arXiv.2503.17287,"Mingyang Song, Mao Zheng, Zheng Li, Wenjie Yang, Xuan Luo, Yue Pan, Feng Zhang",CL,21/03/2025,"fastcurl : curriculum reinforcement learn progressive context extension efficient train reasoning model paper , propose { { fastcurl } } , simple yet efficient { cu } rriculum { r } einforcement { l } earn approach context window extend strategy to accelerate reinforcement learn training efficiency reasoning model enhance performance tackle complex reason task long chain of thought rationale , particularly parameter language model . { { fastcurl } } consists two main procedure : length aware training data segmentation context window extension training . specifically , former first split original training data three different level input prompt length , then latter leverage segment train datasets progressively increase context window length to train reasoning model . experimental result demonstrate { { fastcurl } } surpasses five datasets ( include math , aime , amc , minerva math , olympiadbench ) only utilize % training step . furthermore , training stage be complete use just single node gpus ."
https://doi.org/10.48550/arXiv.2503.17279,"Gaifan Zhang, Yi Zhou, Danushka Bollegala",CL,21/03/2025,"case condition aware sentence embeddings conditional semantic textual similarity measurement meaning convey sentence often depend context which appear . progress sentence embed method , remain unclear how to best modify sentence embed condition context . to address problem , propose condition aware sentence embeddings ( case ) , efficient accurate method to create embedding sentence give condition . first , case create embedding condition use large language model ( llm ) , where sentence influence attention score compute token condition pool . next , supervised nonlinear projection be learn to reduce dimensionality llm based text embeddings . show case significantly outperform previously propose conditional semantic textual similarity ( c sts ) method exist standard benchmark dataset . find subtract condition embed consistently improve c sts performance llm based text embeddings . moreover , propose supervised dimensionality reduction method not only reduce dimensionality llm based embeddings also significantly improve performance ."
https://doi.org/10.48550/arXiv.2503.17247,"Michael J Bommarito, Daniel Martin Katz, Jillian Bommarito",CL,21/03/2025,"tokenizers : family domain specific character level tokenizers legal , financial , preprocessing application present tokenizers , family specialized tokenizers legal , financial , governmental text . establish work tokenization , specialized tokenizers professional domain remain understudied . paper offer two main contribution to , introduce domain specific bpe tokenizers legal , financial , governmental text . tokenizer use % few token domain specific document , have small vocabulary . specialized terminology , cased tokenizer be even more efficient , use up to % few token legal term % few token financial , develop character level bpe tokenizers ( , , vocabulary size ) text correction task ocr post processing . tokenizers keep consistent token boundary error containing correct text , make easy model to learn correction tokenizers help professional application fit more text context window , reduce computational need , preserve meaning domain specific term . analysis show efficiency gain directly benefit processing long legal financial document . release tokenizers code github hug face to support further research specialized tokenization ."
https://doi.org/10.48550/arXiv.2503.17239,"Aladin Djuhera, Swanand Ravindra Kadhe, Farhan Ahmed, Syed Zawad, Holger Boche",CL,21/03/2025,"safemerge : preserving safety alignment fine tuned large language model selective layer wise model merging fine tuning large language model ( llm ) downstream task can inadvertently erode safety alignment , even benign fine tuning datasets . address challenge propose safemerge , post fine tuning framework that preserve safety maintain task utility . achieve selectively merge fine tuned safety aligned model layer only when deviate safe behavior , measure cosine similarity criterion . evaluate safemerge other fine tuning  post fine tuning stage approach model pubmedqa task explore different merging strategy . find safemerge consistently reduce harmful output compare to other baseline significantly sacrifice performance , sometimes even enhance . result suggest selective , subspace guided , per layer merging method provide effective safeguard inadvertent loss safety fine tuned llm outperform simple post fine tuning stage defense ."
https://doi.org/10.48550/arXiv.2503.17222,"Sonish Sivarajkumar, Kimia Ameri, Chuqin Li, Yanshan Wang, Min Jiang",CL,21/03/2025,"automate adjudication cardiovascular event use large language model cardiovascular event , such heart attack stroke , remain leading cause mortality globally , necessitate meticulous monitoring adjudication clinical trial . process , traditionally perform manually clinical expert , be time consuming , resource intensive , prone to inter reviewer variability , potentially introduce bias hinder trial progress . study address critical limitation present novel framework automate adjudication cardiovascular event clinical trial use large language model ( llm ) . develop two stage approach : first , employ llm based pipeline event information extraction unstructured clinical data second , use llm based adjudication process guide tree thought approach clinical endpoint committee ( cec ) guideline . use cardiovascular event specific clinical trial data , framework achieve event extraction accuracy adjudication . furthermore , introduce cleart score , novel , automate metric specifically design evaluate quality ai generated clinical reasoning adjudicate cardiovascular event . approach demonstrate significant potential substantially reduce adjudication time cost maintain high quality , consistent , auditable outcome clinical trial . reduced variability enhanced standardization also allow fast identification mitigation risk associate cardiovascular therapy ."
https://doi.org/10.48550/arXiv.2503.17211,"Zilin Dai, Lehong Wang, Fangzhou Lin, Yidong Wang, Zhigang Li, Kazunori D Yamada, Ziming Zhang, Wang Lu",CL,21/03/2025,"language anchor guided method robust noisy domain generalization real world machine learning application often struggle two major challenge : distribution shift label noise . model tend to overfit focus redundant uninformative feature training data , which make hard to generalize to target domain . data worsens problem cause further overfitting to noise , mean exist method often fail to tell difference true , invariant feature misleading , spurious one . to tackle issue , introduce anchor alignment adaptive weighting ( ) . new algorithm use sample reweighting guide natural language processing ( nlp ) anchor to extract more representative feature . simple term , leverage semantic representation natural language model source domain invariant prior knowledge . additionally , employ weighted loss function adjust sample contribution base similarity to corresponding nlp anchor . adjustment make model more robust to label . extensive experiment standard benchmark datasets show consistently outperform state of the art domain generalization method , offer significant improvement accuracy robustness different datasets noise level ."
https://doi.org/10.48550/arXiv.2503.17136,"Brihi Joshi, Sriram Venkatapathy, Mohit Bansal, Nanyun Peng, Haw-Shiuan Chang",CL,21/03/2025,"coke : customizable fine grained story evaluation chain of keyword rationalization evaluate creative text such human written story use language model have always be challenging task owe to subjectivity multi annotator rating . to mimic thinking process human , chain thought ( cot ) generate free text explanation that help guide model prediction self consistency ( sc ) marginalize prediction multiple generated explanation . study , discover widely used self consistency reason method cause suboptimal result due to objective mismatch generate ' explanation actually lead to good rating prediction aspect story . to overcome challenge , propose $ { c } $ hain  $ { o } $ f  $ { ke } $ ywords ( coke ) , that generate sequence keywords $ { } $ generate free text rationale , that guide rating prediction evaluation language model . then , generate diverse set such keywords , aggregate score correspond to generation . storyer dataset , coke base small fine tuned evaluation model not only reach human level performance significantly outperform boost correlation human annotator , also require drastically less number parameter ."
https://doi.org/10.48550/arXiv.2503.17126,"John Joon Young Chung, Vishakh Padmakumar, Melissa Roemmele, Yuqian Sun, Max Kreminski",CL,21/03/2025,"modify large language model post training diverse creative writing creative writing task do not have singular correct answer , large language model ( llm ) train to perform task should be able to generate diverse valid output . however , llm post training often focus improve generation quality neglect to facilitate output diversity . hence , creative writing generation , investigate post training approach to promote output diversity quality . core idea be to include deviation degree difference training sample other sample same prompt training objective to facilitate learn rare high quality instance . adopt approach to direct preference optimization ( dpo ) odds ratio preference optimization ( orpo ) , demonstrate can promote output diversity trained model minimally decrease quality . best model parameter could achieve on par diversity human created dataset have output quality similar to best instruction tuned model examine , . further validate approach human evaluation , ablation , comparison to exist diversification approach , divpo ."
https://doi.org/10.48550/arXiv.2503.17073,"Jonas Wallat, Abdelrahman Abdallah, Adam Jatowt, Avishek Anand",CL,21/03/2025,"study investigate temporal robustness llm large language model ( llm ) encapsulate surprising amount factual world knowledge . however , performance temporal question historical knowledge be limit often can not understand temporal scope orientation neglect temporal aspect altogether . study , aim to measure precisely how robust llm be question answer base ability to process temporal information perform task require temporal reasoning temporal factual knowledge . specifically , design eight time sensitive robustness test factual information to check sensitivity six popular llm zero shot setting . overall , find llms lacking temporal robustness , especially to temporal reformulations use different granularity temporal reference . show how selection eight test can be use automatically to judge model temporal robustness user question fly . finally , apply finding study to improve temporal qa performance to percent ."
https://doi.org/10.48550/arXiv.2503.17039,"Jeremy Barnes, Naiara Perez, Alba Bonet-Jover, Begoña Altuna",CL,21/03/2025,"summarization metric spanish basque : do automatic score llm judge correlate human ? study evaluation metric llm as a judge model automatic text summarization have largely be focus english , limit understanding effectiveness other language . new dataset basse ( basque spanish summarization evaluation ) , address situation collect human judgment abstractive summary basque spanish , generate manually five llm four different prompt . summary , annotator evaluate five criterion likert scale : coherence , consistency , fluency , relevance , . use data to reevaluate traditional automatic metric use evaluate summary , as well several llm as a judge model show strong performance task english . result show currently proprietary judge llm have high correlation human judgment , follow criteria specific automatic metric , open sourced judge llm perform poorly . release basse code publicly , first large scale basque summarization dataset contain news article subhead ."
https://doi.org/10.48550/arXiv.2503.17003,"Jian Guan, Junfei Wu, Jia-Nan Li, Chuanqi Cheng, Wei Wu",CL,21/03/2025,"survey personalized alignment missing piece large language model real world application large language model ( llm ) have demonstrate remarkable capability , transition to real world application reveal critical limitation : inability to adapt to individual preference maintain alignment universal human value . current alignment technique adopt one size fits all approach that fail to accommodate user ' diverse background need . paper present first comprehensive survey personalized alignment a paradigm that enable llms to adapt behavior ethical boundary base individual preference . propose unified framework comprise preference memory management , personalize generation , feedback based alignment , systematically analyze implementation approach evaluate effectiveness various scenario . examine current technique , potential risk , future challenge , survey provide structured foundation develop more adaptable ethically aligned llm ."
https://doi.org/10.48550/arXiv.2503.16965,"Zhe Hu, Jing Li, Yu Yin",CL,21/03/2025,"when word outperform vision : vlms can self improve text only training human centered decision making embody decision making be fundamental ai agent operate real world environment . visual language model ( vlms ) have advance capability , still struggle complex decision , particularly human centered situation that require deep reasoning human need value . study , systematically evaluate open sourced vlms multimodal human centered decision making task . find llm receive only textual description unexpectedly outperform vlm counterpart similar scale that process actual image , suggest visual alignment may hinder vlm ability . to address challenge , propose novel text only training approach synthesized textual data . method strengthen vlms ' language component transfer learned ability to multimodal inference , eliminate need expensive image text pair data . furthermore , show vlms can achieve substantial performance gain self improvement , use train data generate llm counterparts rather rely large teacher model . finding establish more efficient scalable approach to enhance vlms ' human centered decision making capability , open new avenue optimize vlms self improvement mechanism ."
https://doi.org/10.48550/arXiv.2503.16883,"Deniss Ruder, Andero Uusberg, Kairit Sirts",CL,21/03/2025,"assess reliability validity annotate emotion appraisal rating appraisal theory suggest emotion arise subjective evaluation event , refer to appraisal . taxonomy appraisal be quite diverse , be usually give rating likert scale to be annotate experiencer annotator reader annotator paradigm . paper study reader annotator specific appraisal rating different prompt setting , aim to evaluate improve performance compare to human annotator . find be effective reader annotator perform close to even slightly good human annotator , result can be significantly improve use majority voting five completion . also effectively predict appraisal rating emotion label use single prompt , add instruction complexity result poor performance . also find longer event description lead to more accurate annotation model human annotator rating . work contribute to grow usage llm psychology strategy improve performance annotate appraisal ."
https://doi.org/10.48550/arXiv.2503.16868,"Mengsay Loem, Taiju Hosaka",CL,21/03/2025,"joint extraction matter : prompt based visual question answer multi field document information extraction visual question answering ( vqa ) have emerge flexible approach extract specific piece information document image . however , exist work typically query field isolation , overlook potential dependency multiple item . paper investigate merit extract multiple field jointly versus separately . experiment multiple large vision language model datasets , show jointly extract field often improve accuracy , especially when field share strong numeric contextual dependency . far analyze how performance scale number requested item use regression base metric to quantify inter field relationship . result suggest multi field prompt can mitigate confusion arise similar surface form related numeric value , provide practical method design robust vqa system document information extraction task ."
https://doi.org/10.48550/arXiv.2503.16858,"Jialin Chen, Aosong Feng, Ziyu Zhao, Juan Garza, Gaukhar Nurbek, Cheng Qin, Ali Maatouk, Leandros Tassiulas, Yifeng Gao, Rex Ying",CL,21/03/2025,"mtbench : multimodal time series benchmark temporal reasoning question answering understand relationship textual news time series evolution be critical yet under explored challenge applied data science . multimodal learning have gain traction , exist multimodal time series datasets fall short evaluate cross modal reasoning complex question answering , which be essential capture complex interaction narrative information temporal pattern . to bridge gap , introduce multimodal time series benchmark ( mtbench ) , large scale benchmark design to evaluate large language model ( llm ) time series text understanding financial weather domain . mtbench comprises pair time series textual data , include financial news correspond stock price movement weather report align historical temperature record . exist benchmark that focus isolated modality , mtbench provide comprehensive testbed model to jointly reason structured numerical trend unstructured textual narrative . richness mtbench enables formulation diverse task that require deep understanding text time series data , include time series forecasting , semantic technical trend analysis , news driven question answering ( qa ) . task target model ability to capture temporal dependency , extract key insight textual context , integrate cross modal information . evaluate state of the art llm mtbench , analyze effectiveness model complex relationship news narrative temporal pattern . finding reveal significant challenge current model , include difficulty capture long term dependency , interpret causality financial weather trend , effectively fuse multimodal information ."
https://doi.org/10.48550/arXiv.2503.16856,"Yang Tian, Zheng Lu, Mingqi Gao, Zheng Liu, Bo Zhao",CL,21/03/2025,"mmcr : benchmarking cross source reasoning scientific paper fully comprehend scientific paper machine reflect high level artificial general intelligence , require ability to reason fragment heterogeneous source information , present complex practically significant challenge . vision language model ( vlms ) have make remarkable stride various task , particularly involve reason evidence source single image text page , ability to use cross source information reason remain open problem . work present mmcr , high difficulty benchmark design to evaluate vlms ' capacity reason cross source information scientific paper . benchmark comprise high quality question , meticulously annotate human subject task type . experiment vlms demonstrate cross source reasoning present substantial challenge exist model . notably , even top performing model , , achieve only % overall accuracy , only % accuracy multi table comprehension task , second best model , , reach % overall accuracy . furthermore , investigate impact chain of thought ( cot ) technique cross source reasoning observe detrimental effect small model , whereas large model demonstrate substantially enhanced performance . result highlight press need to develop vlms capable effectively utilize cross source information reasoning ."
https://doi.org/10.48550/arXiv.2503.16853,"Suho Yoo, Hyunjong Ok, Jaeho Lee",CL,21/03/2025,"imagine to hear : auditory knowledge generation can be effective assistant language model language model pretrained text only corpus often struggle task that require auditory commonsense knowledge . previous work address problem augment language model to retrieve knowledge external audio database . approach have several limitation , such potential lack relevant audio database high cost associate constructing query database . to address issue , propose imagine to hear , novel approach that dynamically generate auditory knowledge use generative model . framework detect multiple audio related textual span give prompt generates correspond auditory knowledge . develop several mechanism to efficiently process multiple auditory knowledge , include clap based rejection sampler language audio fusion module . experiment show method achieve state of the art performance auditorybench rely external database , highlight effectiveness generation based approach ."
https://doi.org/10.48550/arXiv.2503.16826,"Jun Seong Kim, Kyaw Ye Thu, Javad Ismayilzada, Junyeong Park, Eunsu Kim, Huzama Ahmad, Na Min An, James Thorne, Alice Oh",CL,21/03/2025,"when tom eat kimchi : evaluate cultural bias multimodal large language model cultural mixture context highly globalized world , be important multi modal large language model ( mllms ) to recognize respond correctly to mixed cultural input . example , model should correctly identify kimchi ( korean food ) image when asian woman be eat , as well african man be eat . however , current mllms show over reliance visual feature person , lead to misclassification entity . to examine robustness mllms to different ethnicity , introduce mixcube , cross cultural bias benchmark , study element five country four ethnicity . finding reveal mllms achieve high accuracy low sensitivity to such perturbation high resource culture , not low resource culture . , best performing model overall , show to % difference accuracy original perturbed cultural setting low resource culture . dataset be publicly available : http url ."
https://doi.org/10.48550/arXiv.2503.16789,"Rupak Sarkar, Bahareh Sarrafzadeh, Nirupama Chandrasekaran, Nagu Rangan, Philip Resnik, Longqi Yang, Sujay Kumar Jauhar",CL,21/03/2025,"conversational user ai intervention : study prompt rewrite improved llm response generation human llm conversation be increasingly become more pervasive people ' professional personal life , yet many user still struggle to elicit helpful response llm chatbots . one reason issue be user ' lack understand craft effective prompt that accurately convey information need . meanwhile , existence real world conversational datasets one hand , text understanding faculty llm other , present unique opportunity to study problem , potential solution scale . thus , paper present first llm centric study real human ai chatbot conversation , focus investigate aspect which user query fall short express information need , potential use llm to rewrite suboptimal user prompt . finding demonstrate rephrase ineffective prompt can elicit good response conversational system , preserve user original intent . notably , performance rewrite improves long conversation , where contextual inference user need can be make more accurately . additionally , observe llms often need to inherently do make { plausible } assumption user intention goal when interpret prompt . finding largely hold true conversational domain , user intent , llm vary size family , indicate promise use prompt rewriting solution good human ai interaction ."
https://doi.org/10.48550/arXiv.2503.16779,"Mengsong Wu, Tong Zhu, Han Han, Xiang Zhang, Wenbiao Shao, Wenliang Chen",CL,21/03/2025,"chain of tool : utilizing massive unseen tool cot reasoning frozen language model tool learning can far broaden usage scenario large language model ( llm ) . however most exist method either need to finetune model can only use tool see training data , add tool demonstration prompt low efficiency . paper , present new tool learn method chain of tool . make full use powerful semantic representation capability frozen llm to finish tool call cot reason huge flexible tool pool which may contain unseen tool . especially , to validate effectiveness approach massive unseen tool scenario , construct new dataset simpletoolquestions . conduct experiment two numerical reason benchmark ( funcqa ) two knowledge based question answer benchmark ( kamel simpletoolquestions ) . experimental result show approach perform good baseline . also identify dimension model output that be critical tool selection , enhance model interpretability . code data be available : http url ."
https://doi.org/10.48550/arXiv.2503.16745,"Shiva Upadhye, Jiaxuan Li, Richard Futrell",CL,20/03/2025,"spacer : parallel dataset speech production comprehension error repair speech error be natural part communication , yet rarely lead to complete communicative failure speaker comprehenders can detect correct error . prior research have examine monitoring correction production comprehension separately , integrated investigation system have be impede scarcity parallel data . study , present spacer , parallel dataset that capture how naturalistic speech error be correct speaker comprehenders . focus single word substitution error extract switchboard corpus , accompany speaker self repairs comprehenders ' response offline text editing experiment . exploratory analysis suggest asymmetry error correction strategy : speaker be more likely to repair error introduce great semantic phonemic deviation , whereas comprehenders tend to correct error that be phonemically similar to more plausible alternative do not fit prior context . dataset enable future research integrated approach study language production comprehension ."
https://doi.org/10.48550/arXiv.2503.16728,"Emiel van Miltenburg, Chenghua Lin",CL,20/03/2025,"natural language generation article provide brief overview field natural language generation . term natural language generation ( nlg ) , broad definition , refers to study system that verbalize form information natural language . information could be store large database knowledge graph ( data to text application ) , nlg researcher may also study summarisation ( text to text ) image captioning ( image to text ) , example . subfield natural language processing , nlg be closely relate to other sub discipline such machine translation ( mt ) dialog system . nlg researcher exclude mt definition field , there be content selection involve where system have to determine what to say . conversely , dialog system do not typically fall header natural language generation nlg be just one component dialog system ( others be natural language understanding dialog management ) . however , rise large language model ( llm ) , different subfields natural language processing have converge similar methodology production natural language evaluation automatically generate text ."
https://doi.org/10.48550/arXiv.2503.16674,"Molly Kennedy, Ayyoob Imani, Timo Spinde, Hinrich Schütze",CL,20/03/2025,"llm look glass : socratic self assessment donkey , elephant , market detect avoid bias llm generated text be become increasingly important , medium bias often remain subtle subjective , make particularly difficult to identify mitigate . study , assess medium bias llm generated content llm ' ability to detect subtle ideological bias . conduct evaluation use two datasets , poligen econolex , cover political economic discourse , respectively . evaluate eight widely use llm prompt to generate article analyze ideological preference self assessment . use self assessment , study aim to directly measure model ' bias rather rely external interpretation , thereby minimize subjective judgment medium bias . result reveal consistent preference democratic republican position model . conversely , economic topic , bias vary western llm , develop china lean more strongly socialism ."
https://doi.org/10.48550/arXiv.2503.16655,"Maxime Delmas, Magdalena Wysocka, Danilo Gusicuma, André Freitas",CL,20/03/2025,"accelerate antibiotic discovery large language model knowledge graph discovery novel antibiotic be critical to address grow antimicrobial resistance ( amr ) . however , pharmaceutical industry face high cost ( $ billion ) , long timeline , high failure rate , worsen rediscovery known compound . propose llm based pipeline that act alarm system , detect prior evidence antibiotic activity to prevent costly rediscovery . system integrate organism chemical literature knowledge graph ( kg ) , ensure taxonomic resolution , synonym handling , multi level evidence classification . test pipeline private list potential antibiotic producing organism , disclose negative hit evaluation . result highlight effectiveness pipeline evidence reviewing , reduce false negative , accelerate decision making . kg negative hit user interface interactive exploration will be make publicly available ."
https://doi.org/10.48550/arXiv.2503.16622,"Michele Fiori, Gabriele Civitarese, Priyankar Choudhary, Claudio Bettini",CL,20/03/2025,"leverage large language model explainable activity recognition smart home : critical evaluation explainable artificial intelligence ( xai ) aim to uncover inner reasoning machine learning model . iot system , xai improve transparency model process sensor data multiple heterogeneous device , ensure end user understand trust output . many application , xai have also be apply to sensor based activity daily living ( adls ) recognition smart home . exist approach highlight which sensor event be most important predicted activity , use simple rule to convert event natural language explanation non expert user . however , method produce rigid explanation lack natural language flexibility be not scalable . recent rise large language model ( llm ) , be worth explore can enhance explanation generation , consider proven knowledge human activity . paper investigate potential approach to combine xai llm sensor based adl recognition . evaluate llm can be use : ) explainable zero shot adl recognition model , avoid costly label data collection , b ) to automate generation explanation exist data driven xai approach when train data be available goal be high recognition rate . critical evaluation provide insight benefit challenge use llm explainable adl recognition ."
https://doi.org/10.48550/arXiv.2503.16614,"Maria de Lourdes M. Silva, André L. C. Mendonça, Eduardo R. D. Neto, Iago C. Chaves, Felipe T. Brito, Victor A. E. Farias, Javam C. Machado",CL,20/03/2025,"classification user report detection faulty computer component use nlp model : case study computer manufacturer typically offer platform user to report fault . however , there remain significant gap platform ' ability to effectively utilize textual report , which impede user describe issue own word . context , natural language processing ( nlp ) offer promising solution , enable analysis user generated text . paper present innovative approach that employ nlp model to classify user report detect faulty computer component , such cpu , memory , motherboard , video card , more . work , build dataset user report obtain many source . additionally , extensive experimental evaluation , approach achieve accuracy % dataset ."
https://doi.org/10.48550/arXiv.2503.16585,"Hadi Amini, Md Jueal Mia, Yasaman Saadati, Ahmed Imteaj, Seyedsina Nabavirazavi, Urmish Thakker, Md Zarif Hossain, Awal Ahmed Fime, S.S. Iyengar",CL,20/03/2025,"distribute llm multimodal large language model : survey advance , challenge , future direction language model ( lm ) be machine learning model design to predict linguistic pattern estimate probability word sequence base large scale datasets , such text . lm have wide range application natural language processing ( nlp ) task , include autocomplete machine translation . large datasets typically enhance lm performance , scalability remain challenge due to constraint computational power resource . distribute compute strategy offer essential solution improve scalability manage grow computational demand . far , use sensitive datasets training deployment raise significant privacy concern . recent research have focus develop decentralize technique to enable distributed training inference utilize diverse computational resource enable edge ai . paper present survey distributed solution various lm , include large language model ( llm ) , vision language model ( vlms ) , multimodal llm ( mllms ) , small language model ( slms ) . llms focus processing generate text , mllms be design to handle multiple modality data ( , text , image , audio ) to integrate broad application . to end , paper review key advancement mllm pipeline , include distributed training , inference , fine tuning , deployment , also identify contribution , limitation , future area improvement . far , categorize literature base six primary focus area decentralization . analysis describe gap current methodology enable distributed solution lm outline future research direction , emphasize need novel solution to enhance robustness applicability distributed lm ."
https://doi.org/10.48550/arXiv.2503.18950,"Taeksoo Kim, Hanbyul Joo",CV,24/03/2025,"target aware video diffusion model present target aware video diffusion model that generate video input image which actor interact specify target perform desired action . target be define segmentation mask desired action be describe text prompt . exist controllable image to video diffusion model that often rely dense structural motion cue to guide actor movement target , target aware model require only simple mask to indicate target , leverage generalization capability pretrained model to produce plausible action . make method particularly effective human object interaction ( hoi ) scenario , where provide precise action guidance be challenge , far enable use video diffusion model high level action planning application such robotics . build target aware model extend baseline model to incorporate target mask additional input . to enforce target awareness , introduce special token that encode target spatial information text prompt . then fine tune model curated dataset use novel cross attention loss that align cross attention map associate token input target mask . to further improve performance , selectively apply loss to most semantically relevant transformer block attention region . experimental result show target aware model outperforms exist solution generate video where actor interact accurately specified target . further demonstrate efficacy two downstream application : video content creation zero shot hoi motion synthesis ."
https://doi.org/10.48550/arXiv.2503.18948,"Ruixiao Dong, Mengde Xu, Zigang Geng, Li Li, Han Hu, Shuyang Gu",CV,24/03/2025,"equivariant image modeling current generative model , such autoregressive diffusion approach , decompose high dimensional data distribution learn series simple subtasks . however , inherent conflict arise joint optimization subtasks , exist solution fail to resolve such conflict sacrifice efficiency scalability . propose novel equivariant image model framework that inherently align optimization target subtasks leverage translation invariance natural visual signal . method introduces ( ) column wise tokenization which enhance translational symmetry horizontal axis , ( ) windowed causal attention which enforce consistent contextual relationship position . evaluate class conditioned imagenet generation resolution , approach achieve performance comparable to state of the art ar model use few computational resource . systematic analysis demonstrate enhance equivariance reduces inter task conflict , significantly improve zero shot generalization enable ultra long image synthesis . work establish first framework task aligned decomposition generative modeling , offer insight efficient parameter share conflict free optimization . code model be publicly available http url ."
https://doi.org/10.48550/arXiv.2503.18947,"Jae Joong Lee, Bedrich Benes, Raymond A. Yeh",CV,24/03/2025,"tuning free amodal segmentation occlusion free bias inpainting model amodal segmentation aim to predict segmentation mask visible occluded region object . most existing work formulate supervised learning problem , require manually annotate amodal mask synthetic training data . consequently , performance depend quality datasets , which often lack diversity scale . work introduce tuning free approach that repurposes pretrained diffusion based inpainting model amodal segmentation . approach be motivate occlusion free bias inpainting model , , inpainted object tend to be complete object occlusion . specifically , reconstruct occluded region object inpainting then apply segmentation , additional training fine tuning . experiment five datasets demonstrate generalizability robustness approach . average , approach achieve % more accurate mask state of the art ."
https://doi.org/10.48550/arXiv.2503.18945,"Aether Team, Haoyi Zhu, Yifan Wang, Jianjun Zhou, Wenzheng Chang, Yang Zhou, Zizun Li, Junyi Chen, Chunhua Shen, Jiangmiao Pang, Tong He",CV,24/03/2025,"aether : geometric aware unified world modeling integration geometric reconstruction generative modeling remain critical challenge develop ai system capable human like spatial reasoning . paper propose aether , unified framework that enable geometry aware reasoning world model jointly optimize three core capability : ( ) dynamic reconstruction , ( ) action conditioned video prediction , ( ) goal conditioned visual planning . task interleaved feature learning , achieve synergistic knowledge share reconstruction , prediction , plan objective . building video generation model , framework demonstrate unprecedented synthetic to real generalization never observe real world data training . furthermore , approach achieve zero shot generalization action follow reconstruction task , thanks to intrinsic geometric modeling . remarkably , even real world data , reconstruction performance far exceed domain specific model . additionally , aether leverage geometry informed action space to seamlessly translate prediction action , enable effective autonomous trajectory planning . hope work inspire community to explore new frontier physically reasonable world modeling application ."
https://doi.org/10.48550/arXiv.2503.18944,"Karim Abou Zeid, Kadir Yilmaz, Daan de Geus, Alexander Hermans, David Adrian, Timm Linder, Bastian Leibe",CV,24/03/2025,"dino room : leveraging foundation model segmentation vision foundation model ( vfms ) train large scale image datasets provide high quality feature that have significantly advance visual recognition . however , potential vision remain largely untapped , common availability image alongside point cloud datasets . significant research have be dedicate to fusion , recent state of the art method predominantly focus data , leave integration vfms model underexplored . work , challenge trend introduce ditr , simple yet effective approach that extract foundation model feature , project to , finally inject point cloud segmentation model . ditr achieve state of the art result indoor outdoor semantic segmentation benchmark . to enable use vfms even when image be unavailable inference , further propose to distill foundation model backbone pretraining task . initialize backbone knowledge distil vfms , create strong basis downstream segmentation task , ultimately boost performance various datasets ."
https://doi.org/10.48550/arXiv.2503.18943,"Mingze Xu, Mingfei Gao, Shiyu Li, Jiasen Lu, Zhe Gan, Zhengfeng Lai, Meng Cao, Kai Kang, Yinfei Yang, Afshin Dehghan",CV,24/03/2025,": family token efficient video large language model long form video understanding introduce ( abbreviate ) , family video large language model ( llm ) offer token efficient solution long form video understanding . model family employ two stream slowfast mechanism , enable efficient modeling long range temporal context to meet demand lightweight , mobile friendly video llm . provide model range to parameter , optimize streamlined training pipeline high quality data mixture compose publicly available datasets . experimental result demonstrate achieves competitive performance wide range video image benchmark , robust result model size . notably , achieves state of the art result long form video understanding ( , longvideobench mlvu ) excels small scale ( ) various video benchmark ."
https://doi.org/10.48550/arXiv.2503.18942,"Fangfu Liu, Hanyang Wang, Yimo Cai, Kaiyan Zhang, Xiaohang Zhan, Yueqi Duan",CV,24/03/2025,": test time scaling video generation scale capability increase training data , model size , computational cost , video generation have achieve impressive result digital creation , enable user to express creativity various domain . recently , researcher large language model ( llm ) have expand scaling to test time , which can significantly improve llm performance use more inference time computation . instead scale up video foundation model expensive training cost , explore power test time scaling ( tt ) video generation , aim to answer question : video generation model be allow to use non trivial amount inference time compute , how much can improve generation quality give challenge text prompt . work , reinterpret test time scaling video generation search problem to sample good trajectory gaussian noise space to target video distribution . specifically , build search space test time verifier to provide feedback heuristic algorithm to guide search process . give text prompt , first explore intuitive linear search strategy increase noise candidate inference time . full step denoising frame simultaneously require heavy test time computation cost , further design more efficient tt method video generation call tree of frame ( tof ) that adaptively expand prune video branch autoregressive manner . extensive experiment text conditioned video generation benchmark demonstrate increase test time compute consistently lead to significant improvement quality video . project page : http url"
https://doi.org/10.48550/arXiv.2503.18940,"Ye Tian, Xin Xia, Yuxi Ren, Shanchuan Lin, Xing Wang, Xuefeng Xiao, Yunhai Tong, Ling Yang, Bin Cui",CV,24/03/2025,"training free diffusion acceleration bottleneck sample diffusion model have demonstrate remarkable capability visual content generation remain challenge to deploy due to high computational cost inference . computational burden primarily arise quadratic complexity self attention respect to image video resolution . exist acceleration method often compromise output quality necessitate costly retrain , observe most diffusion model be pre trained low resolution , present opportunity to exploit low resolution prior more efficient inference degrade performance . work , introduce bottleneck sampling , training free framework that leverage low resolution prior to reduce computational overhead preserve output fidelity . bottleneck sample follow high low high denoising workflow : perform high resolution denoising initial final stage operating low resolution intermediate step . to mitigate aliasing blurring artifact , further refine resolution transition point adaptively shift denoising timesteps stage . evaluate bottleneck sampling image video generation task , where extensive experiment demonstrate accelerate inference to $ $ image generation $ $ video generation , maintain output quality comparable to standard full resolution sample process multiple evaluation metric . code be available : http url"
https://doi.org/10.48550/arXiv.2503.18933,"Enrico Pallotta, Sina Mokhtarzadeh Azar, Shuai Li, Olga Zatsarynna, Juergen Gall",CV,24/03/2025,"syncvp : joint diffusion synchronous multi modal video prediction predict future video frame be essential decision making system , yet rgb frame alone often lack information need to fully capture underlying complexity real world . to address limitation , propose multi modal framework synchronous video prediction ( syncvp ) that incorporate complementary data modality , enhance richness accuracy future prediction . syncvp build pre trained modality specific diffusion model introduces efficient spatio temporal cross attention module to enable effective information share modality . evaluate syncvp standard benchmark datasets , such cityscape bair , use depth additional modality . furthermore demonstrate generalization to other modality synthia semantic information climate data . notably , syncvp achieves state of the art performance , even scenario where only one modality be present , demonstrate robustness potential wide range application ."
https://doi.org/10.48550/arXiv.2503.18931,"Yitong Chen, Lingchen Meng, Wujian Peng, Zuxuan Wu, Yu-Gang Jiang",CV,24/03/2025,"comp : continual multimodal pre training vision foundation model pre trained vision foundation model ( vfms ) provide strong visual representation wide range application . paper , continually pre train prevail vfms multimodal manner such can effortlessly process visual input vary size produce visual representation that be more aligned language representation , regardless original pre training process . to end , introduce comp , carefully design multimodal pre training pipeline . comp use continual rotary position embed to support native resolution continual pre training , alignment loss visual textual feature language prototype to align multimodal representation . three stage training , vfms achieve remarkable improvement not only multimodal understanding also other downstream task such classification segmentation . remarkably , comp siglip achieves score chartqa docvqa llm , maintain % accuracy miou frozen chunk evaluation ."
https://doi.org/10.48550/arXiv.2503.18923,"Meng Cao, Pengfei Hu, Yingyao Wang, Jihao Gu, Haoran Tang, Haoze Zhao, Jiahua Dong, Wangbo Yu, Ge Zhang, Ian Reid, Xiaodan Liang",CV,24/03/2025,"video simpleqa : towards factuality evaluation large video language model recent advancement large video language model ( lvlms ) have highlight potential multi modal understanding , yet evaluate factual grounding video context remain critical unsolved challenge . to address gap , introduce video simpleqa , first comprehensive benchmark tailor factuality evaluation lvlms . work distinguishes exist video benchmark following key feature : ) knowledge require : demand integration external knowledge explicit narrative ; ) fact seeking question : targeting objective , undisputed event relationship , avoid subjective interpretation ; ) definitive & short form answer : answer be craft unambiguous definitively correct short format , enable automate evaluation llm a a judge framework minimal score variance ; ) external source verify : annotation undergo rigorous validation authoritative external reference to ensure reliability ; ) temporal reasoning require : annotated question type encompass static single frame understanding dynamic temporal reasoning , explicitly evaluate lvlms factuality long context dependency . extensively evaluate state of the art lvlms summarize key finding follow : ) current lvlms exhibit notable deficiency factual adherence , particularly open source model . best performing model achieves merely f score % ; ) test time compute paradigm show insignificant performance gain , reveal fundamental constraint enhance factuality post hoc computation ; ) retrieval augmented generation demonstrate consistent improvement cost additional inference time overhead , present critical efficiency performance trade off ."
https://doi.org/10.48550/arXiv.2503.18903,"Moussa Kassem Sbeyti, Nadja Klein, Azarm Nowzad, Fikret Sivrikaya, Sahin Albayrak",CV,24/03/2025,"building block robust effective semi supervised real world object detection semi supervised object detection ( ssod ) base pseudo labeling significantly reduce dependence large label datasets effectively leverage label unlabeled data . however , real world application ssod often face critical challenge , include class imbalance , label noise , labeling error . present in depth analysis ssod real world condition , uncover cause suboptimal pseudo labeling key trade offs label quality quantity . base finding , propose four building block that can be seamlessly integrate ssod framework . rare class collage ( rcc ) : data augmentation method that enhance representation rare class create collage rare object . rare class focus ( rcf ) : stratified batch sample strategy that ensure more balanced representation class training . ground truth label correction ( glc ) : label refinement method identifies corrects false , miss , noisy ground truth label leverage consistency teacher model prediction . pseudo label selection ( pls ) : selection method remove low quality pseudo labeled image , guide novel metric estimate miss detection rate account class rarity . validate method comprehensive experiment autonomous drive datasets , result to % increase ssod performance . overall , investigation novel , data centric , broadly applicable building block enable robust effective ssod complex , real world scenario . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18897,"Thomas Chabal, Shizhe Chen, Jean Ponce, Cordelia Schmid",CV,24/03/2025,"online scene reconstruction use neural object prior paper address problem reconstruct scene online level object give rgb d video sequence . current object aware neural implicit representation hold promise , be limit online reconstruction efficiency shape completion . main contribution to alleviate above limitation be twofold . first , propose feature grid interpolation mechanism to continuously update grid based object centric neural implicit representation new object part be reveal . second , construct object library previously map object advance leverage corresponding shape prior to initialize geometric object model new video , subsequently complete novel view as well synthesize past view to avoid lose original object detail . extensive experiment synthetic environment replica dataset , real world scannet sequence video capture laboratory demonstrate approach outperform state of the art neural implicit model task term reconstruction accuracy completeness ."
https://doi.org/10.48550/arXiv.2503.18886,"Weichen Fan, Amber Yijia Zheng, Raymond A. Yeh, Ziwei Liu",CV,24/03/2025,"cfg zero * : improve classifier free guidance flow matching model classifier free guidance ( cfg ) be widely adopt technique model to improve image fidelity controllability . work , first analytically study effect cfg flow matching model train gaussian mixture where ground truth flow can be derive . observe early stage training , when flow estimation be inaccurate , cfg directs sample incorrect trajectory . building observation , propose cfg zero * , improved cfg two contribution : ( ) optimize scale , where scalar be optimize to correct inaccuracy estimated velocity , hence * name ; ( b ) zero init , which involve zero out first few step ode solver . experiment text to image ( lumina next , stable diffusion , flux ) text to video ( ) generation demonstrate cfg zero * consistently outperform cfg , highlight effectiveness guide flow matching model . ( code be available http url )"
https://doi.org/10.48550/arXiv.2503.18883,"Savas Ozkan, Andrea Maracani, Hyowon Kim, Sijun Cho, Eunchung Noh, Jeongwon Min, Jung Min Cho, Mete Ozay",CV,24/03/2025,"efficient accurate scene text recognition cascaded transformer recent year , vision transformer text decoder have demonstrate remarkable performance scene text recognition ( str ) due to ability to capture long range dependency contextual relationship high learn capacity . however , computational memory demand model be significant , limit deployment resource constrained application . to address challenge , propose efficient accurate str system . specifically , focus improve efficiency encoder model introduce cascaded transformers structure . structure progressively reduce vision token size encoding step , effectively eliminate redundant token reduce computational cost . experimental result confirm str system achieve comparable performance to state of the art baseline substantially decrease computational requirement . particular , large model , accuracy remain same , to , computational complexity be almost halve structure ."
https://doi.org/10.48550/arXiv.2503.18880,"Hyeonggon Ryu, Seongyu Kim, Joon Son Chung, Arda Senocak",CV,24/03/2025,"see speech sound : distinguishing locate audio visual scene present unified model capable simultaneously ground spoken language non speech sound visual scene , address key limitation current audio visual grounding model . exist approach be typically limited to handle speech non speech sound independently , best , together sequentially mix . limitation prevent capture complexity real world audio source that be often mixed . approach introduce ' framework audio visual alignment objective that jointly learn correspondence disentanglement use mixed audio . objective , model learn to produce distinct embeddings audio type , enable effective disentanglement grounding mixed audio source . additionally , create new dataset to evaluate simultaneous grounding mixed audio source , demonstrate model outperform prior method . approach also achieve comparable good performance standard segmentation cross modal retrieval task , highlight benefit mix and separate approach ."
https://doi.org/10.48550/arXiv.2503.18873,"Moein Sorkhei, Emir Konuk, Jingyu Guo, Christos Matsoukas, Kevin Smith",CV,24/03/2025,"efficient self supervised adaptation medical image analysis self supervised adaptation ( ssa ) improve foundation model transfer to medical domain be computationally prohibitive . parameter efficient fine tuning method such lora have be explore supervised adaptation , effectiveness ssa remain unknown . work , introduce efficient self supervised adaptation ( essa ) , framework that apply parameter efficient fine tuning technique to ssa aim reduce computational cost improve adaptation performance . method test , attention projection layer adaptation ( apla ) set new state of the art , consistently surpass full parameter ssa supervise fine tuning diverse medical task , reduce gpu memory to % increase training throughput % , maintain inference efficiency ."
https://doi.org/10.48550/arXiv.2503.18872,"Yanda Chen, Gongwei Chen, Miao Zhang, Weili Guan, Liqiang Nie",CV,24/03/2025,"curriculum coarse to fine selection high ipc dataset distillation dataset distillation ( dd ) excels synthesize small number image class ( ipc ) struggle to maintain effectiveness high ipc setting . recent work dataset distillation demonstrate combine distil real data can mitigate effectiveness decay . however , analysis combination paradigm reveals current one shot independent selection mechanism induce incompatibility issue distil real image . to address issue , introduce novel curriculum coarse to fine selection ( ccfs ) method efficient high ipc dataset distillation . ccfs employ curriculum selection framework real data selection , where leverage coarse to fine strategy to select appropriate real data base current synthetic dataset curriculum . extensive experiment validate ccfs , surpass state of the art % , % , % tiny imagenet high ipc setting . notably , ccfs achieve % test accuracy % compression ratio tiny imagenet , closely match full dataset training only % degradation . code : http url ."
https://doi.org/10.48550/arXiv.2503.18862,"DeShin Hwa, Tobias Holmes, Klaus Drechsler",CV,24/03/2025,"explore integration key value attention pure hybrid transformer semantic segmentation cnns be long consider state art image processing , introduction transformer architecture have challenge position . achieve excellent result image classification segmentation , transformer remain inherently reliant large train datasets remain computationally expensive . newly introduce transformer derivative name kv transformer show promise result synthetic , nlp , image classification task , reduce complexity memory usage . be especially conducive to use case where local inference be require , such medical screening application . endeavour to further evaluate merit kv transformer semantic segmentation task , specifically domain medical imaging . directly compare traditional kv variant same base architecture , provide further insight practical tradeoff reduced model complexity . observe notable reduction parameter count multiply accumulate operation , achieve similar performance most kv variant model when directly compare to qkv implementation ."
https://doi.org/10.48550/arXiv.2503.18860,"Zunnan Xu, Zhentao Yu, Zixiang Zhou, Jun Zhou, Xiaoyu Jin, Fa-Ting Hong, Xiaozhong Ji, Junwei Zhu, Chengfei Cai, Shiyu Tang, Qin Lin, Xiu Li, Qinglin Lu",CV,24/03/2025,"hunyuanportrait : implicit condition control enhanced portrait animation introduce , diffusion based condition control method that employ implicit representation highly controllable lifelike portrait animation . give single portrait image appearance reference video clip drive template , hunyuanportrait can animate character reference image facial expression head pose driving video . framework , utilize pre trained encoders to achieve decoupling portrait motion information identity video . to do so , implicit representation be adopt to encode motion information be employ control signal animation phase . leverage power stable video diffusion main building block , carefully design adapter layer to inject control signal denoising unet attention mechanism . bring spatial richness detail temporal consistency . hunyuanportrait also exhibit strong generalization performance , which can effectively disentangle appearance motion different image style . framework outperform exist method , demonstrate superior temporal consistency controllability . project be available http url ."
https://doi.org/10.48550/arXiv.2503.18854,"Ruichuan An, Sihan Yang, Ming Lu, Renrui Zhang, Kai Zeng, Yulin Luo, Jiajun Cao, Hao Liang, Ying Chen, Qi She, Shanghang Zhang, Wentao Zhang",CV,24/03/2025,"mc llava : multi concept personalized vision language model current vision language model ( vlms ) show exceptional ability diverse task , such visual question answer . to enhance user experience , recent study investigate vlm personalization to understand user provided concept . however , mainly focus single concept personalization , neglect existence interplay multiple concept , which limit real world applicability . paper propose first multi concept personalization paradigm , mc llava . specifically , mc llava employ multi concept instruction tune strategy , effectively integrate multiple concept single training step . to reduce cost relate to joint training , propose personalized textual prompt that use visual token information to initialize concept token . additionally , introduce personalized visual prompt inference , aggregate location confidence map enhanced recognition ground capability . to advance multi concept personalization research , further contribute high quality instruction tune dataset . carefully collect image multiple character object movie manually generate question answer sample multi concept scenario , feature superior diversity . comprehensive qualitative quantitative experiment demonstrate mc llava can achieve impressive multi concept personalized response , pave way vlms to become good user specific assistant . code dataset will be publicly available $ { http url } { http url } $ ."
https://doi.org/10.48550/arXiv.2503.18853,"Xiao Cao, Beibei Lin, Bo Wang, Zhiyong Huang, Robby T. Tan",CV,24/03/2025,": texture swap object single reference image texture swapping allow customization object texture , enable efficient versatile visual transformation editing . dedicated method exists , adapt editing text driven edit approach can serve purpose . however , edit require frame by frame manipulation , cause inconsistency view , text driven edit struggle to preserve texture characteristic reference image . to tackle challenge , introduce , texture swap method that integrate : ) progressive generation , ) view consistency gradient guidance , ) prompt tuned gradient guidance . to ensure view consistency , progressive generation process start edit single reference image gradually propagate edits to adjacent view . view consistency gradient guidance further reinforces consistency condition generation model feature difference consistent inconsistent output . to preserve texture characteristic , introduce prompt tuning based gradient guidance , which learn token that precisely capture difference reference image object . token then guide edit process , ensure more consistent texture preservation view . overall , integrates novel strategy to achieve higher fidelity texture transfer preserve structural coherence multiple viewpoint . extensive qualitative quantitative evaluation confirm three novel component enable convincing effective texture swap object . code will be available upon acceptance ."
https://doi.org/10.48550/arXiv.2503.18830,"Zhengxian Wu, Chuanrui Zhang, Hangrui Xu, Peng Jiao, Haoqian Wang",CV,24/03/2025,"dagait : generalize skeleton guided data alignment gait recognition gait recognition be emerge promising innovative area field computer vision , widely apply to remote person identification . exist gait recognition method have achieve substantial success controlled laboratory datasets , performance often decline significantly when transition to wild http url argue performance gap can be primarily attribute to spatio temporal distribution inconsistency present wild datasets , where subject appear vary angle , position , distance frame . to achieve accurate gait recognition wild , propose skeleton guided silhouette alignment strategy , which use prior knowledge skeleton to perform affine transformation corresponding http url best knowledge , be first study to explore impact data alignment gait recognition . conduct extensive experiment multiple datasets network architecture , result demonstrate significant advantage propose alignment http url , challenge dataset , method achieve average performance improvement % evaluate network . furthermore , method achieve substantial improvement cross domain datasets , accuracy improvement to % ."
https://doi.org/10.48550/arXiv.2503.18817,"Jeonghyeon Kim, Sangheum Hwang",CV,24/03/2025,"enhance ood detection cross modal alignment multi modal representation prior research out of distribution detection ( oodd ) have primarily focus single modality model . recently , advent large scale pretrained vision language model such clip , oodd method utilize such multi modal representation zero shot prompt learning strategy have emerge . however , method typically involve either freeze pretrained weight only partially tune , which can be suboptimal downstream datasets . paper , highlight multi modal fine tuning ( mmft ) can achieve notable oodd performance . recent work demonstrate impact fine tuning method oodd , there remain significant potential performance improvement . investigate limitation naïve fine tuning method , examine why fail to fully leverage pretrained knowledge . empirical analysis suggest issue could stem modality gap in distribution ( id ) embeddings . to address , propose training objective that enhance cross modal alignment regularize distance image text embeddings id data . adjustment help good utilizing pretrained textual information align similar semantics different modality ( , text image ) more closely hyperspherical representation space . theoretically demonstrate propose regularization correspond to maximum likelihood estimation energy based model hypersphere . utilizing ood benchmark datasets , show method , combine post hoc oodd approach leverage pretrained knowledge ( , neglabel ) , significantly outperform exist method , achieve state of the art oodd performance lead id accuracy ."
https://doi.org/10.48550/arXiv.2503.18812,"Shrikant Malviya, Neelanjan Bhowmik, Stamos Katsigiannis",CV,24/03/2025,"skdu de factify : vision transformer data augmentation ai generated image detection aim work be to explore potential pre trained vision language model , . vision transformer ( vit ) , enhance advanced data augmentation strategy detection ai generated image . approach leverage fine tuned vit model train dataset , which include image generate state of the art model such stable diffusion , stable diffusion xl , stable diffusion , dall e , midjourney . employ perturbation technique flip , rotation , gaussian noise injection , jpeg compression training to improve model robustness generalisation . experimental result demonstrate vit based pipeline achieve state of the art performance , significantly outperform compete method validation test datasets ."
https://doi.org/10.48550/arXiv.2503.18808,"Yang Liu, Hongjin Wang, Zepu Wang, Xiaoguang Zhu, Jing Liu, Peng Sun, Rui Tang, Jianwei Du, Victor C.M. Leung, Liang Song",CV,24/03/2025,"crcl : causal representation consistency learn anomaly detection surveillance video video anomaly detection ( vad ) remain fundamental yet formidable task video understand community , promising application area such information forensics public safety protection . due to rarity diversity anomaly , exist method only use easily collect regular event to model inherent normality normal spatial temporal pattern unsupervised manner . previous study have show exist unsupervised vad model be incapable label independent data offset ( , scene change ) real world scenario may fail to respond to light anomaly due to overgeneralization deep neural network . inspire causality learning , argue there exist causal factor that can adequately generalize prototypical pattern regular event present significant deviation when anomalous instance occur . regard , propose causal representation consistency learning ( crcl ) to implicitly mine potential scene robust causal variable unsupervised video normality learning . specifically , build structural causal model , propose scene debiasing learning causality inspired normality learn to strip away entangled scene bias deep representation learn causal video normality , respectively . extensive experiment benchmark validate superiority method conventional deep representation learning . moreover , ablation study extension validation show crcl can cope label independent bias multi scene setting maintain stable performance only limited training data available ."
https://doi.org/10.48550/arXiv.2503.18803,"Duowang Zhu, Xiaohu Huang, Haiyan Huang, Hao Zhou, Zhenfeng Shao",CV,24/03/2025,": revisiting change detection caption video model perspective paper , present , framework that reconceptualizes change detection captioning task video modeling . recent method have achieve remarkable success regard pair bi temporal image separate frame . employ shared weight image encoder to extract spatial feature then use change extractor to capture difference two image . however , image feature encode , be task agnostic process , can not attend to change region effectively . furthermore , different change extractor design various change detection caption task make difficult to have unified framework . to tackle challenge , regard bi temporal image comprise two frame akin to tiny video . integrate learnable perception frame bi temporal image , video encoder enable perception frame to interact image directly perceive difference . therefore , can get rid intricate change extractor , provide unified framework different change detection caption task . verify multiple task , encompass change detection ( include binary change detection , semantic change detection , building damage assessment ) change captioning , eight standard benchmark . bell whistle , simple yet effective framework can achieve superior performance ultra light video model comprise only % % parameter % % flop compare to state of the art method . hope could be alternative to model facilitate future research ."
https://doi.org/10.48550/arXiv.2503.18794,"Yulong Zheng, Zicheng Jiang, Shengfeng He, Yandu Sun, Junyu Dong, Huaidong Zhang, Yong Du",CV,24/03/2025,"nexusgs : sparse view synthesis epipolar depth prior gaussian splatting neural radiance field ( nerf ) gaussian splatting ( ) have noticeably advance photo realistic novel view synthesis use image densely space camera viewpoint . however , method struggle few shot scenario due to limited supervision . paper , present nexusgs , approach that enhance novel view synthesis sparse view image directly embed depth information point cloud , rely complex manual regularization . exploit inherent epipolar geometry , method introduce novel point cloud densification strategy that initialize dense point cloud , reduce randomness point placement prevent over smoothing overfitting . specifically , nexusgs comprises three key step : epipolar depth nexus , flow resilient depth blending , flow filtered depth pruning . step leverage optical flow camera pose to compute accurate depth map , mitigate inaccuracy often associate optical flow . incorporate epipolar depth prior , nexusgs ensures reliable dense point cloud coverage support stable train sparse view condition . experiment demonstrate nexusgs significantly enhance depth accuracy render quality , surpass state of the art method considerable margin . furthermore , validate superiority generated point cloud substantially boost performance compete method . project page : http url ."
https://doi.org/10.48550/arXiv.2503.18785,Zifa Chen,CV,24/03/2025,"lgi detr : local global interaction uav object detection uav have be widely use various field . however , most exist object detector use drone be not end to end require design various complex component careful fine tuning . most exist end to end object detector be design natural scene . be not ideal to apply directly to uav image . order to solve above challenge , design local global information interaction detr uavs , namely lgi detr . cross layer bidirectional low level high level feature information enhancement , fusion method be effective especially field small objection detection . initial stage encoder , propose local spatial enhancement module ( lse ) , which enhance low level rich local spatial information high level feature , reduce loss local information transmission process high level information . final stage encoder , propose novel global information injection module ( gii ) design to integrate rich high level global semantic representation low level feature map . hierarchical fusion mechanism effectively address inherent limitation local receptive field propagate contextual information feature hierarchy . experimental result two challenge uav image object detection benchmark , uavdt , show propose model outperform sota model . compare to baseline model , ap improve % % , respectively ."
https://doi.org/10.48550/arXiv.2503.18784,"Wenxi Chen, Raymond A. Yeh, Shaoshuai Mou, Yan Gu",CV,24/03/2025,"leverage perturbation robustness to enhance out of distribution detection out of distribution ( ood ) detection be task identify input that deviate training data distribution . capability be essential safely deploy deep computer vision model open world environment . work , propose post hoc method , perturbation rectified ood detection ( pro ) , base insight that prediction confidence ood input be more susceptible to reduction perturbation in distribution ( ind ) input . base observation , propose adversarial score function that search local minimum score original input apply gradient descent . procedure enhance separability ind ood sample . importantly , approach improve ood detection performance complex modification to underlie model architecture . conduct extensive experiment use openood { } . approach far push limit softmax based ood detection be lead post hoc method small scale model . model adversarial training , pro effectively detect near ood input , achieve reduction more % fpr @ compare to state of the art method ."
https://doi.org/10.48550/arXiv.2503.18783,"Linwei Chen, Lin Gu, Liang Li, Chenggang Yan, Ying Fu",CV,24/03/2025,"frequency dynamic convolution dense image prediction dynamic convolution ( dy conv ) have show promising performance enable adaptive weight selection multiple parallel weight combine attention mechanism , frequency response weight tend to exhibit high similarity , result high parameter cost limited adaptability . work , introduce frequency dynamic convolution ( fdconv ) , novel approach that mitigate limitation learn fixed parameter budget fourier domain . fdconv divide budget frequency based group disjoint fourier index , enable construction frequency diverse weight increase parameter cost . to further enhance adaptability , propose kernel spatial modulation ( ksm ) frequency band modulation ( fbm ) . ksm dynamically adjust frequency response filter spatial level , fbm decomposes weight distinct frequency band frequency domain modulate dynamically base local content . extensive experiment object detection , segmentation , classification validate effectiveness fdconv . demonstrate when apply to , fdconv achieves superior performance modest increase parameter , outperform previous method that require substantial increase parameter budget ( , condconv , kw ) . moreover , fdconv seamlessly integrate variety architecture , include convnext , swin transformer , offer flexible efficient solution modern vision task . code be make publicly available http url ."
https://doi.org/10.48550/arXiv.2503.18767,"Konstantin Pakulev, Alexander Vakhitov, Gonzalo Ferrer",CV,24/03/2025,"good keypoints two view geometry estimation problem local feature be essential to many modern downstream application . therefore , be interest to determine property local feature that contribute to downstream performance good design feature detector descriptor . work , propose new theoretical model score feature point ( keypoints ) context two view geometry estimation problem . model determine two property good keypoint solve homography estimation problem should have : be repeatable have small expect measurement error . result provide key insight why maximize number correspondence do always lead to good homography estimation accuracy . use developed model to design method that detect keypoints that benefit homography estimation introduce bound ness st ( boness st ) keypoint detector . novelty boness st come strong theoretical foundation , more accurate keypoint score due to subpixel refinement cost design superior robustness to low saliency keypoints . result , boness st outperforms prior self supervised local feature detector planar homography epipolar geometry estimation problem ."
https://doi.org/10.48550/arXiv.2503.18755,"Nathan Darjana, Ryo Fujii, Hideo Saito, Hiroki Kajita",CV,24/03/2025,"egosurgery hts : dataset egocentric hand tool segmentation open surgery video egocentric open surgery video capture rich , fine grained detail essential accurately model surgical procedure human behavior operating room . detailed , pixel level understanding hand surgical tool be crucial interpret surgeon action intention . introduce egosurgery hts , new dataset pixel wise annotation benchmark suite segment surgical tool , hand , interact tool egocentric open surgery video . specifically , provide labeled dataset ( ) tool instance segmentation distinct surgical tool , ( ) hand instance segmentation , ( ) hand tool segmentation to label hand tool manipulate . use egosurgery hts , conduct extensive evaluation state of the art segmentation method demonstrate significant improvement accuracy hand hand tool segmentation egocentric open surgery video compare to exist datasets . dataset will be release http url ."
https://doi.org/10.48550/arXiv.2503.18753,"Qin Wang, Benjamin Bruns, Hanno Scharr, Kai Krajsek",CV,24/03/2025,"self supervised learning base transformed image reconstruction equivariance coherent feature representation equivariant behaviour feature be essential many computer vision task , yet popular self supervised learning ( ssl ) method tend to constrain equivariance design . propose self supervised learning approach where system learn transformation independently reconstruct image that have undergo previously unseen transformation . specifically , model be task to reconstruct intermediate transform image , . translate rotate image , prior knowledge transformation . auxiliary task encourage model to develop equivariance coherent feature rely predefined transformation rule . to end , apply transformation to input image , generate image pair , then split extracted feature two set image . one set be use usual ssl loss encourage invariance , other loss base auxiliary task to reconstruct intermediate transform image . loss ssl loss be linearly combine weighted term . evaluate synthetic task natural image , propose method strongly outperform competitor , regardless be design to learn equivariance . furthermore , when trained alongside augmentation based method invariance task , such ibot , successfully learn balanced combination invariant equivariant feature . approach perform strong rich set realistic computer vision downstream task , almost always improve baseline ."
https://doi.org/10.48550/arXiv.2503.18746,"Yifei Zhang, Chang Liu, Jin Wei, Xiaomeng Yang, Yu Zhou, Can Ma, Xiangyang Ji",CV,24/03/2025,"linguistics aware mask image model self supervised scene text recognition text image be unique dual nature , encompass visual linguistic information . visual component encompass structural appearance based feature , linguistic dimension incorporate contextual semantic element . scenario degraded visual quality , linguistic pattern serve crucial supplement comprehension , highlight necessity integrate aspect robust scene text recognition ( str ) . contemporary str approach often use language model semantic reasoning module to capture linguistic feature , typically require large scale annotated datasets . self supervised learning , which lack annotation , present challenge disentangle linguistic feature relate to global context . typically , sequence contrastive learning emphasize alignment local feature , mask image modeling ( mim ) tend to exploit local structure to reconstruct visual pattern , result limited linguistic knowledge . paper , propose linguistics aware masked image modeling ( lmim ) approach , which channel linguistic information decode process mim separate branch . specifically , design linguistics alignment module to extract vision independent feature linguistic guidance use input different visual appearance . feature extend mere visual structure , lmim must consider global context to achieve reconstruction . extensive experiment various benchmark quantitatively demonstrate state of the art performance , attention visualization qualitatively show simultaneous capture visual linguistic information ."
https://doi.org/10.48550/arXiv.2503.18742,"Sebastian Tewes, Yufan Chen, Omar Moured, Jiaming Zhang, Rainer Stiefelhagen",CV,24/03/2025,"sfdla : source free document layout analysis document layout analysis ( dla ) be fundamental task document understanding . however , exist dla adaptation method often require access to large scale source data target label . requirement severely limit real world applicability , particularly privacy sensitive resource constrained domain , such financial statement , medical record , proprietary business document . accord to observation , directly transfer source domain fine tuned model target domain often result significant performance drop ( avg . % ) . work , introduce source free document layout analysis ( sfdla ) , aim adapt pre trained source dla model to unlabeled target domain , access to source data . to address challenge , establish first sfdla benchmark , cover three major dla datasets geometric  content aware adaptation . furthermore , propose document layout analysis adapter ( dladapter ) , novel framework that be design to improve source free adaptation document domain . method achieve % improvement source only baseline % gain exist source free method publaynet to doclaynet . believe work will inspire dla community to further investigate source free document understanding . to support future research community , benchmark , model , code will be publicly available http url ."
https://doi.org/10.48550/arXiv.2503.18725,"Zimin Xia, Alexandre Alahi",CV,24/03/2025,"fg $ $ : fine grained cross view localization fine grained feature match propose novel fine grained cross view localization method that estimate degree freedom pose ground level image aerial image surroundings match fine grained feature two image . pose be estimate align point plane generate ground image point plane sample aerial image . to generate ground point , first map ground image feature to point cloud . method then learn to select feature height dimension to pool point to ( bev ) plane . selection enable to trace which feature ground image contribute to bev representation . next , sample set sparse match compute point correspondence two point plane compute relative pose use procrustes alignment . compare to previous state of the art , method reduce mean localization error % vigor cross area test set . qualitative result show method learn semantically consistent match ground aerial view weakly supervise learn camera pose ."
https://doi.org/10.48550/arXiv.2503.18719,"Cong Liu, Liang Hou, Mingwu Zheng, Xin Tao, Pengfei Wan, Di Zhang, Kun Gai",CV,24/03/2025,"boost resolution generalization diffusion transformer randomized positional encoding resolution generalization image generation task enable production higher resolution image low training resolution overhead . however , significant challenge resolution generalization , particularly widely use diffusion transformer , lie mismatch positional encoding encounter test use training . exist method have employ technique such interpolation , extrapolation , combination , none have fully resolve issue . paper , propose novel two dimensional randomize positional encoding ( ) framework that focus learn positional order image patch instead specific distance , enable seamless high  low resolution image generation require high  low resolution image training . specifically , independently select position broad range horizontal vertical ax , ensure position encoding be train inference phase , thus improve resolution generalization . additionally , propose random data augmentation technique to enhance modeling position order . to address issue image cropping cause augmentation , introduce correspond micro conditioning to enable model to perceive specific cropping pattern . imagenet dataset , propose achieves state of the art resolution generalization performance , outperform exist competitive method when train resolution $ $ infer $ $ $ $ , as well when scale $ $ to $ $ $ $ . also exhibit outstanding capability low resolution image generation , multi stage training acceleration multi resolution inheritance ."
https://doi.org/10.48550/arXiv.2503.18718,"Lijiang Li, Jinglu Wang, Xiang Ming, Yan Lu",CV,24/03/2025,"g marker : generalizable robust watermarking gaussian splatting generative ai era , safeguard model have become increasingly urgent . invisible watermarking be well established image encoder decoder framework , generalizable robust solution remain elusive . main difficulty arises renderer encoder decoder , which disrupt direct gradient flow complicate train . exist method typically rely per scene iterative optimization , result time inefficiency limited generalization . work , propose single pas watermarking approach gaussian splatting ( ) , well known yet underexplored representation watermarking . identify two major challenge : ( ) ensure effective training generalize diverse model , ( ) reliably extract watermark free view rendering , even distortion . framework , name g marker , incorporate encoder to embed message , distortion layer to enhance resilience various distortion , decoder to extract watermark rendering . key innovation be adaptive marker control mechanism that adaptively perturb initially optimized , escape local minimum improve training stability convergence . extensive experiment show g marker outperforms per scene training approach term decode accuracy model fidelity , also significantly reduce computation time ."
https://doi.org/10.48550/arXiv.2503.18712,"Shaokai Ye, Haozhe Qi, Alexander Mathis, Mackenzie W. Mathis",CV,24/03/2025,"llavaction : evaluating train multi modal large language model action recognition understand human behavior require measure behavioral action . due to complexity , behavior be best map rich , semantic structure such language . recent development multi modal large language model ( mllms ) be promising candidate wide range action understand task . work , focus evaluating then improve mllms to perform action recognition . reformulate , one large most challenging egocentric action datasets , to form video multiple question answer ( ) . show when sample difficult incorrect answer distractors , lead mllms struggle to recognize correct action . propose series method that greatly improve mllms ' ability to perform action recognition , achieve state of the art validation set , as well outperform point accuracy . lastly , show improvement other action related video benchmark such egoschema , perceptiontest , longvideobench , videomme mvbench , suggest mllms be promising path forward complex action task . code model be available : http url ."
https://doi.org/10.48550/arXiv.2503.18711,"Thomas Sugg, Kyle O'Brien, Lekh Poudel, Alex Dumouchelle, Michelle Jou, Marc Bosch, Deva Ramanan, Srinivasa Narasimhan, Shubham Tulsiani",CV,24/03/2025,": novel view synthesis dataset paper introduce , specialized dataset design research novel view synthesis specifically airborne ground imagery . data be collect austin , tx pittsburgh , pa collection encompass six diverse real world scene capture airborne ground camera , result total image . address challenge such vary altitude transient object . dataset be intend to supplement exist datasets , provide additional resource comprehensive research , rather serve benchmark ."
https://doi.org/10.48550/arXiv.2503.18709,"Boqi Chen, Cédric Vincent-Cuaz, Lydia A. Schoenpflug, Manuel Madeira, Lisa Fournier, Vaishnavi Subramanian, Sonali Andani, Samuel Ruiperez-Campillo, Julia E. Vogt, Raphaëlle Luisier, Dorina Thanou, Viktor H. Koelzer, Pascal Frossard, Gabriele Campanella, Gunnar Rätsch",CV,24/03/2025,"revisit automatic data curation vision foundation model digital pathology vision foundation model ( fm ) be accelerate development digital pathology algorithm transform biomedical research . model learn , self supervised manner , to represent histological feature highly heterogeneous tile extract whole slide image ( wsis ) real world patient sample . performance fm be significantly influence size , diversity , balance pre training data . however , data selection have be primarily guide expert knowledge wsi level , focus factor such disease classification tissue type , largely overlook granular detail available tile level . paper , investigate potential unsupervised automatic data curation tile level , take account million tile . specifically , apply hierarchical clustering tree to pre extracted tile embeddings , allow to sample balanced datasets uniformly embed space pretrained fm . further identify datasets be subject to trade off size balance , potentially compromise quality representation learn fm , propose tailored batch sample strategy to mitigate effect . demonstrate effectiveness method improve performance diverse range clinically relevant downstream task ."
https://doi.org/10.48550/arXiv.2503.18705,"Inseung Hwang, Kiseok Choi, Hyunho Ha, Min H. Kim",CV,24/03/2025,"benchmarking burst super resolution polarization image : noise dataset analysis snapshot polarization image calculates polarization state linearly polarize subimages . to achieve , polarization camera employ double bayer patterned sensor to capture color polarization . demonstrate low light efficiency low spatial resolution , result increase noise compromise polarization measurement . burst super resolution effectively reduce noise enhance spatial resolution , apply to polarization image pose challenge due to lack tailored datasets reliable ground truth noise statistic . to address issue , introduce polarns polarburstsr , two innovative datasets develop specifically polarization imaging . polarns provide characterization polarization noise statistic , facilitate thorough analysis , polarburstsr function benchmark burst super resolution polarization image . datasets , collect various real world condition , enable comprehensive evaluation . additionally , present model analyze polarization noise to quantify noise propagation , test large dataset capture darkroom environment . part application , compare late burst super resolution model , highlight advantage training tailor to polarization compare to rgb based method . work establish benchmark polarization burst super resolution offer critical insight noise propagation , thereby enhance polarization image reconstruction ."
https://doi.org/10.48550/arXiv.2503.18703,"Guanglu Dong, Tianheng Zheng, Yuanzhouhan Cao, Linbo Qing, Chao Ren",CV,24/03/2025,"channel consistency prior self reconstruction strategy base unsupervised image deraining recently , deep image deraining model base paired datasets have make series remarkable progress . however , can not be well apply real world application due to difficulty obtain real pair datasets poor generalization performance . paper , propose novel channel consistency prior self reconstruction strategy base unsupervised image deraining framework , csud , to tackle aforementioned challenge . train unpaired data , csud be capable generate high quality pseudo clean rainy image pair which be use to enhance performance deraining network . specifically , to preserve more image background detail transfer rain streak rainy image to unpaired clean image , propose novel channel consistency loss ( ccloss ) introduce channel consistency prior ( ccp ) rain streak training process , thereby ensure generated pseudo rainy image closely resemble real one . furthermore , propose novel self reconstruction ( sr ) strategy to alleviate redundant information transfer problem generator , far improve deraining performance generalization capability method . extensive experiment multiple synthetic real world datasets demonstrate deraining performance csud surpass other state of the art unsupervised method csud exhibit superior generalization capability ."
https://doi.org/10.48550/arXiv.2503.18695,"Luyao Tang, Yuxuan Yuan, Chaoqi Chen, Zeyu Zhang, Yue Huang, Kun Zhang",CV,24/03/2025,"ocrt : boosting foundation model open world object concept relation triad foundation model ( fm ) claim to be powerful , generalization ability significantly decrease when face distribution shift , weak supervision , malicious attack open world . other hand , most domain generalization adversarial fine tuning method be task related model specific , ignore universality practical application transferability fm . paper delve problem generalize fm to out of domain data . propose novel framework , object concept relation triad ( ocrt ) , that enable fms to extract sparse , high level concept intricate relational structure raw visual input . key idea be to bind object visual scene set object centric representation unsupervised decoupling iterative refinement . to be specific , project object centric representation semantic concept space model can readily interpret estimate importance to filter out irrelevant element . then , concept based graph , which have flexible degree , be construct to incorporate set concept corresponding importance , enable extraction high order factor informative concept facilitate relational reasoning concept . extensive experiment demonstrate ocrt can substantially boost generalizability robustness sam clip multiple downstream task ."
https://doi.org/10.48550/arXiv.2503.18682,"Samuel Rota Bulò, Nemanja Bartolovic, Lorenzo Porzi, Peter Kontschieder",CV,24/03/2025,"hardware rasterized ray based gaussian splatting present novel , hardware rasterize render approach ray based gaussian splatting ( raygs ) , obtain fast high quality result novel view synthesis . work contain mathematically rigorous geometrically intuitive derivation how to efficiently estimate relevant quantity render raygs model , structure respect to standard hardware rasterization shaders . solution be first enable render raygs model sufficiently high frame rate to support quality sensitive application virtual mixed reality . second contribution enable alias free render raygs , address mip related issue arise when render diverge scale training test . demonstrate significant performance gain , different benchmark scene , retain state of the art appearance quality raygs ."
https://doi.org/10.48550/arXiv.2503.18678,"Tianyi Wang, Harry Cheng, Xiao Zhang, Yinglong Wang",CV,24/03/2025,"nullswap : proactive identity cloak deepfake face swap suffer performance bottleneck passively detect high quality deepfake image due to advancement generative model , proactive perturbation offer promising approach to disable deepfake manipulation insert signal benign image . however , exist proactive perturbation approach remain unsatisfactory several aspect : ) visual degradation due to direct element wise addition ; ) limit effectiveness face swap manipulation ; ) unavoidable reliance white  grey box setting to involve generative model training . study , analyze essence deepfake face swapping argue necessity protect source identity rather target image , propose nullswap , novel proactive defense approach that cloak source image identity nullifies face swap pure black box scenario . design identity extraction module to obtain facial identity feature source image , perturbation block be then devise to generate identity guided perturbation accordingly . meanwhile , feature block extract shallow level image feature , which be then fuse perturbation cloaking block image reconstruction . furthermore , to ensure adaptability different identity extractor face swap algorithm , propose dynamic loss weight to adaptively balance identity loss . experiment demonstrate outstanding ability approach to fool various identity recognition model , outperform state of the art proactive perturbation prevent face swap model generate image correct source identity ."
https://doi.org/10.48550/arXiv.2503.18674,"Edoardo De Matteis, Matteo Migliarini, Alessio Sampieri, Indro Spinelli, Fabio Galasso",CV,24/03/2025,"human motion unlearning introduce task human motion unlearning to prevent synthesis toxic animation preserve general text to motion generative performance . unlearning toxic motion be challenge can be generate explicit text prompt implicit toxic combination safe motion ( , kicking be load swing leg ) . propose first motion unlearn benchmark filter toxic motion large recent text to motion datasets motion x . propose baseline , adapt state of the art image unlearn technique to process spatio temporal signal . finally , propose novel motion unlearn model base latent code replacement , which dub lcr . lcr be training free suitable to discrete latent space state of the art text to motion diffusion model . lcr be simple consistently outperform baseline qualitatively quantitatively . project page : { http url } { http url } ."
https://doi.org/10.48550/arXiv.2503.18673,"Taeyeop Lee, Bowen Wen, Minjun Kang, Gyuree Kang, In So Kweon, Kuk-Jin Yoon",CV,24/03/2025,": model free pose estimation novel object introduce , model free framework object pose estimation that require only single rgb d anchor image to estimate pose size unknown object novel scene . exist method that rely textured model multiple viewpoint , leverage joint object alignment process to enhance alignment metric scale estimation improve pose accuracy . approach integrate render and compare strategy to generate refine pose hypothesis , enable robust performance scenario occlusion , non overlapping view , diverse lighting condition , large cross environment variation . evaluate method five challenge datasets : , toyota light , , ycbineoat , lm o , demonstrate effectiveness significantly outperform state of the art method novel object pose estimation . project page : http url"
https://doi.org/10.48550/arXiv.2503.18672,"Juncen Guo, Xiaoguang Zhu, Lianlong Sun, Liangyu Teng, Di Li, Yang Liu, Liang Song",CV,24/03/2025,"feature calibration enhance parameter synthesis clip based class incremental learning class incremental learning ( cil ) enable model to continuously learn new class knowledge memorize previous class , facilitate adaptation evolution dynamic environment . traditional cil method be mainly base visual feature , which limit ability to handle complex scenario . contrast , vision language model ( vlms ) show promise potential to promote cil integrate pretrained knowledge textual feature . however , previous method make difficult to overcome catastrophic forget preserve generalization capability vlms . to tackle challenge , propose feature calibration enhance parameter synthesis ( fcps ) paper . specifically , fcps employ specific parameter adjustment mechanism to iteratively refine proportion original visual feature participate final class determination , ensure model foundational generalization capability . meanwhile , parameter integration different task achieve balance learn new class knowledge retain old knowledge . experimental result popular benchmark ( , ) validate superiority propose method ."
https://doi.org/10.48550/arXiv.2503.18671,"Yihan Chen, Wenfei Yang, Huan Ren, Shifeng Zhang, Tianzhu Zhang, Feng Wu",CV,24/03/2025,"structure aware correspondence learning relative pose estimation relative pose estimation provide promising way achieve object agnostic pose estimation . success exist correspondence based method , reliance explicit feature match suffers small overlap visible region unreliable feature estimation invisible region . inspire human ' ability to assemble two object part that have small overlap region consider object structure , propose novel structure aware correspondence learning method relative pose estimation , which consist two key module . first , structure aware keypoint extraction module be design to locate set kepoints that can represent structure object different shape appearance , guidance keypoint base image reconstruction loss . second , structure aware correspondence estimation module be design to model intra image inter image relationship keypoints to extract structure aware feature correspondence estimation . jointly leverage two module , propose method can naturally estimate correspondence unseen object explicit feature match precise relative pose estimation . experimental result , objaverse linemod datasets demonstrate propose method significantly outperform prior method , , mean angular error dataset ."
https://doi.org/10.48550/arXiv.2503.18665,"Bingchen Miao, Yang Wu, Minghe Gao, Qifan Yu, Wendong Bu, Wenqiao Zhang, Yunfei Li, Siliang Tang, Tat-Seng Chua, Juncheng Li",CV,24/03/2025,"boost virtual agent learning reasoning : step wise , multi dimensional , generalist reward model benchmark development generalist virtual agent ( gvas ) power multimodal large language model ( mllms ) have show significant promise autonomous task execution . however , current training paradigm face critical limitation , include reliance outcome supervision labor intensive human annotation . to address challenge , propose similar , step wise multi dimensional generalist reward model , which offer fine grained signal agent training can choose good action inference time scaling . specifically , begin systematically define five dimension evaluate agent action . building framework , design mcts p algorithm to automatically collect annotate step wise , five dimensional agent execution data . use data , train similar triple m strategy . furthermore , introduce first benchmark virtual agent domain step wise , multi dimensional reward model training evaluation , name srm . benchmark consist two component : srmtrain , which serve training set similar , srmeval , manually select test set evaluate reward model . experimental result demonstrate similar , step wise , multi dimensional assessment synergistic gain , provide gvas effective intermediate signal training inference time scaling . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18658,"Christopher Ummerle, Antonio Giganti, Sara Mandelli, Paolo Bestagini, Stefano Tubaro",CV,24/03/2025,"leverage land cover prior isoprene emission super resolution remote sense play crucial role monitor earth ecosystem , yet satellite derived data often suffer limited spatial resolution , restrict applicability atmospheric modeling climate research . work , propose deep learning based super resolution ( sr ) framework that leverage land cover information to enhance spatial accuracy biogenic volatile organic compound ( bvocs ) emission , particular focus isoprene . approach integrate land cover prior emission driver , capture spatial pattern more effectively traditional method . evaluate model performance various climate condition analyze statistical correlation isoprene emission key environmental information such cropland tree cover data . additionally , assess generalization capability sr model apply to unseen climate zone geographical region . experimental result demonstrate incorporate land cover data significantly improve emission sr accuracy , particularly heterogeneous landscape . study contribute to atmospheric chemistry climate modeling provide cost effective , data driven approach to refine bvoc emission map . propose method enhance usability satellite based emission data , support application air quality forecasting , climate impact assessment , environmental study ."
https://doi.org/10.48550/arXiv.2503.18652,"Yaoyao Yun, Jianwen Xu",CV,24/03/2025,"robust face recognition base wing loss $ $ regularization recent year , sparse sample technique base regression analysis have witness extensive application face recognition research . presently , numerous sparse sample model base regression analysis have be explore various researcher . nevertheless , recognition rate majority model would be significantly decrease when confront highly occlude highly damaged face image . paper , new wing constrained sparse cod model ( wcsc ) weighted version ( wwcsc ) be introduce , so to deal face recognition problem complex circumstance , where alternate direction method multiplier ( admm ) algorithm be employ to solve corresponding minimization problem . addition , performance propose method be examine base four well known facial database , namely orl facial database , yale facial database , ar facial database feret facial database . also , compare to other method literature , wwcsc have very high recognition rate even complex situation where face image have high occlusion high damage , which illustrate robustness wwcsc method facial recognition ."
https://doi.org/10.48550/arXiv.2503.18640,"Haoran Wang, Jingwei Huang, Lu Yang, Tianchen Deng, Gaojing Zhang, Mingrui Li",CV,24/03/2025,"llgs : unsupervised gaussian splatting image enhancement reconstruction pure dark environment gaussian splatting have show remarkable capability novel view render task exhibit significant potential multi view http url , original gaussian splatting lack color representation input low light environment . simply use enhance image input would lead to issue multi view consistency , current single view enhancement system rely pre trained data , lack scene generalization . problem limit application gaussian splatting low light condition field robotics , include high fidelity modeling feature matching . to address challenge , propose unsupervised multi view stereoscopic system base gaussian splatting , call low light gaussian splatting ( llgs ) . system aim to enhance image low light environment reconstruct scene . method introduce decomposable gaussian representation call m color , which separately characterize color information targeted enhancement . furthermore , propose unsupervised optimization method zero knowledge prior , use direction based enhancement to ensure multi view consistency . experiment conduct real world datasets demonstrate system outperform state of the art method low light enhancement gaussian splatting ."
https://doi.org/10.48550/arXiv.2503.18637,"Nina Shvetsova, Arsha Nagrani, Bernt Schiele, Hilde Kuehne, Christian Rupprecht",CV,24/03/2025,"unbiasing textual description : mitigate representation bias video benchmark propose new unbiased textual description ( utd ) video benchmark base unbiased subset exist video classification retrieval datasets to enable more robust assessment video understanding capability . namely , tackle problem that current video benchmark may suffer different representation bias , , object bias single frame bias , where mere recognition object utilization only single frame be sufficient correct prediction . leverage vlms llm to analyze debias benchmark such representation bias . specifically , generate frame wise textual description video , filter specific information ( . only object ) leverage to examine representation bias three dimension : ) concept bias - determine specific concept ( , object ) alone suffice prediction ; ) temporal bias - assess temporal information contributes to prediction ; ) common sense dataset bias - evaluate zero shot reasoning dataset correlation contribute to prediction . conduct systematic analysis popular video classification retrieval datasets create new object debiased test split datasets . moreover , benchmark state of the art video model original debiased split analyze bias model . to facilitate future development more robust video understand benchmark model , release : utd description , dataset rich structured description dataset , utd splits , dataset object debiased test split ."
https://doi.org/10.48550/arXiv.2503.18635,"Hui Li, Congcong Bian, Zeyang Zhang, Xiaoning Song, Xi Li, Xiao-Jun Wu",CV,24/03/2025,"occo : lvm guided infrared visible image fusion framework base object aware contextual contrastive learning image fusion be crucial technique field computer vision , goal be to generate high quality fused image improve performance downstream task . however , exist fusion method struggle to balance two factor . achieve high quality fused image may result low performance downstream visual task , vice versa . to address drawback , novel lvm ( large vision model )  guide fusion framework object aware contextual contrastive learning be propose , term occo . pre trained lvm be utilize to provide semantic guidance , allow network to focus solely fusion task emphasize learn salient semantic feature form contrastive learning . additionally , novel feature interaction fusion network be also design to resolve information conflict fusion image cause modality difference . learn distinction positive sample negative sample latent feature space ( contextual space ) , integrity target information fused image be improve , thereby benefit downstream performance . finally , compare eight state of the art method four datasets , effectiveness propose method be validate , exceptional performance be also demonstrate downstream visual task ."
https://doi.org/10.48550/arXiv.2503.18631,"Kunyang Li, Ming Hou",CV,24/03/2025,"robust lane detection wavelet enhanced context modeling adaptive sampling lane detection be critical autonomous driving ad vanced driver assistance system ( adas ) . recent method clrnet achieve strong performance , struggle adverse con ditions such extreme weather , illumination change , occlusion , complex curve . propose wavelet enhanced feature net work ( we fpn ) to address challenge . wavelet based non local block be integrate feature pyramid to improve global context modeling , especially occlude curve lane . additionally , de sign adaptive preprocessing module to enhance lane visibility poor lighting . attention guided sampling strategy further reffnes spa tial feature , boost accuracy distant curve lane . experiment culane tusimple demonstrate approach signiffcantly outperform baseline challenge scenario , achieve good robust ness accuracy real world driving condition ."
https://doi.org/10.48550/arXiv.2503.18629,"Arne Grobrügge, Niklas Kühl, Gerhard Satzger, Philipp Spitzer",CV,24/03/2025,"towards human understandable multi dimensional concept discovery concept based explainable ai ( c xai ) aim to overcome limitation traditional saliency map convert pixel human understandable concept that be consistent entire dataset . crucial aspect c xai be completeness , which measure how well set concept explain model decision . c xai method , multi dimensional concept discovery ( mcd ) effectively improve completeness break down cnn latent space distinct interpretable concept subspace . however , explanation can be difficult human to understand , raise concern practical utility . to address , propose human understandable multi dimensional concept discovery ( hu mcd ) . hu mcd use segment anything model concept identification implement cnn specific input mask technique to reduce noise introduce traditional masking method . change to mcd , pair completeness relation , enable hu mcd to enhance concept understandability maintain explanation faithfulness . experiment , include human subject study , show hu mcd provide more precise reliable explanation exist c xai method . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18627,"Bing Cao, Baoshuo Cai, Changqing Zhang, Qinghua Hu",CV,24/03/2025,": dig diffusion information gain image fusion image fusion integrate complementary information multi source image to generate more informative result . recently , diffusion model , which demonstrate unprecedented generative potential , have be explore image fusion . however , approach typically incorporate predefined multimodal guidance diffusion , fail to capture dynamically change significance modality , lack theoretical guarantee . to address issue , reveal significant spatio temporal imbalance image denoising ; specifically , diffusion model produce dynamic information gain different image region denoising step . base observation , dig diffusion information gain ( ) theoretically derive diffusion based dynamic image fusion framework that provably reduce upper bound generalization error . accordingly , introduce diffusion information gain ( dig ) to quantify information contribution modality different denoising step , thereby provide dynamic guidance fusion process . extensive experiment multiple fusion scenario confirm method outperform exist diffusion based approach term fusion quality inference efficiency ."
https://doi.org/10.48550/arXiv.2503.18626,"Junqiao Fan, Yunjiao Zhou, Min Chang Jordan Ren, Jianfei Yang",CV,24/03/2025,"generative dataset distillation use min max diffusion model paper , address problem generative dataset distillation that utilize generative model to synthesize image . generator may produce number image preserved evaluation time . work , leverage popular diffusion model generator to compute surrogate dataset , boost min max loss to control dataset diversity representativeness training . however , diffusion model be time consuming when generate image , require iterative generation process . observe critical trade off number image sample image quality control diffusion step propose diffusion step reduction to achieve optimal performance . paper detail comprehensive method performance . model achieve $ { nd } $ place generative track { http url } { first dataset distillation challenge } , demonstrate superior performance ."
https://doi.org/10.48550/arXiv.2503.18623,"Deepayan Das, Davide Talon, Yiming Wang, Massimiliano Mancini, Elisa Ricci",CV,24/03/2025,"training free personalization retrieval reason fingerprint vision language model ( vlms ) have lead to major improvement multimodal reasoning , yet still struggle to understand user specific concept . exist personalization method address limitation heavily rely training procedure , that can be either costly unpleasant to individual user . depart exist work , first time explore training free setting context personalization . propose novel method , retrieval reason personalization ( ) , leverage internal knowledge vlms . first , leverage vlms to extract concept fingerprint , , key attribute uniquely define concept semantic class . when query arrive , most similar fingerprint be retrieve score chain of thought reasoning . to reduce risk hallucination , score be validate cross modal verification attribute level : case discrepancy score , refine concept association pairwise multimodal matching , where retrieved fingerprint image be directly compare query . validate two publicly available benchmark newly introduce dataset , personal concept visual ambiguity ( perva ) , concept identification highlight challenge visual ambiguity . consistently outperform state of the art approach various downstream task benchmark . code will be available upon acceptance ."
https://doi.org/10.48550/arXiv.2503.18589,"Guillem Capellera, Antonio Rubio, Luis Ferraz, Antonio Agudo",CV,24/03/2025,"unified uncertainty aware diffusion multi agent trajectory modeling multi agent trajectory modeling have primarily focus forecast future state , often overlook broad task trajectory completion , which be crucial real world application such correct track data . exist method also generally predict agent ' state offer state wise measure uncertainty . moreover , popular multi modal sampling method lack error probability estimate generate scene same prior observation , make difficult to rank prediction inference time . introduce , { unified } diffusion model design to handle trajectory completion provide state wise { uncertainty } estimate jointly . uncertainty estimation be achieve augment simple denoising loss negative log likelihood predicted noise propagate latent space uncertainty to real state space . additionally , incorporate rank neural network post processing to enable { error probability } estimation generated mode , demonstrate strong correlation error relative to grind truth . method outperform state of the art solution trajectory completion forecasting four challenge sport datasets ( nba , basketball u , football u , soccer u ) , highlight effectiveness uncertainty error probability estimation . video http url"
https://doi.org/10.48550/arXiv.2503.18583,"Alexander Holmberg, Nils Mechtel, Wei Ouyang",CV,24/03/2025,"adapt video diffusion model time lapse microscopy present domain adaptation video diffusion model to generate highly realistic time lapse microscopy video cell division hela cell . state of the art generative video model have advance significantly natural video , remain underexplored microscopy domain . to address gap , fine tune pretrained video diffusion model microscopy specific sequence , explore three condition strategy : ( ) text prompt derive numeric phenotypic measurement ( , proliferation rate , migration speed , cell death frequency ) , ( ) direct numeric embeddings phenotype score , ( ) image conditioned generation , where initial microscopy frame be extend complete video sequence . evaluation use biologically meaningful morphological , proliferation , migration metric demonstrate fine tuning substantially improve realism accurately capture critical cellular behavior such mitosis migration . notably , fine tuned model also generalize training horizon , generate coherent cell dynamic even extended sequence . however , precisely control specific phenotypic characteristic remain challenging , highlight opportunity future work to enhance condition method . result demonstrate potential domain specific fine tuning generative video model to produce biologically plausible synthetic microscopy data , support application such in silico hypothesis testing data augmentation ."
https://doi.org/10.48550/arXiv.2503.18567,"Biwen Meng, Xi Long, Wanrong Yang, Ruochen Liu, Yi Tian, Yalin Zheng, Jingxin Liu",CV,24/03/2025,"advance cross organ domain generalization test time style transfer diversity enhancement deep learning have make significant progress address challenge various field include computational pathology ( cpath ) . however , due to complexity domain shift problem , performance exist model will degrade , especially when come to multi domain cross domain task . paper , propose test time style transfer ( ) that use bidirectional mapping mechanism to project feature source target domain unified feature space , enhance generalization ability model . to further increase style expression space , introduce cross domain style diversification module ( csdm ) to ensure orthogonality style base . addition , data augmentation low rank adaptation technique be use to improve feature alignment sensitivity , enable model to adapt to multi domain input effectively . method have demonstrate effectiveness three unseen datasets ."
https://doi.org/10.48550/arXiv.2503.18559,"Takashi Isobe, He Cui, Dong Zhou, Mengmeng Ge, Dong Li, Emad Barsoum",CV,24/03/2025,"amd hummingbird : towards efficient text to video model text to video ( ) generation have attract significant attention ability to synthesize realistic video textual description . however , exist model struggle to balance computational efficiency high visual quality , particularly resource limited device , , igpus mobile phone . most prior work prioritizes visual fidelity overlook need small , more efficient model suitable real world deployment . to address challenge , propose lightweight framework , term hummingbird , which prune exist model enhances visual quality visual feedback learning . approach reduce size u net billion to billion parameter , significantly improve efficiency preserve high quality video generation . additionally , introduce novel data processing pipeline leverage large language model ( llm ) video quality assessment ( vqa ) model to enhance quality text prompt video data . to support user driven training style customization , publicly release full training code , include data processing model training . extensive experiment show method achieve speedup compare to state of the art model such , also attain high overall score vbench . moreover , method support generation video to frame , address limitation exist u net based method long video generation . notably , entire training process require only four gpus , delivers performance competitive exist lead method . hummingbird present practical efficient solution generation , combine high performance , scalability , flexibility real world application ."
https://doi.org/10.48550/arXiv.2503.18557,"Rafia Rahim, Samuel Woerz, Andreas Zell",CV,24/03/2025,"leanstereo : leaner backbone base stereo network recently , end to end deep network base stereo match method , mainly performance , have gain popularity . however , improvement performance come cost increased computational memory bandwidth requirement , thus necessitate specialize hardware ( gpus ) ; even then , method have large inference time compare to classical method . limit applicability real world application . desire high accuracy stereo method reasonable inference time . to end , propose fast end to end stereo match method . majority speedup come integrate leaner backbone . to recover performance lose leaner backbone , propose to use learned attention weight base cost volume combine loss stereo matching . use loss not only improve overall performance propose network also lead to faster convergence . do detailed empirical evaluation different design choice show method require less operation be also about to faster compare to state art method acvnet [ ] , leastereo [ ] cfnet [ ] give comparable performance ."
https://doi.org/10.48550/arXiv.2503.18556,"Bin Li, Dehong Gao, Yeyuan Wang, Linbo Jin, Shanqing Yu, Xiaoyan Cai, Libin Yang",CV,24/03/2025,"instruction aligned visual attention mitigate hallucination large vision language model significant success large vision language model ( lvlms ) , model still suffer hallucination when describe image , generate answer that include non existent object . be report model tend to over focus certain irrelevant image token that do not contain critical information answer question distort output . to address , propose instruction aligned visual attention ( iava ) approach , which identify irrelevant token compare change attention weight two different instruction . apply contrastive decoding , dynamically adjust logits generate original image token irrelevant image token , reduce model over attention to irrelevant information . experimental result demonstrate iava consistently outperform exist decode technique benchmark such mme , pope , textvqa mitigate object hallucination . iava approach be available online http url ."
https://doi.org/10.48550/arXiv.2503.18553,"Zihao Chen, Hsuanyu Wu, Chi-Hsi Kung, Yi-Ting Chen, Yan-Tsung Peng",CV,24/03/2025,"atar : aerial traffic atomic activity recognition temporal segmentation dataset traffic atomic activity which describe traffic pattern topological intersection dynamic be crucial topic advancement intelligent drive system . however , exist atomic activity datasets be collect egocentric view , which can not support scenario where traffic activity entire intersection be require . moreover , exist datasets only provide video level atomic activity annotation , which require exhaust effort to manually trim video recognition limit application to untrimmed video . to bridge gap , introduce aerial traffic atomic activity recognition segmentation ( atar ) dataset , first aerial dataset design multi label atomic activity analysis . offer atomic activity label frame , which accurately record interval traffic activity . moreover , propose novel task , multi label temporal atomic activity recognition , enable study accurate temporal localization atomic activity ease burden manual video trim recognition . conduct extensive experiment to evaluate exist state of the art model atomic activity recognition temporal atomic activity segmentation . result highlight unique challenge atar dataset , such recognize extremely small object ' activity . further provide comprehensive discussion analyze challenge offer valuable insight future direction to improve recognize atomic activity aerial view . source code dataset be available http url"
https://doi.org/10.48550/arXiv.2503.18552,"Qiang Qu, Ming Li, Xiaoming Chen, Tongliang Liu",CV,24/03/2025,"evanimate : event conditioned image to video generation human animation conditional human animation transform static reference image dynamic sequence apply motion cue such pose . motion cue be typically derive video data be susceptible to limitation include low temporal resolution , motion blur , overexposure , inaccuracy low light condition . contrast , event camera provide data stream exceptionally high temporal resolution , wide dynamic range , inherent resistance to motion blur exposure issue . work , propose evanimate , framework that leverage event stream motion cue to animate static human image . approach employ specialized event representation transform asynchronous event stream slice controllable slice rate appropriate slice density , ensure compatibility diffusion model . subsequently , dual branch architecture generate high quality video harness inherent motion dynamic event stream , thereby enhance video quality temporal consistency . specialize data augmentation strategy far enhance cross person generalization . finally , establish new benchmarking , include simulated event data training validation , real world event dataset capture human action normal extreme scenario . experiment result demonstrate evanimate achieves high temporal fidelity robust performance scenario where traditional video derived cue fall short ."
https://doi.org/10.48550/arXiv.2503.18548,"Lubnaa Abdur Rahman, Ioannis Papathanail, Lorenzo Brigato, Stavroula Mougiakakou",CV,24/03/2025,"benchmarking post hoc unknown category detection food recognition food recognition model often struggle to distinguish see unseen sample , frequently misclassifying sample unseen category assign in distribution ( id ) label . misclassification present significant challenge when deploy model real world application , particularly automatic dietary assessment system , where incorrect label can lead to cascade error system . ideally , such model should prompt user when unknown sample be encounter , allow corrective action . give prior research explore food recognition real world setting , work conduct empirical analysis various post hoc out of distribution ( ood ) detection method fine grained food recognition . finding indicate virtual logit matching ( vim ) perform best overall , likely due to combination logits feature space representation . additionally , work reinforces prior notion ood domain , note model high id accuracy perform good evaluated ood detection method . furthermore , transformer based architecture consistently outperform convolution based model detect ood sample various method ."
https://doi.org/10.48550/arXiv.2503.18544,"Rafia Rahim, Samuel Woerz, Andreas Zell",CV,24/03/2025,"distil stereo network performant efficient leaner network knowledge distillation have be quite popular vision task classification segmentation however not much work have be do distil state of the art stereo match method range application . one reason lack use stereo matching network be due to inherent complexity network , where typical network be compose multiple two  three dimensional module . work , systematically combine insight state of the art stereo method general knowledge distillation technique to develop joint framework stereo network distillation competitive result fast inference . moreover , show , detailed empirical analysis , distil knowledge stereo network require careful design complete distillation pipeline start backbone to right selection distillation point corresponding loss function . result student network that be not only leaner faster give excellent performance . instance , student network perform good performance orient method psmnet [ ] , cfnet [ ] , leastereo [ ] ) benchmark sceneflow dataset , be , , faster respectively . furthermore , compare to speed orient method have inference time less , student network perform good all test method . addition , student network also show good generalization capability when test unseen datasets middlebury ."
https://doi.org/10.48550/arXiv.2503.18541,"Kangli Wang, Wei Gao",CV,24/03/2025,"unipcgc : towards practical point cloud geometry compression efficient unified approach learning based point cloud compression method have make significant progress term performance . however , method still encounter challenge include high complexity , limited compression mode , lack support variable rate , which restrict practical application method . order to promote development practical point cloud compression , propose efficient unified point cloud geometry compression framework , dub unipcgc . be lightweight framework that support lossy compression , lossless compression , variable rate variable complexity . first , introduce uneven lossless coder ( uelc ) lossless mode , which allocate more computational complexity to group high coding difficulty , merges group low coding difficulty . second , variable rate complexity module ( vrcm ) be achieve lossy mode joint adoption rate modulation module dynamic sparse convolution . finally , dynamic combination uelc vrcm , achieve lossy compression , lossless compression , variable rate complexity unified framework . compare to previous state of the art method , method achieve compression ratio ( cr ) gain % lossless compression , bjontegaard delta rate ( bd rate ) gain % lossy compression , also support variable rate variable complexity ."
https://doi.org/10.48550/arXiv.2503.18540,"Guneet Mutreja, Philipp Schuegraf, Ksenia Bittner",CV,24/03/2025,"hire fusedmim : high resolution rgb dsm pre trained model building level remote sensing application recent advance self supervised learning have lead to development foundation model that have significantly advance performance various computer vision task . however , potential , model often overlook crucial role high resolution digital surface model ( dsms ) understand urban environment , particularly building level analysis , which be essential application digital twin . to address gap , introduce hires fusedmim , novel pre trained model specifically design to leverage rich information contain high resolution rgb dsm data . hire fusedmim utilize dual encoder simple mask image modeling ( simmim ) architecture multi objective loss function combine reconstruction contrastive objective , enable to learn powerful , joint representation modality . conduct comprehensive evaluation hire fusedmim diverse set downstream task , include classification , semantic segmentation , instance segmentation . result demonstrate : ) hire fusedmim outperforms previous state of the art geospatial method several building related datasets , include whu aerial loveda , demonstrate effectiveness capture leverage fine grained building information ; ) incorporate dsms pre training consistently improve performance compare to use rgb data alone , highlight value elevation information building level analysis ; ) dual encoder architecture hire fusedmim , separate encoders rgb dsm data , significantly outperform single encoder model vaihingen segmentation task , indicate benefit learn specialized representation modality . to facilitate further research application direction , will publicly release trained model weight ."
https://doi.org/10.48550/arXiv.2503.18536,"Erjian Guo, Zhen Zhao, Zicheng Wang, Tong Chen, Yunyi Liu, Luping Zhou",CV,24/03/2025,"din : diffusion model robust medical vqa semantic noisy label medical visual question answer ( med vqa ) system benefit interpretation medical image contain critical clinical information . however , challenge noisy label limited high quality datasets remain underexplored . to address , establish first benchmark noisy label med vqa simulate human mislabeling semantically design noise type . more importantly , introduce din framework , which leverage diffusion model to handle noisy label med vqa . dominant classification based vqa approach that directly predict answer , answer diffuser ( ad ) module employ coarse to fine process , refine answer candidate diffusion model improved accuracy . answer condition generator ( acg ) far enhance process generate task specific conditional information integrate answer embeddings fused image question feature . to address label noise , noisy label refinement ( nlr ) module introduce robust loss function dynamic answer adjustment to far boost performance ad module ."
https://doi.org/10.48550/arXiv.2503.18527,"Soulaimene Turki, Daniel Panangian, Houda Chaabouni-Chouayakh, Ksenia Bittner",CV,24/03/2025,": aerial image to building point cloud reconstruction three dimensional urban reconstruction building single view image have attract significant attention past two decade . however , recent method primarily focus rooftop aerial image , often overlook essential geometrical detail . additionally , there be notable lack datasets contain complete point cloud entire building , challenge obtain reliable camera pose information aerial image . paper address challenge present novel methodology , , which utilize generated dataset that include complete point cloud determine camera pose . approach take feature single aerial image input concatenate essential additional condition , such binary mask sobel edge map , to enable more edge aware reconstruction . incorporate point cloud diffusion model base centered denoising diffusion probabilistic model ( cdpm ) , project concatenate feature partially denoised point cloud use camera pose diffusion step . propose method be able to reconstruct complete building point cloud , include wall information demonstrate superior performance compare to exist baseline technique . to allow further comparison methodology dataset have be make available http url"
https://doi.org/10.48550/arXiv.2503.18513,"Xiaoyu Zhang, Weihong Pan, Chong Bao, Xiyu Zhang, Xiaojun Xiang, Hanqing Jiang, Hujun Bao",CV,24/03/2025,"lookcloser : frequency aware radiance field tiny detail scene human perceive comprehend surroundings information span multiple frequency . immersive scene , people naturally scan environment to grasp overall structure examine fine detail object that capture attention . however , current nerf framework primarily focus model high frequency local view broad structure scene low frequency information , which be limit to balance . introduce fa nerf , novel frequency aware framework view synthesis that simultaneously capture overall scene structure high definition detail single nerf model . to achieve , propose frequency quantification method that analyze scene frequency distribution , enable frequency aware rendering . framework incorporate frequency grid fast convergence querying , frequency aware feature re weighting strategy to balance feature different frequency content . extensive experiment show method significantly outperform exist approach model entire scene preserve fine detail ."
https://doi.org/10.48550/arXiv.2503.18512,"Leheng Zhang, Weiyi You, Kexuan Shi, Shuhang Gu",CV,24/03/2025,"uncertainty guided perturbation image super resolution diffusion model diffusion based image super resolution method have demonstrate significant advantage gan based approach , particularly term perceptual quality . building lengthy markov chain , diffusion based method possess remarkable modeling capacity , enable to achieve outstanding performance real world scenario . previous method that focus modify noise schedule sample process to enhance performance , approach emphasize improved utilization lr information . find different region lr image can be view correspond to different timesteps diffusion process , where flat area be close to target hr distribution edge texture region be far away . flat area , apply slight noise be more advantageous reconstruction . associate characteristic uncertainty propose to apply uncertainty estimate to guide region specific noise level control , technique refer to uncertainty guided noise weighting . pixel low uncertainty ( , flat region ) receive reduce noise to preserve more lr information , therefore improve performance . furthermore , modify network architecture previous method to develop uncertainty guided perturbation super resolution ( upsr ) model . extensive experimental result demonstrate , reduce model size training overhead , propose uwsr method outperform current state of the art method various datasets , quantitatively qualitatively ."
https://doi.org/10.48550/arXiv.2503.18507,"Luca Zanella, Massimiliano Mancini, Willi Menapace, Sergey Tulyakov, Yiming Wang, Elisa Ricci",CV,24/03/2025,"can text to video generation help video language alignment ? recent video language alignment model be train set video , associate positive caption negative caption generate large language model . problem procedure be negative caption may introduce linguistic bias , , concept be see only negative never associate video . solution would be to collect video negative caption , exist database lack fine grained variation need to cover possible negative . work , study synthetic video can help to overcome issue . preliminary analysis multiple generator show , promise task , synthetic video harm performance model others . hypothesize issue be link to noise ( semantic visual ) generated video develop method , synvita , that account . synvita dynamically weight contribution synthetic video base how similar target caption be . real counterpart . moreover , semantic consistency loss make model focus fine grained difference caption , rather difference video appearance . experiment show , average , synvita improve over exist method videocon test set , , atp hard benchmark , be first promising step use synthetic video when learn video language model ."
https://doi.org/10.48550/arXiv.2503.18484,"Junyuan Gao, Jiahe Song, Jiang Wu, Runchuan Zhu, Guanlin Shen, Shasha Wang, Xingjian Wei, Haote Yang, Songyang Zhang, Weijia Li, Bin Wang, Dahua Lin, Lijun Wu, Conghui He",CV,24/03/2025,": parallel multilingual multi modal multi task benchmark large vision language model exist multilingual benchmark large vision language model ( lvlms ) suffer limitation include language specific content bias , disjoint multimodal input format , lack safety evaluation . to address gap , propose , first parallel multilingual multi modal multi task benchmark lvlms . feature parallel corpus design language , enable fair accurate cross lingual comparison . include vision set where text query be embed image , require lvlms to simultaneously see , read , think , align real world application . additionally , { } bench incorporates safety evaluation , address critical oversight exist multilingual benchmark . use , evaluate mainstream lvlms , reveal significant cross linguistic performance disparity , particularly vision setting , identify ocr capability key determinant imbalance . will release http url ."
https://doi.org/10.48550/arXiv.2503.18483,"Zequn Zeng, Yudi Su, Jianqiao Sun, Tiansheng Wen, Hao Zhang, Zhengjue Wang, Bo Chen, Hongwei Liu, Jiawei Ma",CV,24/03/2025,"explain domain shift language : concept erase interpretable image classification concept based model can map black box representation to human understandable concept , which make decision making process more transparent then allow user to understand reason prediction . however , domain specific concept often impact final prediction , which subsequently undermine model generalization capability , prevent model be use high stake application . paper , propose novel language guided concept erasing ( lance ) framework . particular , empirically demonstrate pre trained vision language model ( vlms ) can approximate distinct visual domain shift domain descriptor prompt large language model ( llm ) can easily simulate wide range descriptor unseen visual domain . then , introduce novel plug in domain descriptor orthogonality ( ddo ) regularizer to mitigate impact domain specific concept final prediction . notably , ddo regularizer be agnostic to design concept based model integrate several prevailing model . evaluation domain generalization four standard benchmark three newly introduce benchmark , demonstrate ddo can significantly improve out of distribution ( ood ) generalization previous state of the art concept based http url code be available http url ."
https://doi.org/10.48550/arXiv.2503.18478,"Xiangrui Liu, Yan Shu, Zheng Liu, Ao Li, Yang Tian, Bo Zhao",CV,24/03/2025,"video xl pro : reconstructive token compression extremely long video understanding advanced token compression technique , exist multimodal large language model ( mllms ) still struggle hour long video understanding . work , propose video xl pro , efficient method extremely long video understanding , build reconstructive compression token ( recot ) , learnable module leverage self supervised learning to generate comprehensive compact video token . recot introduces two key component : ( i ) dynamic token synthesizer ( dts ) : dts generate pseudo video token static image token learn intra token relationship , which be then use masked video modeling . ( ii ) semantic guided masking ( sgm ) : sgm adaptively masks redundant visual token to facilitate more effective reconstructive learning . to improve training efficiency mllms fine tuning , introduce video specific dataset pruning strategy design simple yet query aware selector that enable model to precisely locate query relevant video token . only parameter , video xl pro outperforms most model train large datasets multiple long video understanding benchmark . moreover , can process frame single gpu maintain high quality performance ."
https://doi.org/10.48550/arXiv.2503.18476,"Wei Deng, Mengshi Qi, Huadong Ma",CV,24/03/2025,"global local tree search language guide scene generation large vision language model ( vlms ) , such , have achieve remarkable success various field . however , there be few study indoor scene generation vlms . paper consider task planning problem subject to spatial layout common sense constraint . to solve problem vlm , propose new global local tree search algorithm . globally , method place object sequentially explore multiple placement placement process , where problem space be represent tree . to reduce depth tree , decompose scene structure hierarchically , . room level , region level , floor object level , support object level . algorithm independently generate floor object different region support object place different floor object . locally , also decompose sub task , placement object , multiple step . algorithm search tree problem space . to leverage vlm model to produce position object , discretize top down view space dense grid fill cell diverse emojis to make to cell distinct . prompt vlm emoji grid vlm produce reasonable location object describe position name emojis . quantitative qualitative experimental result illustrate approach generate more plausible scene state of the art approach . source code be available http url ."
https://doi.org/10.48550/arXiv.2503.18470,"Zhenyu Pan, Han Liu",CV,24/03/2025,"metaspatial : reinforce spatial reasoning vlms metaverse present metaspatial , first reinforcement learning ( rl )  base framework design to enhance spatial reason vision language model ( vlms ) , enable real time scene generation need hard coded optimization . metaspatial address two core challenge : ( i ) lack internalized spatial reasoning vlms , which limit ability to generate realistic layout , ( ii ) inefficiency traditional supervise fine tuning ( sft ) layout generation task , perfect ground truth annotation be unavailable . key innovation be multi turn rl based optimization mechanism that integrate physics aware constraint render image evaluation , ensure generate layout be coherent , physically plausible , aesthetically consistent . methodologically , metaspatial introduces adaptive , iterative reasoning process , where vlm refine spatial arrangement multiple turn analyze render output , improve scene coherence progressively . empirical evaluation demonstrate metaspatial significantly enhance spatial consistency format stability various scale model . post training , object placement be more realistic , align , functionally coherent , validate effectiveness rl spatial reasoning metaverse , , digital twin , game development application . code , data , training pipeline be publicly available http url ."
https://doi.org/10.48550/arXiv.2503.18469,"Hao Ni, Lianli Gao, Pengpeng Zeng, Heng Tao Shen, Jingkuan Song",CV,24/03/2025,"cfreid : continual few shot person re identification real world surveillance system be dynamically evolve , require person re identification model to continuously handle newly incoming data various domain . to cope dynamic , lifelong reid ( lreid ) have be propose to learn accumulate knowledge multiple domain incrementally . however , lreid model need to be train large scale label data unseen domain , which be typically inaccessible due to privacy cost concern . paper , propose new paradigm call continual few shot reid ( cfreid ) , which require model to be incrementally trained use few shot data test see domain . few shot condition , cfreid face two core challenge : ) learn knowledge few shot data unseen domain , ) avoid catastrophic forgetting see domain . to tackle two challenge , propose stable distribution alignment ( sda ) framework feature distribution perspective . specifically , sda be compose two module , , meta distribution alignment ( mda ) prototype based few shot adaptation ( pfa ) . to support study cfreid , establish evaluation benchmark cfreid five publicly available reid datasets . extensive experiment demonstrate sda can enhance few shot learning anti forgetting capability few shot condition . notably , approach , use only % data , , id , significantly outperform lreid state of the art performance , which require to id ."
https://doi.org/10.48550/arXiv.2503.18463,"Sixian Ding, Xu Jiang, Zhongjing Du, Jiaqi Cui, Xinyi Zeng, Yan Wang",CV,24/03/2025,"sit fer : integration semantic  , instance  , text level information semi supervised facial expression recognition semi supervised deep facial expression recognition ( s dfer ) have gain increasingly research interest due to difficulty access sufficient label data practical setting . however , exist s dfer method mainly utilize generated semantic level pseudo label supervised learning , unreliability which compromise performance undermine practical utility . paper , propose novel s dfer framework that simultaneously incorporate semantic , instance , text level information to generate high quality pseudo label . specifically , unlabeled data , consider comprehensive knowledge textual description instance representation , respectively calculate similarity facial vision feature corresponding textual instance feature to obtain probability text  instance level . combine semantic level probability , three level probability be elaborately aggregate to gain final pseudo label . furthermore , to enhance utilization one hot label label data , also incorporate text embeddings excavate textual description to co supervise model training , enable facial visual feature to exhibit semantic correlation text space . experiment three datasets demonstrate method significantly outperform current state of the art s dfer method even exceeds fully supervise baseline . code will be available http url ."
https://doi.org/10.48550/arXiv.2503.18461,"Lingting Zhu, Jingrui Ye, Runze Zhang, Zeyu Hu, Yingda Yin, Lanjiong Li, Jinnan Chen, Shengju Qian, Xin Wang, Qingmin Liao, Lequan Yu",CV,24/03/2025,"muma : pbr texturing multi channel multi view generation agentic post processing current method generation still fall short physically base rendering ( pbr ) texturing , primarily due to limited data challenge model multi channel material . work , propose muma , method pbr texturing multi channel multi view generation agentic post processing . approach feature two key innovation : ) opt to model shaded albedo appearance channel , where shaded channel enable integration intrinsic decomposition module material property . ) leverage multimodal large language model , emulate artist ' technique material assessment selection . experiment demonstrate muma achieves superior result visual quality material fidelity compare to exist method ."
https://doi.org/10.48550/arXiv.2503.18459,"Haoyu Chen, Yunqiao Yang, Nan Zhong, Kede Ma",CV,24/03/2025,"hide image diffusion model edit learn score function hide data use neural network ( , neural steganography ) have achieve remarkable success discriminative classifier generative adversarial network . however , potential data hide diffusion model remain relatively unexplored . current method exhibit limitation achieve high extraction accuracy , model fidelity , hide efficiency due primarily to entanglement hiding extraction process multiple denoising diffusion step . to address , describe simple yet effective approach that embed image specific timesteps reverse diffusion process edit learn score function . additionally , introduce parameter efficient fine tuning method combine gradient based parameter selection low rank adaptation to enhance model fidelity hiding efficiency . comprehensive experiment demonstrate method extract high quality image human indistinguishable level , replicate original model behavior sample population level , embeds image order magnitude faster prior method . besides , method naturally support multi recipient scenario independent extraction channel ."
https://doi.org/10.48550/arXiv.2503.18458,"Luchao Wang, Qian Ren, Kaiming He, Hua Wang, Zhi Chen, Yaohua Tang",CV,24/03/2025,"stablegs : floater free framework gaussian splatting recent year have witness remarkable success gaussian splatting ( ) novel view synthesis , surpass prior differentiable render method quality efficiency . however , training process suffers couple opacity color optimization that frequently converge to local minimum , produce floater artifact that degrade visual fidelity . present stablegs , framework that eliminate floater cross view depth consistency constraint introduce dual opacity g model to decouple geometry material property translucent object . to further enhance reconstruction quality weakly textured region , integrate depth estimation , significantly improve geometric stability . method fundamentally address training instability , outperform exist state of the art method open source datasets ."
https://doi.org/10.48550/arXiv.2503.18454,"Yunhong Lu, Qichao Wang, Hengyuan Cao, Xierui Wang, Xiaoyin Xu, Min Zhang",CV,24/03/2025,"inpo : inversion preference optimization reparametrized ddim efficient diffusion model alignment use explicit reward , direct preference optimization ( dpo ) employ paired human preference data to fine tune generative model , method that have garner considerable attention large language model ( llm ) . however , exploration align text to image ( ) diffusion model human preference remain limited . comparison to supervise fine tuning , exist method that align diffusion model suffer low training efficiency subpar generation quality due to long markov chain process intractability reverse process . to address limitation , introduce ddim inpo , efficient method direct preference alignment diffusion model . approach conceptualize diffusion model single step generative model , allow to fine tune output specific latent variable selectively . order to accomplish objective , first assign implicit reward to latent variable directly reparameterization technique . then construct inversion technique to estimate appropriate latent variable preference optimization . modification process enable diffusion model to only fine tune output latent variable that have strong correlation preference dataset . experimental result indicate ddim inpo achieves state of the art performance just step fine tuning , surpass preference align baseline diffusion model human preference evaluation task ."
https://doi.org/10.48550/arXiv.2503.18446,"Jinho Jeong, Sangmin Han, Jinwoo Kim, Seon Joo Kim",CV,24/03/2025,"latent space super resolution higher resolution image generation diffusion model paper , propose lsrna , novel framework higher resolution ( exceed ) image generation use diffusion model leverage super resolution directly latent space . exist diffusion model struggle scale training resolution , often lead to structural distortion content repetition . reference based method issue upsampling low resolution reference to guide higher resolution generation . however , face significant challenge : upsampling latent space often cause manifold deviation , which degrade output quality . other hand , upsampling rgb space tends to produce overly smooth output . to overcome limitation , lsrna combine latent space super resolution ( lsr ) manifold alignment region wise noise addition ( rna ) to enhance high frequency detail . extensive experiment demonstrate integrate lsrna outperforms state of the art reference based method various resolution metric , show critical role latent space upsampling preserve detail sharpness . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18445,"Chenfei Liao, Kaiyu Lei, Xu Zheng, Junha Moon, Zhixiong Wang, Yixuan Wang, Danda Pani Paudel, Luc Van Gool, Xuming Hu",CV,24/03/2025,"benchmarking multi modal semantic segmentation sensor failure : missing noisy modality robustness multi modal semantic segmentation ( mmss ) address limitation single modality data integrate complementary information modality . notable progress , significant gap persist research real world deployment due to variability uncertainty multi modal data quality . robustness have thus become essential practical mmss application . however , absence standardized benchmark evaluate robustness hinders far advancement . to address , first survey exist mmss literature categorize representative method to provide structured overview . then introduce robustness benchmark that evaluate mmss model three scenario : entire missing modality ( emm ) , random missing modality ( rmm ) , noisy modality ( nm ) . probabilistic standpoint , model modality failure two condition : ( ) damage combination be equally probable ; ( ) modality fail independently follow bernoulli distribution . base , propose four metrics  $ { avg } _ { emm } $ , $ { e } _ { emm } $ , $ { avg } _ { rmm } $ , $ { e } _ { rmm } $  to assess model robustness emm rmm . work provide first dedicate benchmark mmss robustness , offer new insight tool to advance field . source code be available http url ."
https://doi.org/10.48550/arXiv.2503.18438,"Guosheng Zhao, Xiaofeng Wang, Chaojun Ni, Zheng Zhu, Wenkang Qin, Guan Huang, Xingang Wang",CV,24/03/2025,": harmonizing generative reconstructive model drive scene representation combine reconstruction model generative model have emerge promising paradigm closed loop simulation autonomous driving . example , recondreamer have demonstrate remarkable success render large scale maneuver . however , significant gap remain generate data real world sensor observation , particularly term fidelity structured element , such ground surface . to address challenge , propose , enhanced framework that significantly improve overall rendering quality mitigate domain gap refine representation ground surface . specifically , introduces novel trajectory deformable network ( ntdnet ) , which leverage learnable spatial deformation mechanism to bridge domain gap synthesize novel view original sensor observation . moreover , structured element such ground surface , preserve geometric prior knowledge gaussians , optimization process focus refine appearance attribute preserve underlie geometric structure . experimental evaluation conduct multiple datasets ( waymo , nuscenes , pandaset , euvs ) confirm superior performance . specifically , waymo , achieves performance comparable to street gaussians original trajectory significantly outperform recondreamer novel trajectory . particular , achieve substantial improvement , include % increase nta iou , . % improvement fid , remarkable % gain ground surface metric ntl iou , highlight effectiveness accurately reconstruct structure element such road surface ."
https://doi.org/10.48550/arXiv.2503.18435,"Junteng Liu, Weihao Zeng, Xiwen Zhang, Yijun Wang, Zifei Shan, Junxian He",CV,24/03/2025,"perception bottleneck vlms chart understanding chart understand require model to effectively analyze reason numerical data , textual element , complex visual component . observation reveal perception capability exist large vision language model ( lvlms ) constitute critical bottleneck process . study , delve perception bottleneck decompose two component : vision encoder bottleneck , where visual representation may fail to encapsulate correct information , extraction bottleneck , where language model struggle to extract necessary information provide visual representation . comprehensive experiment , find ( ) information embed visual representation be substantially rich what be typically capture linear extractor , such widely use retrieval accuracy metric ; ( ) instruction tune effectively enhance extraction capability lvlms , vision encoder remain critical bottleneck , demand focused attention improvement . therefore , further enhance visual encoder to mitigate vision encoder bottleneck contrastive learning framework . empirical result demonstrate approach significantly mitigate perception bottleneck improve ability lvlms to comprehend chart . code be publicly available http url ."
https://doi.org/10.48550/arXiv.2503.18434,"Zhaoqing Zhu, Chuwei Luo, Zirui Shao, Feiyu Gao, Hangdi Xing, Qi Zheng, Ji Zhang",CV,24/03/2025,"simple yet effective layout token large language model document understanding recent method that integrate spatial layout text document understanding large language model ( llm ) have show promising result . commonly use method be to represent layout information text token interleave text content input to llm . however , such method still demonstrate limitation , require additional position id token that be use to represent layout information . due to constraint max position id , assign to layout information reduces available text content , reduce capacity model to learn text training , also introduce large number potentially untrained position id long context inference , which can hinder performance document understanding task . to address issue , propose laytokenllm , simple yet effective method document understanding . laytokenllm represent layout information single token text segment use specialized positional encode scheme . share position id text layout token , eliminate need additional position id . design maintain model capacity to learn text mitigate long context issue inference . furthermore , novel pre training objective call next interleaved text layout token prediction ( ntlp ) be devise to enhance cross modality learn text layout token . extensive experiment show laytokenllm outperforms exist layout integrated llm mllms similar scale multi page document understand task , as well most single page task ."
https://doi.org/10.48550/arXiv.2503.18430,"Zhichao Sun, Huazhang Hu, Yidong Ma, Gang Liu, Nemo Chen, Xu Tang, Yongchao Xu",CV,24/03/2025,"cq dino : mitigating gradient dilution category query vast vocabulary object detection exponential growth data , traditional object detection method be increasingly struggle to handle vast vocabulary object detection task effectively . analyze two key limitation classification based detector : positive gradient dilution , where rare positive category receive insufficient learning signal , hard negative gradient dilution , where discriminative gradient be overwhelm numerous easy negative . to address challenge , propose cq dino , category query based object detection framework that reformulate classification contrastive task object query learnable category query . method introduces image guided query selection , which reduce negative space adaptively retrieve top k relevant category image cross attention , thereby rebalancing gradient distribution facilitate implicit hard example mining . furthermore , cq dino flexibly integrate explicit hierarchical category relationship structured datasets ( , ) learn implicit category correlation self attention generic datasets ( , coco ) . experiment demonstrate cq dino achieves superior performance challenge benchmark ( surpass previous method % ap ) maintain competitiveness coco . work provide scalable solution real world detection system require wide category coverage . dataset code will be publicly http url ."
https://doi.org/10.48550/arXiv.2503.18429,"Dingcheng Zhen, Shunshun Yin, Shiyang Qin, Hou Yi, Ziwei Zhang, Siyuan Liu, Gan Qi, Ming Tao",CV,24/03/2025,"teller : real time stream audio driven portrait animation autoregressive motion generation work , introduce first autoregressive framework real time , audio driven portrait animation , , talk head . challenge lengthy animation time , critical challenge realistic talk head generation lie preserve natural movement diverse body part . to end , propose teller , first stream audio driven protrait animation framework autoregressive motion generation . specifically , teller first decompose facial body detail animation two component : facial motion latent generation ( fmlg ) base autoregressive transfromer , movement authenticity refinement use efficient temporal module ( etm ) , fmlg employ residual vq model to map facial motion latent implicit keypoint based model discrete motion token , which be then temporally slice audio embeddings . enable ar tranformer to learn real time , stream based mapping audio to motion . furthermore , teller incorporate etm to capture fine motion detail . module ensure physical consistency body part accessory , such neck muscle earring , improve realism movement . teller be design to be efficient , surpass inference speed diffusion based model ( hallo teller one second video generation ) , achieve real time streaming performance to fps . extensive experiment demonstrate method outperform recent audio driven portrait animation model , especially small movement , validate human evaluation significant margin quality realism ."
https://doi.org/10.48550/arXiv.2503.18422,"Handong Li, Yiyuan Zhang, Longteng Guo, Xiangyu Yue, Jing Liu",CV,24/03/2025,"break encoder barrier seamless video language understanding most video large language model ( video llm ) adopt encoder decoder framework , where vision encoder extract frame wise feature processing language model . however , approach incur high computational cost , introduces resolution bias , struggle to capture fine grained multimodal interaction . to overcome limitation , propose elva , encoder free video llm that directly model nuanced video language interaction rely vision encoder . employ token merge to construct bottom up hierarchical representation incorporate video guidance supervisor direct spatiotemporal representation learning . additionally , hybrid resolution mechanism strategically integrate high  low resolution frame input to achieve optimal balance performance efficiency . only publicly available video text pair , elva achieves performance par encoder based video llm reduce flop to % inference latency % , offer scalable efficient solution real time video understanding ."
https://doi.org/10.48550/arXiv.2503.18421,"Qiang Hu, Zihan Zheng, Houqiang Zhong, Sihua Fu, Li Song, XiaoyunZhang, Guangtao Zhai, Yanfeng Wang",CV,24/03/2025,": rate aware gaussian compression efficient streamable free viewpoint video gaussian splatting ( ) have substantial potential enable photorealistic free viewpoint video ( fvv ) experience . however , vast number gaussians associate attribute pose significant challenge storage transmission . exist method typically handle dynamic representation compression separately , neglect motion information rate distortion ( rd ) trade off training , lead to performance degradation increase model redundancy . to address gap , propose , novel rate aware gaussian compression framework that significantly reduce storage size maintain superior rd performance fvv . specifically , introduces motion aware dynamic gaussian representation that utilize compact motion grid combine sparse compensate gaussians to exploit inter frame similarity . representation effectively handle large motion , preserve quality reduce temporal redundancy . furthermore , present end to end compression scheme that employ differentiable quantization tiny implicit entropy model to compress motion grid compensated gaussians efficiently . entire framework be jointly optimize use rate distortion trade off . extensive experiment demonstrate support variable bitrates consistently outperform exist method rd performance multiple datasets ."
https://doi.org/10.48550/arXiv.2503.18420,"Dian Zheng, Cheng Zhang, Xiao-Ming Wu, Cao Li, Chengfei Lv, Jian-Fang Hu, Wei-Shi Zheng",CV,24/03/2025,"panorama generation nfov image do right generate panorama narrow field view ( nfov ) image be promising computer vision task virtual reality ( vr ) application . exist method mostly generated panorama inceptionnet clip base metric , which tend to perceive image quality be { not suitable evaluate distortion } . work , first propose distortion specific clip , name distort clip to accurately evaluate panorama distortion discover { visual cheating } phenomenon previous work ( , tend to improve visual result sacrifice distortion accuracy ) . phenomenon arise prior method employ single network to learn distinct panorama distortion content completion once , which lead model to prioritize optimize latter . to address phenomenon , propose { panodecouple } , decoupled diffusion model framework , which decouple panorama generation distortion guidance content completion , aim to generate panorama accurate distortion visual appeal . specifically , design distortnet distortion guidance impose panorama specific distortion prior modified condition registration mechanism ; contentnet content completion impose perspective image information . additionally , distortion correction loss function distort clip be introduce to constrain distortion explicitly . extensive experiment validate panodecouple surpasses exist method distortion visual metric ."
https://doi.org/10.48550/arXiv.2503.18414,"Yuchuan Tian, Hanting Chen, Mengyu Zheng, Yuchen Liang, Chao Xu, Yunhe Wang",CV,24/03/2025,"u repa : aligning diffusion u net to vits representation alignment ( repa ) that align diffusion transformer ( dit ) hide state vit visual encoders have prove highly effective dit training , demonstrate superior convergence property , have not be validate canonical diffusion u net architecture that show fast convergence compare to dit . however , adapt repa to u net architecture present unique challenge : ( ) different block functionality necessitate revise alignment strategy ; ( ) spatial dimension inconsistency emerge u net spatial downsampling operation ; ( ) space gap u net vit hinder effectiveness tokenwise alignment . to encounter challenge , propose u repa , representation alignment paradigm that bridge u net hidden state vit feature follow : firstly , propose observation that due to skip connection , middle stage u net be best alignment option . secondly , propose upsampling u net feature pass mlps . thirdly , observe difficulty when perform tokenwise similarity alignment , far introduces manifold loss that regularize relative similarity sample . experiment indicate result u repa could achieve excellent generation quality greatly accelerate convergence speed . cfg guidance interval , u repa could reach $ fid < $ epoch iteration imagenet $ $ , need only half total epoch to perform good repa . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18408,"Jiacheng Wu, Ruiqi Zhang, Jie Chen, Hui Zhang",CV,24/03/2025,"fast physically based neural explicit surface relightable human avatar efficiently model relightable human avatar sparse view video be crucial application . current method use neural implicit representation to capture dynamic geometry reflectance , which incur high cost due to need dense sampling volume render . to overcome challenge , introduce physically based neural explicit surface ( phynes ) , which employ compact neural material map base neural explicit surface ( ne ) representation . phynes human model compact space , enhance material disentanglement efficiency . connect sign distance field to explicit surface , phynes enables efficient geometry inference parameterized human shape model . approach model dynamic geometry , texture , material map neural representation , enable efficient rasterization . phynes effectively capture physical surface attribute vary illumination , enable real time physically based rendering . experiment show phynes achieves relighting quality comparable to sota method significantly improve render speed , memory efficiency , reconstruction quality ."
https://doi.org/10.48550/arXiv.2503.18407,"Wencheng Zhu, Yuexin Wang, Hongxuan Li, Pengfei Zhu, Danqing Song, Qinghua Hu",CV,24/03/2025,"vtd clip : video to text discretization prompt clip vision language model bridge visual linguistic understanding have prove to be powerful video recognition task . exist approach primarily rely parameter efficient fine tuning image text pre trained model , yet often suffer limited interpretability poor generalization due to inadequate temporal modeling . to address , propose simple yet effective video to text discretization framework . method repurposes frozen text encoder to construct visual codebook video class label due to many to one contrastive alignment visual textual embeddings multimodal pretraining . codebook effectively transform temporal visual data textual token feature lookup offer interpretable video representation explicit video modeling . then , to enhance robustness irrelevant noisy frame , introduce confidence aware fusion module that dynamically weight keyframes assess semantic relevance codebook . furthermore , method incorporate learnable text prompt to conduct adaptive codebook update . extensive experiment , , , have validate superiority approach , achieve more competitive improvement state of the art method . code will be publicly available http url ."
https://doi.org/10.48550/arXiv.2503.18406,"Sherry X. Chen, Misha Sra, Pradeep Sen",CV,24/03/2025,"instruct clip : improve instruction guided image edit automate data refinement use contrastive learning natural language instruction offer intuitive way to guide automated image editing , deep learning model often struggle to achieve high quality result , largely due to challenge create large , high quality training datasets . previous work have typically rely text toimage ( ) generative model to produce pair original edited image that simulate instruction guided image editing model . however , image pair often fail to align specify edit instruction due to limitation model , which negatively impact model train such datasets . to address , present instruct clip , self supervised method that learn semantic change original edited image to refine good align instruction exist datasets . furthermore , adapt instruct clip to handle noisy latent image diffusion timesteps so can be use to train latent diffusion model ( ldms ) [ ] efficiently enforce alignment edit instruction image change latent space step diffusion pipeline . use instruct clip to correct dataset get refined sample then use to fine tune model , guide novel instruct clip based loss function . result model can produce edits that be more aligned give instruction . code dataset be available http url ."
https://doi.org/10.48550/arXiv.2503.18405,"Xu Fan, Yuetan Lin, Bing Gong, Hao Li",CV,24/03/2025,"offline meteorology pollution couple global air pollution forecast model bilinear pooling air pollution have become major threat to human health , make accurate forecasting crucial pollution control . traditional physics based model forecast global air pollution couple meteorology pollution process , use online offline method depend fully integrate meteorological model run simultaneously . however , high computational demand method severely limit real time prediction efficiency . exist deep learning ( dl ) solution employ online coupling strategy global air pollution forecasting , which finetune pollution forecasting base pretrained atmospheric model , require substantial training resource . study pioneer dl based offline couple framework that utilize bilinear pool to achieve offline couple meteorological field pollutant . propose model require only % parameter dl based online couple model achieve competitive performance . compare state of the art global air pollution forecast model cam , approach demonstrate superiority % variable forecast time step % variable prediction exceed hour . work pioneer experimental validation effectiveness meteorological field dl based global air pollution forecasting , demonstrate offline couple meteorological field pollutant can achieve % relative reduction rmse pollution variable . research establish new paradigm real time global air pollution warn system delivers critical technical support develop more efficient comprehensive ai powered global atmospheric forecasting framework ."
https://doi.org/10.48550/arXiv.2503.18403,"Xusheng Cao, Haori Lu, Linlan Huang, Fei Yang, Xialei Liu, Ming-Ming Cheng",CV,24/03/2025,"knowledge graph enhance generative multi modal model class incremental learning continual learning computer vision face critical challenge catastrophic forgetting , where model struggle to retain prior knowledge adapt to new task . recent study have attempt to leverage generalization capability pre trained model to mitigate overfitting current task , model still tend to forget detail previously learn category task progress , lead to misclassification . to address limitation , introduce novel knowledge graph enhance generative multi modal model ( kg gmm ) that build evolve knowledge graph learning process . approach utilizes relationship knowledge graph to augment class label assigns different relation to similar category to enhance model differentiation . test , propose knowledge graph augment inference method that locate specific category analyze relationship generated text , thereby reduce loss detailed information old class when learn new knowledge alleviate forgetting . experiment demonstrate method effectively leverage relational information to help model correct mispredictions , achieve state of the art result conventional cil few shot cil setting , confirm efficacy knowledge graph preserve knowledge continual learning scenario ."
https://doi.org/10.48550/arXiv.2503.18402,"Youyu Chen, Junjun Jiang, Kui Jiang, Xiao Tang, Zhihao Li, Xianming Liu, Yinyu Nie",CV,24/03/2025,"dashgaussian : optimize gaussian splatting second gaussian splatting ( ) render pixel rasterize gaussian primitive , where rendering resolution primitive number , conclude optimization complexity , dominate time cost primitive optimization . paper , propose dashgaussian , scheduling scheme optimization complexity strip redundant complexity to accelerate optimization . specifically , formulate optimization progressively fit to high level frequency component training view , propose dynamic rendering resolution scheme that largely reduce optimization complexity base formulation . besides , argue specific render resolution should cooperate proper primitive number good balance compute redundancy fitting quality , where schedule growth primitive to synchronize render resolution . extensive experiment show method accelerate optimization various backbone % average preserve rendering quality ."
https://doi.org/10.48550/arXiv.2503.18393,"Xinhua Xu, Hong Liu, Jianbing Wu, Jinfu Liu",CV,24/03/2025,"pddm : pseudo depth diffusion model rgb pd semantic segmentation base complex indoor scene integration rgb depth modality significantly enhance accuracy segment complex indoor scene , depth data rgb d camera play crucial role improvement . however , collect rgb d dataset be more expensive rgb dataset due to need specialized depth sensor . align depth rgb image also pose challenge due to sensor positioning issue miss data noise . contrast , pseudo depth ( pd ) high precision depth estimation algorithm can eliminate dependence rgb d sensor alignment process , as well provide effective depth information show significant potential semantic segmentation . therefore , to explore practicality utilize pseudo depth instead real depth semantic segmentation , design rgb pd segmentation pipeline to integrate rgb pseudo depth propose pseudo depth aggregation module ( pdam ) fully exploit informative clue provide diverse pseudo depth map . pdam aggregate multiple pseudo depth map single modality , make easily adaptable to other rgb d segmentation method . addition , pre trained diffusion model serve strong feature extractor rgb segmentation task , multi modal diffusion based segmentation method remain unexplored . therefore , present pseudo depth diffusion model ( pddm ) that adopt large scale text image diffusion model feature extractor simple yet effective fusion strategy to integrate pseudo depth . to verify applicability pseudo depth pddm , perform extensive experiment sunrgb d datasets . experimental result demonstrate pseudo depth can effectively enhance segmentation performance , pddm achieves state of the art performance , outperform other method miou miou sunrgb d ."
https://doi.org/10.48550/arXiv.2503.18386,"Sicong Feng, Jielong Yang, Li Peng",CV,24/03/2025,"resource efficient motion control video generation dynamic mask guidance recent advance diffusion model bring new vitality to visual content creation . however , current text to video generation model still face significant challenge such high training cost , substantial data requirement , difficulty maintain consistency give text motion foreground object . to address challenge , propose mask guided video generation , which can control video generation mask motion sequence , require limited training data . model enhance exist architecture incorporate foreground mask precise text position matching motion trajectory control . mask motion sequence , guide video generation process to maintain consistent foreground object sequence . additionally , first frame sharing strategy autoregressive extension approach , achieve more stable long video generation . extensive qualitative quantitative experiment demonstrate approach excel various video generation task , such video editing generate artistic video , outperform previous method term consistency quality . generated result can be view supplementary material ."
https://doi.org/10.48550/arXiv.2503.18384,"Yuan Gao, Shaobo Xia, Pu Wang, Xiaohuan Xi, Sheng Nie, Cheng Wang",CV,24/03/2025,"lidar remote sense meet weak supervision : concept , method , perspective lidar ( light detection range ) enable rapid accurate acquisition three dimensional spatial data , widely apply remote sense area such surface mapping , environmental monitoring , urban modeling , forestry inventory . lidar remote sense primarily include data interpretation lidar based inversion . however , lidar interpretation typically rely dense precise annotation , which be costly time consuming . similarly , lidar inversion depend scarce supervisory signal expensive field survey annotation . to address challenge , weakly supervise learning have gain significant attention recent year , many method emerge to tackle lidar remote sense task use incomplete , inaccurate , inexact annotation , as well annotation other domain . exist review article treat lidar interpretation inversion separate task . review , first time , adopt unified weakly supervise learn perspective to systematically examine research lidar interpretation inversion . summarize late advancement , provide comprehensive review development application weakly supervise technique lidar remote sensing , discuss potential future research direction field ."
https://doi.org/10.48550/arXiv.2503.18382,"Hongen Liu, Cheng Cui, Yuning Du, Yi Liu, Gang Pan",CV,24/03/2025,"pp formulanet : bridging accuracy efficiency advanced formula recognition formula recognition be important task document intelligence . involve convert mathematical expression document image structure symbolic format computer can easily work . latex be most common format use purpose . work , present pp formulanet , state of the art formula recognition model that excel accuracy efficiency . to meet diverse need application , have develop two specialized model : pp formulanet l , tailor high accuracy scenario , pp formulanet s , optimize high efficiency context . extensive evaluation reveal pp formulanet l attains accuracy level that surpass prominent model such unimernet significant % . conversely , pp formulanet s operates speed that be time faster . advancement facilitate seamless integration pp formulanet broad spectrum document processing environment that involve intricate mathematical formula . furthermore , introduce formula mining system , which be capable extract vast amount high quality formula data . system far enhance robustness applicability formula recognition model . code model be publicly available paddleocr ( http url ) paddlex ( http url ) ."
https://doi.org/10.48550/arXiv.2503.18378,"Tianpei Zhang, Yiming Zhu, Jufeng Zhao, Guangmang Cui, Yuchen Zheng",CV,24/03/2025,"explore state space model wavelet domain : infrared visible image fusion network wavelet transform state space model deep learning technique have revolutionize infrared visible image fusion ( ivif ) , show remarkable efficacy complex scenario . however , current method do not fully combine frequency domain feature global semantic information , which will result suboptimal extraction global feature modality insufficient preservation local texture detail . to address issue , propose wavelet mamba ( w mamba ) , which integrate wavelet transform state space model ( ssm ) . specifically , introduce wavelet ssm module , which incorporate wavelet based frequency domain feature extraction global information extraction ssm , thereby effectively capture global local feature . additionally , propose cross modal feature attention modulation , which facilitate efficient interaction fusion different modality . experimental result indicate method achieve visually compelling result superior performance compare to current state of the art method . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18371,"Hankyul Kang, Gregor Seifer, Donghyun Lee, Jongbin Ryu",CV,24/03/2025,"do best get enough rest continual learning accord to forget curve theory , can enhance memory retention learn extensive data take adequate rest . mean order to effectively retain new knowledge , be essential to learn thoroughly ensure sufficient rest brain can memorize forget . main takeaway theory be learn extensive data once necessitates sufficient rest learn same data again . aspect human long term memory retention can be effectively utilized to address continual learning neural network . retain new knowledge long period time catastrophic forgetting be critical problem continual learning . therefore , base ebbinghaus ' theory , introduce view batch model that adjust learning schedule to optimize recall interval retrain same sample . propose view batch model allow network to get enough rest to learn extensive knowledge same sample recall interval sufficient length . to end , specifically present two approach : ) replay method that guarantee optimal recall interval , ) self supervised learning that acquire extensive knowledge single training sample time . empirically show approach method be align forget curve theory , which can enhance long term memory . experiment , also demonstrate method significantly improve many state of the art continual learning method various protocol scenario . open source project http url ."
https://doi.org/10.48550/arXiv.2503.18370,"Raquel Vidaurre, Elena Garces, Dan Casas",CV,24/03/2025,"diffusedwrinkles : diffusion based model data driven garment animation present data driven method learn to generate animation garment use image diffusion model . contrast to exist method , typically base fully connect network , graph neural network , generative adversarial network , which have difficulty to cope parametric garment fine wrinkle detail , approach be able to synthesize high quality animation wide variety garment body shape , be agnostic to garment mesh topology . key idea be to represent garment deformation layout consistent texture that encode offset respect to parametric garment template . use representation , encode large dataset garment simulate various motion shape train novel conditional diffusion model that be able to synthesize high quality pose shape and design dependent garment deformation . model be generative , can synthesize various plausible deformation give target pose , shape , design . additionally , show can further condition model use exist garment state , which enable generation temporally coherent sequence ."
https://doi.org/10.48550/arXiv.2503.18368,"Xu Han, Yuan Tang, Jinfeng Xu, Xianzhi Li",CV,24/03/2025,"most : efficient monarch sparse tune representation learning introduce monarch sparse tuning ( most ) , first reparameterization based parameter efficient fine tuning ( peft ) method tailor representation learning . exist adapter based prompt tuning peft method , most introduces additional inference overhead be compatible many representation learn backbone . core , present new family structured matrix point cloud , point monarch , which can capture local geometric feature irregular point offer high expressiveness . most reparameterizes dense update weight matrix sparse point monarch matrix , significantly reduce parameter retain strong performance . experiment various backbone show most be simple , effective , highly generalizable . capture local feature point cloud , achieve state of the art result multiple benchmark , , % acc . scanobjectnn ( ) % classification , can also combine other matrix decomposition ( , low rank , kronecker ) to further reduce parameter ."
https://doi.org/10.48550/arXiv.2503.18364,"Chenxi Xie, Minghan Li, Hui Zeng, Jun Luo, Lei Zhang",CV,24/03/2025,": matting level semantic segmentation benchmark high resolution semantic segmentation be essential application such image editing , bokeh imaging , , etc . unfortunately , exist datasets often have limit resolution lack precise mask detail boundary . work , build large scale , matting level semantic segmentation dataset , name , which consist real world image , resolution . provide high quality mask annotation number object , which be categorize seven category : human , vegetation , ground , sky , water , building , others . feature precise mask , average mask complexity time high exist semantic segmentation datasets . consequently present method specifically design high resolution semantic segmentation , namely massformer , which employ efficient pixel decoder that aggregate high level semantic feature low level texture feature three stage , aim to produce high resolution mask minimal computational cost . finally , propose new learning paradigm , which integrate high quality mask seven give category pseudo label new class , enable massformer to transfer accurate segmentation capability to other class object . propose massformer be comprehensively evaluate benchmark together representative segmentation model . expect meticulously annotate dataset massformer model can facilitate research high resolution high quality semantic segmentation . datasets code can be find http url ."
https://doi.org/10.48550/arXiv.2503.18363,"Wenyuan Zhang, Yixiao Yang, Han Huang, Liang Han, Kanle Shi, Yu-Shen Liu",CV,24/03/2025,"monoinstance : enhance monocular prior multi view instance alignment neural rendering reconstruction monocular depth prior have be widely adopt neural rendering multi view base task such reconstruction novel view synthesis . however , due to inconsistent prediction view , how to more effectively leverage monocular cue multi view context remain challenge . current method treat entire estimate depth map indiscriminately , use ground truth supervision , ignore inherent inaccuracy cross view inconsistency monocular prior . to resolve issue , propose monoinstance , general approach that explore uncertainty monocular depth to provide enhanced geometric prior neural rendering reconstruction . key insight lie align segment instance depth multiple view common space , thereby cast uncertainty estimation monocular depth density measure noisy point cloud . high uncertainty area where depth prior be unreliable , further introduce constraint term that encourage projected instance to align correspond instance mask nearby view . monoinstance be versatile strategy which can be seamlessly integrate various multi view neural rendering framework . experimental result demonstrate monoinstance significantly improve performance reconstruction novel view synthesis various benchmark ."
https://doi.org/10.48550/arXiv.2503.18361,"Wenyuan Zhang, Emily Yue-ting Jia, Junsheng Zhou, Baorui Ma, Kanle Shi, Yu-Shen Liu",CV,24/03/2025,"nerfprior : learning neural radiance field prior indoor scene reconstruction recently , have show prior be vital neural implicit function to reconstruct high quality surface multi view rgb image . however , current prior require large scale pre training , merely provide geometric clue consider importance color . paper , present nerfprior , which adopt neural radiance field prior to learn signed distance field use volume render surface reconstruction . nerf prior can provide geometric color clue , also get train fast same scene additional data . base nerf prior , be enable to learn signed distance function ( sdf ) explicitly impose multi view consistency constraint ray intersection surface inference . specifically , ray intersection , use density prior coarse geometry estimation , use color surface clue to check visibility view angle . textureless area where multi view consistency constraint do not work well , further introduce depth consistency loss confidence weight to infer sdf . experimental result state of the art method widely use benchmark ."
https://doi.org/10.48550/arXiv.2503.18359,"Zhanzhong Pang, Fadime Sener, Angela Yao",CV,24/03/2025,"context enhanced memory refined transformer online action detection online action detection ( oad ) detect action stream video use past observation . state of the art oad approach model past observation interaction anticipated future . past be encode use short  long term memory to capture immediate long range dependency , anticipation compensates miss future context . identify training inference discrepancy exist oad method hinders learn effectiveness . training use vary length short term memory , inference relies full length short term memory . remedy , propose context enhanced memory refined transformer ( cmert ) . cmert introduce context enhanced encoder to improve frame representation use additional near past context . also feature memory refined decoder to leverage near future generation to enhance performance . cmert achieve state of the art online detection anticipation , crosstask , ."
https://doi.org/10.48550/arXiv.2503.18358,"Zhanzhong Pang, Fadime Sener, Shrinivas Ramasubramanian, Angela Yao",CV,24/03/2025,"cost sensitive learning long tailed temporal action segmentation temporal action segmentation untrimmed procedural video aim to densely label frame action class . video inherently exhibit long tailed distribution , where action vary widely frequency duration . temporal action segmentation approach , identify bi level learning bias . bias encompass ( ) class level bias , stem class imbalance favor head class , ( ) transition level bias arise variation transition , prioritize commonly observe transition . remedy , introduce constrained optimization problem to alleviate bias . define learn state action class associated transition integrate optimization process . propose novel cost sensitive loss function formulate weighted cross entropy loss , weight adaptively adjust base learn state action transition . experiment three challenge temporal segmentation benchmark various framework demonstrate effectiveness approach , result significant improvement per class frame wise segment wise performance ."
https://doi.org/10.48550/arXiv.2503.18352,"Jinjin Zhang, Qiuyu Huang, Junjie Liu, Xiefan Guo, Di Huang",CV,24/03/2025,": ultra high resolution image synthesis latent diffusion model paper , present , novel framework direct ultra high resolution image synthesis use text to image diffusion model . core advancement include : ( ) benchmark : address absence publicly available image synthesis dataset , construct , comprehensive benchmark ultra high resolution image generation . curated high quality dataset carefully select image caption generate . additionally , introduce glcm score compression ratio metric to evaluate fine detail , combine holistic measure such fid , aesthetic clipscore comprehensive assessment ultra high resolution image . ( ) wavelet based fine tuning : propose wavelet based fine tuning approach direct training photorealistic image , applicable to various latent diffusion model , demonstrate effectiveness synthesize highly detailed image . consequently , achieves impressive performance high quality image synthesis text prompt adherence , especially when power modern large scale diffusion model ( , ) . extensive experimental result benchmark demonstrate superiority ultra high resolution image synthesis ."
https://doi.org/10.48550/arXiv.2503.18349,"Zekai Deng, Ye Shi, Kaiyang Ji, Lan Xu, Shaoli Huang, Jingya Wang",CV,24/03/2025,"human object interaction vision language model guide relative movement dynamic human object interaction ( hoi ) be vital advance simulation , animation , robotics , enable generation long term , physically plausible motion environment . however , exist method often fall short achieve physic realism support diverse type interaction . to address challenge , paper introduce unified human object interaction framework that provide unified control interaction static scene dynamic object use language command . interaction human object part can always be describe continuous stable relative movement dynamic ( rmd ) human object part . leverage world knowledge scene perception capability vision language model ( vlms ) , translate language command rmd diagram , which be use to guide goal conditioned reinforcement learn sequential interaction object . framework support long horizon interaction dynamic , articulate , static object . to support training evaluation framework , present new dataset name interplay , which include multi round task plan generate vlms , cover static dynamic hoi task . extensive experiment demonstrate propose framework can effectively handle wide range hoi task , showcasing ability to maintain long term , multi round transition . more detail , please refer to project webpage : http url ."
https://doi.org/10.48550/arXiv.2503.18341,"Kazuma Kitazawa, Takahito Aoto, Satoshi Ikehata, Tsuyoshi Takatani",CV,24/03/2025,"p eip : robust photometric stereo base event interval profile recently , energy efficient photometric stereo method use event camera have be propose to recover surface normal event trigger change logarithmic lambertian reflection moving directional light source . however , eventps treat event interval independently , make sensitive to noise , shadow , non lambertian reflection . paper propose photometric stereo base event interval profile ( ps eip ) , robust method recovers pixelwise surface normal time series profile event interval . exploit continuity profile introduce outlier detection method base profile shape , approach enhance robustness outlier shadow specular reflection . experiment use real event data object demonstrate p eip significantly improve robustness to outlier compare to eventps deep learning variant , eventps fcn , rely deep learning ."
https://doi.org/10.48550/arXiv.2503.18339,"Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Sanghyun Park",CV,24/03/2025,"granq : granular zero shot quantization unified layer channel awareness zero shot quantization ( zsq ) enable neural network compression train data , which be crucial restricted data access environment . however , exist zsq method suffer significant activation loss low bit environment owe to coarse grained scaling strategy . to address issue , propose granq , novel zsq approach that leverage layer channel awareness to minimize quantization error . conventional layer  channel wise quantization , granq dynamically adjust quantization granularity consider layer  channel level activation distribution . enable fine grained quantization minimize activation distortion . additionally , introduce vectorized activation quantization , which enable efficient parallel computation reduce computational overhead preserve accuracy . granq achieve superior performance compare state of the art zsq method that employ quantization aware training . finding , anticipate granq will inspire novel research direction conventional zsq approach focus data generation model training ."
https://doi.org/10.48550/arXiv.2503.18338,"Wenrui Cai, Qingjie Liu, Yunhong Wang",CV,24/03/2025,"spmtrack : spatio temporal parameter efficient fine tuning mixture expert scalable visual tracking most state of the art tracker adopt one stream paradigm , use single vision transformer joint feature extraction relation modeling template search region image . however , relation model different image patch exhibit significant variation . instance , background region dominate target irrelevant information require reduce attention allocation , foreground , particularly boundary area , need to be be emphasize . single model may not effectively handle kind relation model simultaneously . paper , propose novel tracker call spmtrack base mixture of expert tailor visual tracking task ( tmoe ) , combine capability multiple expert to handle diverse relation model more flexibly . benefit tmoe , extend relation modeling image pair to spatio temporal context , far improve track accuracy minimal increase model parameter . moreover , employ tmoe parameter efficient fine tuning method , substantially reduce trainable parameter , which enable to train spmtrack vary scale efficiently preserve generalization ability pretrained model to achieve superior performance . conduct experiment seven datasets , experimental result demonstrate method significantly outperform current state of the art tracker . source code be available http url ."
https://doi.org/10.48550/arXiv.2503.18337,"Zichen Miao, Wei Chen, Qiang Qiu",CV,24/03/2025,"coeff tuning : graph filter subspace view tune attention based large model transformer based large pre trained model have show remarkable generalization ability , various parameter efficient fine tuning ( peft ) method have be propose to customize model downstream task minimal computational memory budget . previous peft method be primarily design tensor decomposition perspective that try to effectively tune linear transformation find small subset parameter to train . study adopt orthogonal view represent attention operation graph convolution formulate multi head attention map convolutional filter subspace , attention map subspace element . paper , propose to tune large pre trained transformer learn small set combination coefficient that construct more expressive filter subspace original multi head attention map . show analytically experimentally tuned filter subspace can effectively expand feature space multi head attention further enhance capacity transformer . further stabilize fine tuning residual parameterization tunable subspace coefficient , enhance generalization regularization design directly apply dropout tunable coefficient training . tunable coefficient take tiny number parameter can be combine previous peft method plug and play manner . extensive experiment show approach achieve superior performance peft baseline neglectable additional parameter ."
https://doi.org/10.48550/arXiv.2503.18334,"Haotian Zhai, Xinyu Chen, Can Zhang, Tianming Sha, Ruirui Li",CV,24/03/2025,"mitigate cache noise test time adaptation large vision language model test time adaptation ( tta ) visual language model have recently attract significant attention solution to performance degradation cause distribution shift downstream task . however , exist cache based tta method have certain limitation . mainly rely accuracy cached feature label , presence noisy pseudo label can cause feature to deviate true distribution . make cache retrieval method base similarity match highly sensitive to outlier extreme sample . moreover , current method lack effective mechanism to model class distribution , which limit ability to fully exploit potential cached information . to address challenge , introduce comprehensive reliable caching mechanism propose novel zero shot tta method call cache , residual , gaussian ( crg ) . method not only employ learnable residual parameter to good align positive negative visual prototype text prototype , thereby optimize quality cached feature , also incorporate gaussian discriminant analysis ( gda ) to dynamically model intra class feature distribution , far mitigate impact noisy feature . experimental result benchmark demonstrate crg outperform state of the art tta method , showcasing exceptional robustness adaptability ."
https://doi.org/10.48550/arXiv.2503.18328,"Chun Gu, Xiaofei Wei, Li Zhang, Xiatian Zhu",CV,24/03/2025,"tensoflow : tensorial flow based sampler inverse rendering inverse render aim to recover scene geometry , material property , light multi view image . give complexity light surface interaction , importance sampling be essential evaluation render equation , reduce variance enhance efficiency monte carlo sample . exist inverse render method typically use pre defined non learnable importance sampler prior manually , struggle to effectively match spatially directionally varied integrand result high variance suboptimal performance . to address limitation , propose concept learn spatially directionally aware importance sampler render equation to accurately flexibly capture unconstrained complexity typical scene . further formulate tensoflow , generic approach sampler learning inverse rendering , enable to closely match integrand render equation spatially directionally . concretely , sampler be parameterized normalize flow , allow directional sampling incident light probability density function ( pdf ) inference . to capture characteristic sampler spatially , learn tensorial representation scene space , which impose spatial condition , together reflected direction , lead to spatially directionally aware sample distribution . model can be optimize minimize difference integrand normalizing flow . extensive experiment validate superiority tensoflow prior alternative synthetic real world benchmark ."
https://doi.org/10.48550/arXiv.2503.18325,"Jinjin Zhang, Guodong Wang, Yizhou Jin, Di Huang",CV,24/03/2025,"towards training free anomaly detection vision language foundation model anomaly detection be valuable real world application , such industrial quality inspection . however , most approach focus detect local structural anomaly neglect compositional anomaly incorporate logical constraint . paper , introduce logsad , novel multi modal framework that require training logical structural anomaly detection . first , propose match of thought architecture employ advanced large multi modal model ( . ) to generate matching proposal , formulate interest compositional rule thought anomaly detection . second , elaborate multi granularity anomaly detection , consist patch token , set interest , composition match vision language foundation model . subsequently , present calibration module to align anomaly score different detector , follow integration strategy final decision . consequently , approach address logical structural anomaly detection unified framework achieve state of the art result need training , even when compare to supervise approach , highlight robustness effectiveness . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18324,"Basim Azam, Naveed Akhtar",CV,24/03/2025,"plug and play interpretable responsible text to image generation dual space multi facet concept control ethical issue text to image ( ) model demand comprehensive control generative content . exist technique address issue responsible model aim generated content to be fair safe ( ) . however , method remain bounded to handle facet responsibility concept individually , also lack interpretability . moreover , often require alteration to original model , which compromise model performance . work , propose unique technique to enable responsible generation simultaneously account extensive range concept fair safe content generation scalable manner . key idea be to distill target pipeline external plug and play mechanism that learn interpretable composite responsible space desired concept , condition target pipeline . use knowledge distillation concept whitening to enable . inference , learned space be utilize to modulate generative content . typical pipeline present two plug in point approach , namely ; text embed space diffusion model latent space . develop module point show effectiveness approach range strong result ."
https://doi.org/10.48550/arXiv.2503.18312,"Jianlong Jin, Chenglong Zhao, Ruixin Zhang, Sheng Shang, Jianqing Xu, Jingyun Zhang, ShaoMing Wang, Yang Zhao, Shouhong Ding, Wei Jia, Yunsheng Wu",CV,24/03/2025,"diff palm : realistic palmprint generation polynomial crease intra class variation controllable diffusion model palmprint recognition be significantly limit lack large scale publicly available datasets . previous method have adopt bézier curve to simulate palm crease , which then serve input conditional gans to generate realistic palmprints . however , employ real data fine tuning , performance recognition model train synthetic datasets would drastically decline , indicate large gap generate real palmprints . be primarily due to utilization inaccurate palm crease representation challenge balance intra class variation identity consistency . to address , introduce polynomial based palm crease representation that provide new palm crease generation mechanism more closely align real distribution . also propose palm crease condition diffusion model novel intra class variation control method . apply propose $ k $  step noise sharing sampling , be able to synthesize palmprint datasets large intra class variation high identity consistency . experimental result show , first time , recognition model train solely synthetic datasets , fine tuning , outperform train real datasets . furthermore , approach achieve superior recognition performance number generated identity increase ."
https://doi.org/10.48550/arXiv.2503.18297,"Yishen Liu, Shengda Liu, Hudan Pan",CV,24/03/2025,"image to text medical report use adaptive co attention triple lstm module medical report generation require specialized expertise general large model often fail to accurately capture . moreover , inherent repetition similarity medical data make difficult model to extract meaningful feature , result tendency to overfit . so paper , propose multimodal model , co attention triple lstm network ( ca trinet ) , deep learning model that combine transformer architecture multi lstm network . co attention module synergistically link vision transformer text transformer to good differentiate medical image similarity , augment adaptive weight operator to catch amplify image label minor similarity . furthermore , triple lstm module refines generate sentence use targeted image object . extensive evaluation three public datasets have demonstrate ca trinet outperforms state of the art model term comprehensive ability , even pre trained large language model metric ."
https://doi.org/10.48550/arXiv.2503.18294,"Fiseha B. Tesema, Alejandro Guerra Manzanares, Tianxiang Cui, Qian Zhang, Moses Solomon, Sean He",CV,24/03/2025,"lgps : lightweight gan based approach polyp segmentation colonoscopy image colorectal cancer ( crc ) be major global cause cancer related death , early polyp detection removal colonoscopy be crucial prevention . deep learn method have show promise polyp segmentation , challenge such high computational cost , difficulty segment small low contrast polyp , limited generalizability datasets persist . to address issue , propose lgps , lightweight gan based framework polyp segmentation . lgps incorporate three key innovation : ( ) backbone enhance modified residual block squeeze and excitation ( rese ) module efficient feature extraction ; ( ) convolutional conditional random field ( convcrf ) precise boundary refinement ; ( ) hybrid loss function combine binary cross entropy , weight iou loss , dice loss to address class imbalance enhance segmentation accuracy . lgps be validate five benchmark datasets compare state of the art ( sota ) method . large challenge polypgen test dataset , lgps achieve dice iou , outperform sota work demonstrate robust generalization . only million parameter , lgps be time small small exist model , make highly suitable real time clinical application . lightweight design strong performance underscore potential improve early crc diagnosis . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18286,"Siyuan Cheng, Lingjuan Lyu, Zhenting Wang, Xiangyu Zhang, Vikash Sehwag",CV,24/03/2025,"co spy : combining semantic pixel feature to detect synthetic image ai rapid advancement generative ai , be now possible to synthesize high quality image few second . power technology , raise significant concern regard misuse . current effort to distinguish real ai generated image may lack generalization , be effective only certain type generative model susceptible to post processing technique jpeg compression . to overcome limitation , propose novel framework , co spy , first enhances exist semantic feature ( , number finger hand ) artifact feature ( , pixel value difference ) , then adaptively integrate to achieve more general robust synthetic image detection . additionally , create co spy bench , comprehensive dataset comprise real image datasets state of the art generative model , include late model flux . also collect synthetic image wild internet to enable evaluation more practical setting . extensive evaluation demonstrate detector outperform exist method identical training condition , achieve average accuracy improvement approximately % to % . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18283,"Bojun Liu, Yangzhi Ma, Ao Luo, Li Li, Dong Liu",CV,24/03/2025,"voxel based point cloud geometry compression space to channel context voxel based method be most efficient point cloud geometry compression , particularly dense point cloud . however , face limitation due to restricted receptive field , especially when handle high bit depth point cloud . to overcome issue , introduce stage wise space to channel ( ) context model dense point cloud low level sparse point cloud . model utilize channel wise autoregressive strategy to effectively integrate neighborhood information coarse resolution . high level sparse point cloud , further propose level wise context model that address resolution limitation incorporate geometry residual coding ( grc ) consistent resolution cross level prediction . additionally , use spherical coordinate system compact representation enhance grc approach residual probability approximation ( rpa ) module , which feature large kernel size . experimental result show context model not only achieve bit saving maintain improve reconstruction quality also reduce computational complexity compare to state of the art voxel based compression method ."
https://doi.org/10.48550/arXiv.2503.18282,"Kazuhiro Yamada, Li Yin, Qingrui Hu, Ning Ding, Shunsuke Iwashita, Jun Ichikawa, Kiwamu Kotani, Calvin Yeung, Keisuke Fujii",CV,24/03/2025,": dataset algorithm multi player tracking identification pose estimation basketball full court video multi object tracking , player identification , pose estimation be fundamental component sport analytics , essential analyze player movement , performance , tactical strategy . however , exist datasets methodology primarily target mainstream team sport such soccer conventional basketball , often overlook scenario involve fixed camera setup commonly use amateur level , less mainstream sport , datasets that explicitly incorporate pose annotation . paper , propose dataset , first publicly available comprehensive dataset specifically design multi player tracking , player identification , pose estimation basketball scenario . dataset comprise three distinct subset ( indoor fixed camera , outdoor fixed camera , drone camera footage ) , capture diverse full court camera perspective environment . also introduce track id task , simplified variant game state reconstruction task that exclude field detection focus exclusively fixed camera scenario . to evaluate performance , propose baseline algorithm call track id algorithm , tailor to assess tracking identification quality . furthermore , benchmark experiment , utilizing recent multi object tracking algorithm ( , bot sort reid ) top down pose estimation method ( hrnet , rtmpose , swinpose ) , demonstrate robust result highlight remain challenge . dataset evaluation benchmark provide solid foundation advance automated analytics basketball . dataset code will be available http url ."
https://doi.org/10.48550/arXiv.2503.18278,"Cheng Yang, Yang Sui, Jinqi Xiao, Lingyi Huang, Yu Gong, Chendi Li, Jinghua Yan, Yu Bai, Ponnuswamy Sadayappan, Xia Hu, Bo Yuan",CV,24/03/2025,"topv : compatible token prune inference time optimization fast low memory multimodal vision language model vision language model ( vlms ) demand substantial computational resource inference , largely due to extensive visual input token represent visual information . previous study have note visual token tend to receive less attention text token , suggest low importance inference potential prune . however , method encounter several challenge : reliance greedy heuristic criterion token importance incompatibility flashattention kv cache . to address issue , introduce { topv } , compatible { to } ken { p } run inference time optimization fast low memory { v } lm , achieve efficient prune additional training fine tuning . instead rely attention score , formulate token pruning optimization problem , accurately identify important visual token remain compatible flashattention . additionally , only perform pruning once prefilling stage , effectively reduce kv cache size . optimization framework incorporate visual aware cost function consider factor such feature similarity , relative spatial distance , absolute central distance , to measure importance source visual token , enable effective pruning low importance token . extensive experiment demonstrate method outperform previous token prune method , validate effectiveness efficiency approach ."
https://doi.org/10.48550/arXiv.2503.18267,"Minh-Tuan Tran, Trung Le, Xuan-May Le, Thanh-Toan Do, Dinh Phung",CV,24/03/2025,"enhance dataset distillation non critical region refinement dataset distillation have become popular method compress large datasets small , more efficient representation preserve critical information model training . data feature be broadly categorize two type : instance specific feature , which capture unique , fine grained detail individual example , class general feature , which represent share , broad pattern class . however , previous approach often struggle to balance features some focus solely class general pattern , neglect finer instance detail , others prioritize instance specific feature , overlook share characteristic essential class level understanding . paper , introduce non critical region refinement dataset distillation ( nrr dd ) method , which preserve instance specific detail fine grained region synthetic data enrich non critical region class general information . approach enable model to leverage pixel information , capture feature type enhance overall performance . additionally , present distance based representative ( dbr ) knowledge transfer , which eliminate need soft label training rely distance synthetic data prediction one hot encoded label . experimental result show nrr dd achieves state of the art performance small  large scale datasets . furthermore , store only two distance instance , method delivers comparable result various setting . code be available http url ."
https://doi.org/10.48550/arXiv.2503.18254,"Lukas Uzolas, Elmar Eisemann, Petr Kellnhofer",CV,24/03/2025,"surface aware distil semantic feature many task such pose alignment , animation , motion transfer , reconstruction rely establish correspondence shape . challenge have recently be approach match semantic feature pre trained vision model . however , power , feature struggle to differentiate instance same semantic class such left hand versus right hand which lead to substantial mapping error . to solve , learn surface aware embedding space that be robust to ambiguity . importantly , approach be self supervised require only small number unpaired training mesh to infer feature new shape test time . achieve introduce contrastive loss that preserve semantic content feature distil foundational model disambiguate feature locate far apart shape surface . observe superior performance correspondence matching benchmark enable downstream application include in part segmentation , pose alignment , motion transfer . project site be available http url ."
https://doi.org/10.48550/arXiv.2503.18244,"Jungsoo Lee, Debasmit Das, Munawar Hayat, Sungha Choi, Kyuwoong Hwang, Fatih Porikli",CV,23/03/2025,"customkd : customize large vision foundation edge model improvement knowledge distillation propose novel knowledge distillation approach , customkd , that effectively leverage large vision foundation model ( lvfms ) to enhance performance edge model ( , ) . recent advancement lvfms , such clip , potential knowledge distillation enhance edge model remain underexplored . knowledge distillation be promising approach improve performance edge model , discrepancy model capacity heterogeneous architecture lvfms edge model pose significant challenge . observation indicate utilizing large backbone ( , vit s to vit l ) teacher model improve downstream task performance , knowledge distillation large teacher model fail to bring as much performance gain student model teacher model due to large model discrepancy . simple yet effective customkd customize well generalized feature inherent lvfms to give student model order to reduce model discrepancy . specifically , provide well generalized original knowledge teacher , customkd align feature teacher to student , make easy student to understand overcome large model discrepancy overall . customkd significantly improve performance edge model scenario unlabeled data such unsupervised domain adaptation ( , officehome domainnet ) semi supervised learning ( , labeled sample imagenet % labeled sample ) , achieve new state of the art performance ."
https://doi.org/10.48550/arXiv.2503.18227,"Yiheng Zhong, Zihong Luo, Chengzhi Liu, Feilong Tang, Zelin Peng, Ming Hu, Yingzhen Hu, Jionglong Su, Zongyuan Geand, Imran Razzak",CV,23/03/2025,"pg sam : prior guided sam medical multi organ segmentation segment anything model ( sam ) demonstrate powerful zero shot capability ; however , accuracy robustness significantly decrease when apply to medical image segmentation . exist method address issue modality fusion , integrate textual image information to provide more detailed prior . study , argue granularity text domain gap affect accuracy prior . furthermore , discrepancy high level abstract semantics pixel level boundary detail image can introduce noise fusion process . to address , propose prior guided sam ( pg sam ) , which employ fine grained modality prior aligner to leverage specialized medical knowledge good modality alignment . core method lie efficiently address domain gap fine grained text medical llm . meanwhile , also enhance prior ' quality modality alignment , ensure more accurate segmentation . addition , decoder enhance model expressive capability multi level feature fusion iterative mask optimizer operation , support unprompted learning . also propose unified pipeline that effectively supply high quality semantic information to sam . extensive experiment synapse dataset demonstrate propose pg sam achieve state of the art performance . anonymous code be release http url ."
https://doi.org/10.48550/arXiv.2503.18223,"Valentin Gabeff, Haozhe Qi, Brendan Flaherty, Gencer Sumbül, Alexander Mathis, Devis Tuia",CV,23/03/2025,"mammalps : multi view video behavior monitor dataset wild mammal swiss alp monitor wildlife be essential ecology ethology , especially light increase human impact ecosystem . camera trap have emerge habitat centric sensor enable study wildlife population scale minimal disturbance . however , lack annotated video datasets limit development powerful video understanding model need to process vast amount fieldwork data collect . to advance research wild animal behavior monitoring present mammalps , multimodal multi view dataset wildlife behavior monitoring camera trap swiss national park . mammalps contain hour video audio , segmentation map hour individual track densely label specie behavior . base single animal clip , propose first hierarchical multimodal animal behavior recognition benchmark use audio , video reference scene segmentation map input . furthermore , also propose second ecology oriented benchmark aim identify activity , specie , number individual meteorological condition multi view long term ecological event , include false positive trigger . advocate task be complementary contribute to bridge gap machine learning ecology . code data be available : http url"
https://doi.org/10.48550/arXiv.2503.18211,"Zhengyuan Li, Kai Cheng, Anindita Ghosh, Uttaran Bhattacharya, Liangyan Gui, Aniket Bera",CV,23/03/2025,"simmotionedit : text based human motion edit motion similarity prediction text based human motion editing be critical yet challenge task computer vision graphic . training free approach have be explore , recent release motionfix dataset , which include source text motion triplet , have open new avenue training , yield promising result . however , exist method struggle precise control , often lead to misalignment motion semantics language instruction . paper , introduce related task , motion similarity prediction , propose multi task training paradigm , where train model jointly motion editing motion similarity prediction to foster learning semantically meaningful representation . to complement task , design advanced diffusion transformer based architecture that separately handle motion similarity prediction motion editing . extensive experiment demonstrate state of the art performance approach edit alignment fidelity ."
https://doi.org/10.48550/arXiv.2503.18177,"Gulnaz Gimaletdinova, Dim Shaiakhmetov, Madina Akpaeva, Mukhammadmuso Abduzhabbarov, Kadyrmamat Momunov",CV,23/03/2025,"train neural network partially occlude road sign identification context autonomous vehicle increase number autonomous vehicle rapid development computer vision technology underscore particular importance conduct research accuracy traffic sign recognition . numerous study field have already achieve significant result , demonstrate high effectiveness address traffic sign recognition task . however , task become considerably more complex when sign be partially obscure surround object , such tree branch , billboard , other element urban environment . study , investigate how partial occlusion traffic sign affect recognition . purpose , collect dataset comprise image , include fully visible partially occluded sign , make publicly available . use dataset , compare performance custom convolutional neural network ( cnn ) , which achieve % accuracy , model train use transfer learning . best result be obtain full layer unfreezing , reach % accuracy . additional experiment reveal model train solely fully visible sign lose effectiveness when recognize occlude sign . highlight critical importance incorporate real world data partial occlusion train set to ensure robust model performance complex practical scenario to enhance safety autonomous driving ."
https://doi.org/10.48550/arXiv.2503.18170,"Abderrachid Hamrani, Anuradha Godavarty",CV,23/03/2025,"self attention diffusion model zero shot biomedical image segmentation : unlocking new frontier medical imaging produce high quality segmentation mask medical image be fundamental challenge biomedical image analysis . recent research have explore large scale supervised training to enable segmentation various medical imaging modality unsupervised training to facilitate segmentation dense annotation . however , construct model capable segment diverse medical image zero shot manner annotation remain significant hurdle . paper introduce attention diffusion zero shot unsupervised system ( adzus ) , novel approach that leverage self attention diffusion model zero shot biomedical image segmentation . adzus harness intrinsic capability pre trained diffusion model , utilize generative discriminative potential to segment medical image require annotated training data prior domain specific knowledge . adzus architecture be detail , integration self attention mechanism that facilitate context aware detail sensitive segmentation be highlight . experimental result various medical image datasets , include skin lesion segmentation , chest x ray infection segmentation , white blood cell segmentation , reveal adzus achieves state of the art performance . notably , adzus reach dice score range % to % iou score % to % different segmentation task , demonstrate significant improvement handle novel , unseen medical imagery . be noteworthy adzus demonstrate high effectiveness , demand substantial computational resource extend processing time . model efficacy zero shot setting underscore potential to reduce reliance costly annotation seamlessly adapt to new medical imaging task , thereby expand diagnostic capability ai driven medical imaging technology ."
https://doi.org/10.48550/arXiv.2503.18160,"Haoyang Li, Siyu Zhou, Liang Wang, Guodong Long",CV,23/03/2025,"mao : efficient model agnostic optimization prompt tune vision language model clip based prompt tune significantly enhance pre trained vision language model , exist research focus reconstruct model architecture , , additional loss calculation meta network . approach generally lead to increase complexity extend training cost . to maintain efficiency tuning process , propose plug and play model agnostic optimization ( mao ) prompt tuning . alter component prompt tune backbone , introduce data driven enhancement framework to optimize distribution initial data , incorporate alterable regularization module to boost task specific feature processing pipeline , thereby improve overall performance maintain low computational cost . extensive experiment mao demonstrate outstanding performance efficiency . code mao be available : http url ."
https://doi.org/10.48550/arXiv.2503.18159,"Peng Chen, Xiaobao Wei, Ming Lu, Hui Chen, Feng Tian",CV,23/03/2025,"diffusiontalker : efficient compact speech driven talk head personalizer guided distillation real time speech driven facial animation have be attractive academia industry . traditional method mainly focus learn deterministic mapping speech to animation . recent approach start to consider nondeterministic fact speech driven face animation employ diffusion model task . exist diffusion based method can improve diversity facial animation . however , personalize speaking style convey accurate lip language be still lack , besides , efficiency compactness still need to be improve . work , propose diffusiontalker to address above limitation personalizer guided distillation . term personalization , introduce contrastive personalizer that learn identity emotion embeddings to capture speak style audio . further propose personalizer enhancer distillation to enhance influence embeddings facial animation . efficiency , use iterative distillation to reduce step require animation generation achieve more speedup inference . to achieve compactness , distill large teacher model small student model , reduce model storage % minimize performance loss . distillation , user can derive identity emotion embeddings audio to quickly create personalized animation that reflect specific speaking style . extensive experiment be conduct to demonstrate method outperform state of the art method . code will be release : http url ."
https://doi.org/10.48550/arXiv.2503.18155,"Kelly O. Marshall, Omid Poursaeed, Sergiu Oprea, Amit Kumar, Anushrut Jignasu, Chinmay Hegde, Yilei Li, Rakesh Ranjan",CV,23/03/2025,"decorum : language based approach style conditioned synthesis indoor scene indoor scene generation be important problem design digital real world environment . to automate process , scene generation model should be able to not only generate plausible scene layout , also take consideration visual feature style preference . exist method task exhibit very limited control attribute , only allow text input form simple object level description pairwise spatial relationship . propose method decorum enable user to control scene generation process natural language adopt language based representation stage . enable to harness recent advancement large language model ( llm ) to model language to language mapping . addition , show use text based representation allow to select furniture scene use novel object retrieval method base multimodal llm . evaluation benchmark dataset show method achieve improvement exist work text conditioned scene synthesis object retrieval ."
https://doi.org/10.48550/arXiv.2503.18150,"Zhuoling Li, Hossein Rahmani, Qiuhong Ke, Jun Liu",CV,23/03/2025,"longdiff : training free long video generation one go video diffusion model have recently achieve remarkable result video generation . encouraging performance , most model be mainly design train short video generation , lead to challenge maintain temporal consistency visual detail long video generation . paper , propose longdiff , novel training free method consisting carefully design component \ position mapping ( pm ) informative frame selection ( ifs ) \ to tackle two key challenge that hinder short to long video generation generalization : temporal position ambiguity information dilution . longdiff unlock potential off the shelf video diffusion model to achieve high quality long video generation one go . extensive experiment demonstrate efficacy method ."
https://doi.org/10.48550/arXiv.2503.18147,"Ke Niu, Yuwen Chen, Haiyang Yu, Zhuofan Chen, Xianghui Que, Bin Li, Xiangyang Xue",CV,23/03/2025,"pht cad : efficient cad parametric primitive analysis progressive hierarchical tuning computer aided design ( cad ) play pivotal role industrial manufacturing , yet parametric primitive analysis ( ppa ) remain underexplored due to two key challenge : structural constraint reasoning advance semantic understanding . to tackle challenge , first propose efficient hybrid parametrization ( ehp ) good represent engineering drawing . ehp contain four type atomic component , point , line , circle , arc ) . additionally , propose pht cad , novel ppa framework that harness modality alignment reason capability vision language model ( vlms ) precise engineering draw analysis . pht cad , introduce four dedicate regression head to predict correspond atomic component . to train pht cad , three stage training paradigm progressive hierarchical tuning ( pht ) be propose to progressively enhance pht cad capability to perceive individual primitive , infer structural constraint , align annotation layer correspond geometric representation . consider exist datasets lack complete annotation layer real world engineering drawing , introduce paracad , first large scale benchmark that explicitly integrate geometric annotation layer . paracad comprise million annotated drawing training real world industrial drawing complex topological structure physical constraint test . extensive experiment demonstrate effectiveness pht cad highlight practical significance paracad advance ppa research ."
